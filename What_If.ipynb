{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "import sys\n",
    "import itertools\n",
    "import os \n",
    "import time as timer\n",
    "import math\n",
    "from bisect import bisect_left, bisect # For efficient searching in sorted lisst\n",
    "import multiprocessing as mp\n",
    "\n",
    "# from file_management import read_capacity, read_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_capacity(CAPACITY_FILE, airport_substitutions=None):\n",
    "    capacity = pd.read_csv(CAPACITY_FILE, sep=',')\n",
    "\n",
    "    capacity['deptime'] = pd.to_datetime(capacity['deptime'])\n",
    "    capacity['arrtime'] = pd.to_datetime(capacity['arrtime'])\n",
    "\n",
    "    # Map Weekday_Z to day number (0=Mon, 6=Sun)\n",
    "    day_map = {'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6}\n",
    "    capacity['day'] = capacity['Weekday_Z'].map(day_map)\n",
    "\n",
    "    # Calculate total minutes from start of week (Monday 00:00) # Dep Time = Day * 1440 + Hour * 60 + Minute\n",
    "    capacity['dep_time'] = capacity['day'] * 1440 + capacity['deptime'].dt.hour * 60 + capacity['deptime'].dt.minute\n",
    "    capacity['DD_Z'] = capacity['DD_Z'].fillna(0)\n",
    "    capacity['arr_time'] = capacity['day'] * 1440 + capacity['arrtime'].dt.hour * 60 + capacity['arrtime'].dt.minute + capacity['DD_Z']*1440\n",
    "\n",
    "    # --- Column Renaming and Selection ---\n",
    "    rename_columns = {'Net Payload': 'cap_kg','Net Volume': 'cap_m3','Orig': 'ori',\n",
    "        'Dest': 'des','Flight Number': 'flight_number','A/C': 'aircraft_type'}\n",
    "    capacity = capacity.rename(columns=rename_columns)\n",
    "\n",
    "    # Define desired columns\n",
    "    columns = [ 'ori', 'des', 'dep_time', 'arr_time', 'cap_kg']  # , 'aircraft_type', 'flight_number',\n",
    "    capacity = capacity[[col for col in columns if col in capacity.columns]]\n",
    "\n",
    "    # CONVERT SAME AIRPORTS FROM DICTIONARY - same_airports - CONVERT EVERY KEY TO ITS VALUE\n",
    "    for key, value in airport_substitutions.items():\n",
    "        capacity.loc[capacity['ori'] == key, 'ori'] = value\n",
    "        capacity.loc[capacity['des'] == key, 'des'] = value\n",
    "\n",
    "    capacity['dep_time'] = capacity['dep_time'].astype(int) # TIME SINCE START OF SIMULATION\n",
    "    capacity['arr_time'] = capacity['arr_time'].astype(int) # TIME SINCE START OF SIMULATION\n",
    "    # capacity['day'] = capacity['day'].astype(int) # DAY OF SIMULATION OF DEPARTURE FLIGHT\n",
    "    capacity['flight_id'] = capacity.index # FLIGHT NUMBER\n",
    "    print(f\"Capacity data read: {len(capacity)} rows.\")\n",
    "    return capacity\n",
    "\n",
    "\n",
    "def read_market(MARKET_FILE, airport_substitutions=None):\n",
    "    market = pd.read_csv(MARKET_FILE, sep=';')\n",
    "\n",
    "    market = market.rename(columns={'origin': 'ori', 'destination': 'des', 'Market CHW': 'demand', 'Day': 'day'})\n",
    "    if 'product' in market.columns: market.drop(columns=['product'], inplace=True)\n",
    "    if 'Market Allin Yield' in market.columns: market.drop(columns=['Market Allin Yield'], inplace=True)\n",
    "\n",
    "    day_map = {'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6}\n",
    "    market['day'] = market['day'].map(day_map)\n",
    "\n",
    "    # convert HH:MM to minutes\n",
    "    time_minutes = market['Time'].str.split(':', expand=True).astype(int).apply(lambda x: x[0] * 60 + x[1], axis=1)\n",
    "    market['time'] = market['day'] * 1440 + time_minutes\n",
    "\n",
    "    # SUBSITUTE AIRPORTS FROM same_airports DICTIONERY - CONVERT EVERY KEY TO ITS VALUE\n",
    "    for key, value in airport_substitutions.items():\n",
    "        market.loc[market['ori'] == key, 'ori'] = value\n",
    "        market.loc[market['des'] == key, 'des'] = value\n",
    "\n",
    "    # Add original key\n",
    "    market['ODT'] = market['ori'] + '/' + market['des'] + '/' + market['time'].astype(str)\n",
    "\n",
    "    # WE CREATED DUPLICATES KEY AS A RESULT OF CONVERTING SAME AIRPORTS\n",
    "    # MERGE THE DEMAND VALUES FOR THE SAME KEY\n",
    "    market = market.groupby(['ODT', 'ori', 'des', 'time']).agg({'demand': 'sum'}).reset_index()\n",
    "    market = market[['ori', 'des', 'demand', 'time', 'ODT']].copy()\n",
    "\n",
    "    # Convert types\n",
    "    market['time'] = market['time'].astype(int) # TIME SINCE START OF SIMULATION\n",
    "    # market['day'] = market['day'].astype(int) # DAY OF SIMULATION\n",
    "    market['demand'] = pd.to_numeric(market['demand'], errors='coerce').fillna(0)\n",
    "    print(f\"Market data read: {len(market)} rows.\")\n",
    "    return market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_PATHS = 5\n",
    "\n",
    "MIN_CONNECT_MINS = 60\n",
    "MAX_CONNECT_WAIT_MINS = 2 * 24 * 60 # 48 hours - Aggressive Pruning\n",
    "MAX_TOTAL_DURATION_MINS = 5 * 24 * 60 # Pruning: Max overall path duration \n",
    "\n",
    "DIVERSITY_NODE_PENALTY = 1.2 # Small multiplicative penalty for reusing\n",
    "DIVERSITY_FLIGHT_PENALTY = 2.0 # Larger penalty for reusing exact flight IDs\n",
    "A_STAR_HEURISTIC_FACTOR = 0 # Factor for simple heuristic (0 = Dijkstra) - \n",
    "\n",
    "CAPACITY_FILE = 'files/capacity.csv'\n",
    "MARKET_FILE = 'files/market.csv'\n",
    "\n",
    "airport_substitutions = {\n",
    "    'DOH': \"BAH\",\n",
    "    'SZX': \"HKG\",\n",
    "    'CAN': \"HKG\",\n",
    "    'STN': 'LHR',\n",
    "    'LTN': 'LHR'\n",
    "}\n",
    "\n",
    "# schedule_df_raw = read_capacity(CAPACITY_FILE, airport_substitutions=airport_substitutions)\n",
    "# demand_df_raw = read_market(MARKET_FILE, airport_substitutions=airport_substitutions)\n",
    "\n",
    "tie_breaker = itertools.count() # removed for paralell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tuned Fast Flight Path Analysis...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Tuned Fast Network (MaxWait=2880, MaxDuration=7200)...\n",
      "Building graph...\n",
      "Graph built in 0.07s\n",
      "\n",
      "Finding 5 paths (NodePen=1.2, FlightPen=2.0)...\n",
      "  Processed 500/3185... (281.3 req/s)\n",
      "  Processed 1000/3185... (317.5 req/s)\n",
      "  Processed 1500/3185... (296.2 req/s)\n",
      "  Processed 2000/3185... (275.2 req/s)\n",
      "  Processed 2500/3185... (263.8 req/s)\n",
      "  Processed 3000/3185... (271.4 req/s)\n",
      "\n",
      "Finished finding paths in 11.83 seconds.\n",
      "\n",
      "--- Pathfinding Summary ---\n",
      "Found results for 3185 ODTs.\n",
      "Total paths found: 8710\n",
      "Average paths per ODT: 2.73 (Target K=5)\n",
      "\n",
      "Example for ODT 'AMS/LAX/1080':\n",
      "  Path 1: Time=1850, Cap=47650.00, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Time=1850, Cap=46000.00, Flights=[25, 1307, 1177, 536]\n",
      "  Path 3: Time=2110, Cap=46000.00, Flights=[25, 1317, 1116]\n",
      "  Path 4: Time=2310, Cap=46000.00, Flights=[24, 1302, 347, 1313, 1846]\n",
      "  Path 5: Time=2345, Cap=46000.00, Flights=[25, 1319, 163, 996]\n"
     ]
    }
   ],
   "source": [
    "# --- Tuned Fast Network Class ---\n",
    "class TunedFastNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins, max_wait_mins, max_total_duration):\n",
    "        print(f\"\\nInitializing Tuned Fast Network (MaxWait={max_wait_mins}, MaxDuration={max_total_duration})...\")\n",
    "        if schedule_df.empty or demand_df.empty: raise ValueError(\"Input data is empty.\")\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "        self.max_wait_mins = max_wait_mins\n",
    "        self.max_total_duration = max_total_duration # New pruning limit\n",
    "\n",
    "        # Lookups\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        for _, row in schedule_df.sort_values(by='dep_time').iterrows():\n",
    "             key = row['ori']; self.flights_by_origin[key]['ids'].append(row['flight_id']); self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # Graph\n",
    "        self.graph = defaultdict(list)\n",
    "        self._build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, elapsed_time, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        if elapsed_time < 0: return\n",
    "        cap = float(capacity) if math.isfinite(capacity) else float('inf')\n",
    "        self.graph[u].append({'neighbor': v, 'weight': float(elapsed_time), 'flight_id': flight_id,'capacity': cap, 'is_flight': is_flight})\n",
    "\n",
    "    def _find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        return idx if idx < len(dep_times_list) else -1\n",
    "\n",
    "    def _build_graph(self):\n",
    "        print(\"Building graph...\")\n",
    "        start_time = timer.time()\n",
    "        # Simplified node types: ('S', odt), ('D', airport), (fid, 'd'), (fid, 'a')\n",
    "\n",
    "        for fid, f in self.flight_data.items(): # Flight Edges\n",
    "            self._add_edge((fid, 'd'), (fid, 'a'), f['arr_time'] - f['dep_time'], fid, f['cap_kg'], True)\n",
    "\n",
    "        for fid, f in self.flight_data.items(): # Connections & Sinks\n",
    "            arr_node, arr_time, arr_apt = (fid, 'a'), f['arr_time'], f['des']\n",
    "            self._add_edge(arr_node, ('D', arr_apt), 0) # Sink Edge\n",
    "            origin_data = self.flights_by_origin.get(arr_apt)\n",
    "            if origin_data:\n",
    "                idx = self._find_first_flight_idx_after(origin_data['dep_times'], arr_time + self.min_connect_mins)\n",
    "                if idx != -1:\n",
    "                    for i in range(idx, len(origin_data['ids'])):\n",
    "                        wait = origin_data['dep_times'][i] - arr_time\n",
    "                        if wait <= self.max_wait_mins: self._add_edge(arr_node, (origin_data['ids'][i], 'd'), wait)\n",
    "                        else: break\n",
    "\n",
    "        for odt, dem in self.demand_details.items(): # Source Edges\n",
    "            origin_data = self.flights_by_origin.get(dem['ori'])\n",
    "            if origin_data:\n",
    "                idx = self._find_first_flight_idx_after(origin_data['dep_times'], dem['time'])\n",
    "                if idx != -1:\n",
    "                    for i in range(idx, len(origin_data['ids'])):\n",
    "                        wait = origin_data['dep_times'][i] - dem['time']\n",
    "                        if wait <= self.max_wait_mins: self._add_edge(('S', odt), (origin_data['ids'][i], 'd'), wait)\n",
    "                        else: break\n",
    "        print(f\"Graph built in {timer.time() - start_time:.2f}s\")\n",
    "\n",
    "\n",
    "    def _a_star(self, start_node, end_node, node_penalties=None, flight_penalties=None):\n",
    "        \"\"\"A* Search incorporating node AND flight penalties + max duration pruning.\"\"\"\n",
    "        global tie_breaker\n",
    "        if node_penalties is None: node_penalties = defaultdict(lambda: 1.0)\n",
    "        if flight_penalties is None: flight_penalties = defaultdict(lambda: 1.0)\n",
    "        heuristic = lambda u, v: 0.0\n",
    "\n",
    "        pq = [(heuristic(start_node, end_node), next(tie_breaker), 0.0, start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_g_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_g_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            f, _, g, curr_node, path = heapq.heappop(pq)\n",
    "\n",
    "            # --- Pruning based on Max Duration ---\n",
    "            if g > self.max_total_duration: continue\n",
    "            # ---\n",
    "\n",
    "            if g > visited_g_costs[curr_node]: continue\n",
    "            if curr_node == end_node: return g, path\n",
    "\n",
    "            if curr_node not in self.graph: continue\n",
    "\n",
    "            current_node_penalty = node_penalties[curr_node]\n",
    "\n",
    "            for edge in self.graph[curr_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                # Combine Node and Flight Penalties\n",
    "                # Penalize based on *current* node and the *specific flight* of the edge (if any)\n",
    "                flight_id = edge['flight_id']\n",
    "                edge_flight_penalty = flight_penalties[flight_id] if flight_id is not None else 1.0\n",
    "                combined_penalty = current_node_penalty * edge_flight_penalty\n",
    "\n",
    "                cost_to_neighbor = edge['weight'] * combined_penalty\n",
    "                new_g = g + cost_to_neighbor\n",
    "\n",
    "                if new_g < visited_g_costs[neighbor]:\n",
    "                    visited_g_costs[neighbor] = new_g\n",
    "                    h = heuristic(neighbor, end_node)\n",
    "                    new_f = new_g + h\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    heapq.heappush(pq, (new_f, next(tie_breaker), new_g, neighbor, path + [new_step]))\n",
    "        return float('inf'), None\n",
    "\n",
    "    def _format_path(self, path_list):\n",
    "        \"\"\"Formats path list, calculates ORIGINAL cost and capacity.\"\"\"\n",
    "        if not path_list: return None\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        total_original_time = 0.0 # Sum original weights\n",
    "        for step in path_list[1:]:\n",
    "            edge = step['edge_info']\n",
    "            if edge:\n",
    "                total_original_time += edge['weight'] # Sum original weights\n",
    "                if edge['is_flight']:\n",
    "                    flight_ids.append(edge['flight_id'])\n",
    "                    min_capacity = min(min_capacity, edge['capacity'])\n",
    "            if isinstance(step['node'], tuple) and step['node'][0] == 'D': break\n",
    "        min_cap = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "        # Return the true duration calculated from original weights\n",
    "        return {'total_time': total_original_time, 'flight_ids': flight_ids, 'min_capacity': min_cap}\n",
    "\n",
    "    def find_k_paths(self, node_penalty=DIVERSITY_NODE_PENALTY, flight_penalty=DIVERSITY_FLIGHT_PENALTY):\n",
    "        \"\"\"Finds K paths using A* and combined node/flight penalization.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} paths (NodePen={node_penalty}, FlightPen={flight_penalty})...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 500 == 0:\n",
    "                elapsed = timer.time() - start_run_time; rate = (i+1)/elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Processed {i+1}/{total_demands}... ({rate:.1f} req/s)\")\n",
    "\n",
    "            start_node = ('S', odt_id)\n",
    "            target_node = ('D', demand['des'])\n",
    "\n",
    "            found_paths_output = [] # Store final formatted paths\n",
    "            node_penalties = defaultdict(lambda: 1.0)\n",
    "            flight_penalties = defaultdict(lambda: 1.0)\n",
    "            found_sequences = set()\n",
    "\n",
    "            for k in range(self.k_paths):\n",
    "                # Pass current penalties to A*\n",
    "                cost_internal, path_list = self._a_star(start_node, target_node, node_penalties, flight_penalties)\n",
    "\n",
    "                if path_list:\n",
    "                    nodes_tuple = tuple(s['node'] for s in path_list)\n",
    "                    if nodes_tuple not in found_sequences:\n",
    "                        # Format using original weights to get true time\n",
    "                        formatted_path = self._format_path(path_list)\n",
    "                        if formatted_path:\n",
    "                            found_paths_output.append(formatted_path)\n",
    "                            found_sequences.add(nodes_tuple)\n",
    "\n",
    "                            # Apply penalties for next iteration\n",
    "                            for step in path_list[1:]:\n",
    "                                node = step['node']\n",
    "                                edge = step['edge_info']\n",
    "                                # Don't penalize source/sink nodes themselves heavily\n",
    "                                if isinstance(node, tuple) and node[0] in ['S', 'D']: continue\n",
    "\n",
    "                                # Penalize intermediate nodes visited\n",
    "                                node_penalties[node] *= node_penalty\n",
    "\n",
    "                                # Penalize specific flight IDs used\n",
    "                                if edge and edge['is_flight']:\n",
    "                                    flight_id = edge['flight_id']\n",
    "                                    flight_penalties[flight_id] *= flight_penalty\n",
    "                        else: break\n",
    "                    else: break\n",
    "                else: break\n",
    "\n",
    "            # Sort the final collected paths by their true total time\n",
    "            found_paths_output.sort(key=lambda p: p['total_time'])\n",
    "            all_results[odt_id] = found_paths_output\n",
    "\n",
    "        print(f\"\\nFinished finding paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting Tuned Fast Flight Path Analysis...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run\n",
    "\n",
    "# Note: Pass the new max_total_duration parameter\n",
    "flight_network = TunedFastNetwork(\n",
    "    schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS,\n",
    "    MAX_CONNECT_WAIT_MINS, MAX_TOTAL_DURATION_MINS\n",
    ")\n",
    "# Use the find_k_paths method\n",
    "k_shortest_paths = flight_network.find_k_paths()\n",
    "\n",
    "# 3. Output Summary\n",
    "print(\"\\n--- Pathfinding Summary ---\")\n",
    "total_paths_found = sum(len(p) for p in k_shortest_paths.values())\n",
    "num_odts = len(k_shortest_paths)\n",
    "avg_paths = total_paths_found / num_odts if num_odts > 0 else 0\n",
    "print(f\"Found results for {num_odts} ODTs.\")\n",
    "print(f\"Total paths found: {total_paths_found}\")\n",
    "print(f\"Average paths per ODT: {avg_paths:.2f} (Target K={K_PATHS})\")\n",
    "\n",
    "# Example ODT output (optional)\n",
    "if num_odts > 0:\n",
    "    example_odt_list = list(k_shortest_paths.keys())\n",
    "    if example_odt_list:\n",
    "        first_odt = example_odt_list[0]\n",
    "        print(f\"\\nExample for ODT '{first_odt}':\")\n",
    "        if k_shortest_paths[first_odt]:\n",
    "            for i, path in enumerate(k_shortest_paths[first_odt]):\n",
    "                print(f\"  Path {i+1}: Time={path['total_time']:.0f}, Cap={path['min_capacity']:.2f}, Flights={path['flight_ids']}\")\n",
    "        else:\n",
    "            print(\"  No paths found for this ODT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fast Flight Path Analysis...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Fast Network (MaxWait=2880 min)...\n",
      "Building graph...\n",
      "Graph built in 0.12s\n",
      "\n",
      "Finding 5 paths per demand (Node Penalty=2)...\n",
      "  Processed 500/3185... (278.7 req/s)\n",
      "  Processed 1000/3185... (308.0 req/s)\n",
      "  Processed 1500/3185... (283.2 req/s)\n",
      "  Processed 2000/3185... (265.0 req/s)\n",
      "  Processed 2500/3185... (254.1 req/s)\n",
      "  Processed 3000/3185... (263.9 req/s)\n",
      "\n",
      "Finished finding paths in 12.18 seconds.\n",
      "\n",
      "--- Pathfinding Summary ---\n",
      "Found results for 3185 ODTs.\n",
      "Total paths found: 9254\n",
      "Average paths per ODT: 2.91 (Target K=5)\n",
      "\n",
      "Example for ODT 'AMS/LAX/1080':\n",
      "  Path 1: Time=1850, Cap=47650.00, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Time=2110, Cap=46000.00, Flights=[25, 1317, 1116]\n",
      "  Path 3: Time=1850, Cap=46000.00, Flights=[25, 1307, 1177, 536]\n",
      "  Path 4: Time=2310, Cap=46000.00, Flights=[24, 1302, 347, 1313, 1846]\n",
      "  Path 5: Time=2345, Cap=46000.00, Flights=[25, 1319, 163, 996]\n"
     ]
    }
   ],
   "source": [
    "# --- Further Simplified Network Class ---\n",
    "class FastFlightNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins, max_wait_mins):\n",
    "        print(f\"\\nInitializing Fast Network (MaxWait={max_wait_mins} min)...\")\n",
    "        if schedule_df.empty or demand_df.empty: raise ValueError(\"Input data is empty.\")\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "        self.max_wait_mins = max_wait_mins\n",
    "\n",
    "        # --- Lookups ---\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        schedule_sorted = schedule_df.sort_values(by='dep_time')\n",
    "        for idx, row in schedule_sorted.iterrows():\n",
    "             key = row['ori']\n",
    "             self.flights_by_origin[key]['ids'].append(row['flight_id'])\n",
    "             self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # --- Graph ---\n",
    "        self.graph = defaultdict(list)\n",
    "        self._build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, elapsed_time, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        if elapsed_time < 0: return\n",
    "        cap = float(capacity) if math.isfinite(capacity) else float('inf')\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v, 'weight': float(elapsed_time), 'flight_id': flight_id,\n",
    "            'capacity': cap, 'is_flight': is_flight\n",
    "        })\n",
    "\n",
    "    def _find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        return idx if idx < len(dep_times_list) else -1\n",
    "\n",
    "    def _build_graph(self):\n",
    "        print(\"Building graph...\")\n",
    "        start_time = timer.time()\n",
    "        # Simplified node types: S=Source, D=DestSink, F=FlightArr/Dep\n",
    "        # ('S', odt), ('D', airport), (fid, 'd'), (fid, 'a')\n",
    "\n",
    "        # 1. Flight Edges (Dep -> Arr)\n",
    "        for fid, f in self.flight_data.items():\n",
    "            self._add_edge((fid, 'd'), (fid, 'a'), f['arr_time'] - f['dep_time'], fid, f['cap_kg'], True)\n",
    "\n",
    "        # 2. Connections & Sinks (Arr -> Dep/Sink)\n",
    "        for fid, f in self.flight_data.items():\n",
    "            arr_node, arr_time, arr_apt = (fid, 'a'), f['arr_time'], f['des']\n",
    "            self._add_edge(arr_node, ('D', arr_apt), 0) # Simplified Sink Edge\n",
    "\n",
    "            origin_data = self.flights_by_origin.get(arr_apt)\n",
    "            if origin_data:\n",
    "                min_dep_time = arr_time + self.min_connect_mins\n",
    "                start_idx = self._find_first_flight_idx_after(origin_data['dep_times'], min_dep_time)\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        wait = origin_data['dep_times'][i] - arr_time\n",
    "                        if wait <= self.max_wait_mins:\n",
    "                            self._add_edge(arr_node, (origin_data['ids'][i], 'd'), wait)\n",
    "                        else: break\n",
    "\n",
    "        # 3. Source Edges (Source -> Dep)\n",
    "        for odt, dem in self.demand_details.items():\n",
    "            source_node = ('S', odt)\n",
    "            origin_data = self.flights_by_origin.get(dem['ori'])\n",
    "            if origin_data:\n",
    "                start_idx = self._find_first_flight_idx_after(origin_data['dep_times'], dem['time'])\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        wait = origin_data['dep_times'][i] - dem['time']\n",
    "                        if wait <= self.max_wait_mins:\n",
    "                             self._add_edge(source_node, (origin_data['ids'][i], 'd'), wait)\n",
    "                        else: break\n",
    "        print(f\"Graph built in {timer.time() - start_time:.2f}s\")\n",
    "\n",
    "\n",
    "    def _heuristic(self, node, target_node):\n",
    "        \"\"\"Simple A* heuristic. Currently 0 (Dijkstra).\"\"\"\n",
    "        # Could estimate hops remaining, but needs target info propagation. Keep 0.\n",
    "        # Heuristic must be based on the *node representation*, not external data easily.\n",
    "        return 0.0 * A_STAR_HEURISTIC_FACTOR # Effectively Dijkstra\n",
    "\n",
    "\n",
    "    def _a_star(self, start_node, end_node, node_penalties=None):\n",
    "        \"\"\"A* Search incorporating node penalties for diversity.\"\"\"\n",
    "        global tie_breaker\n",
    "        if node_penalties is None: node_penalties = defaultdict(lambda: 1.0)\n",
    "\n",
    "        heuristic = self._heuristic\n",
    "        pq = [(heuristic(start_node, end_node), next(tie_breaker), 0.0, start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_g_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_g_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            f, _, g, curr_node, path = heapq.heappop(pq)\n",
    "            if g > visited_g_costs[curr_node]: continue\n",
    "            if curr_node == end_node: return g, path\n",
    "\n",
    "            if curr_node not in self.graph: continue\n",
    "\n",
    "            # Apply penalty for visiting the current node (affects cost to neighbors)\n",
    "            current_node_penalty = node_penalties[curr_node]\n",
    "\n",
    "            for edge in self.graph[curr_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                # Cost includes edge weight PLUS penalty for visiting the *current* node\n",
    "                cost_to_neighbor = edge['weight'] * current_node_penalty\n",
    "                new_g = g + cost_to_neighbor\n",
    "\n",
    "                if new_g < visited_g_costs[neighbor]:\n",
    "                    visited_g_costs[neighbor] = new_g\n",
    "                    h = heuristic(neighbor, end_node)\n",
    "                    new_f = new_g + h\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    heapq.heappush(pq, (new_f, next(tie_breaker), new_g, neighbor, path + [new_step]))\n",
    "        return float('inf'), None\n",
    "\n",
    "\n",
    "    def _format_path(self, path_list):\n",
    "        \"\"\"Formats path list, calculates cost and capacity.\"\"\"\n",
    "        if not path_list: return None\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        total_elapsed_time = 0.0\n",
    "        for step in path_list[1:]:\n",
    "            edge = step['edge_info']\n",
    "            if edge:\n",
    "                total_elapsed_time += edge['weight'] # Sum original weights for true time\n",
    "                if edge['is_flight']:\n",
    "                    flight_ids.append(edge['flight_id'])\n",
    "                    min_capacity = min(min_capacity, edge['capacity'])\n",
    "            # Stop if we hit the conceptual sink\n",
    "            if isinstance(step['node'], tuple) and step['node'][0] == 'D':\n",
    "                 break\n",
    "        min_cap = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "        return {'total_time': total_elapsed_time, 'flight_ids': flight_ids, 'min_capacity': min_cap}\n",
    "\n",
    "\n",
    "    def find_k_paths(self, node_penalty_factor=DIVERSITY_NODE_PENALTY):\n",
    "        \"\"\"Finds K paths using A* and node penalization heuristic for diversity.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} paths per demand (Node Penalty={node_penalty_factor})...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 500 == 0:\n",
    "                elapsed = timer.time() - start_run_time; rate = (i+1)/elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Processed {i+1}/{total_demands}... ({rate:.1f} req/s)\")\n",
    "\n",
    "            start_node = ('S', odt_id)\n",
    "            target_node = ('D', demand['des']) # Use simplified destination sink\n",
    "\n",
    "            found_paths = []\n",
    "            # Node penalties accumulate over the K iterations for this ODT\n",
    "            node_penalties = defaultdict(lambda: 1.0)\n",
    "            found_sequences = set()\n",
    "\n",
    "            for k in range(self.k_paths):\n",
    "                # Pass current node penalties to A*\n",
    "                cost, path_list = self._a_star(start_node, target_node, node_penalties)\n",
    "\n",
    "                if path_list:\n",
    "                    nodes_tuple = tuple(s['node'] for s in path_list)\n",
    "                    if nodes_tuple not in found_sequences:\n",
    "                        # Format uses original weights to get true time\n",
    "                        formatted_path = self._format_path(path_list)\n",
    "                        if formatted_path:\n",
    "                            found_paths.append(formatted_path) # Store formatted path\n",
    "                            found_sequences.add(nodes_tuple)\n",
    "\n",
    "                            # Apply node penalties for next iteration\n",
    "                            for step in path_list[1:]: # Don't penalize source\n",
    "                                node = step['node']\n",
    "                                # Penalize flight arrival/departure nodes and potentially sinks\n",
    "                                if isinstance(node, tuple) and node[0] in ['D']: continue # Maybe don't penalize final sink\n",
    "                                if isinstance(node, int) or (isinstance(node, tuple) and node[0] != 'S'):\n",
    "                                     node_penalties[node] *= node_penalty_factor\n",
    "                        else: break # Formatting failed?\n",
    "                    else: break # Duplicate sequence found\n",
    "                else: break # No more paths found\n",
    "\n",
    "            all_results[odt_id] = found_paths # Already formatted\n",
    "\n",
    "        print(f\"\\nFinished finding paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting Fast Flight Path Analysis...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run\n",
    "\n",
    "flight_network = FastFlightNetwork(\n",
    "    schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS, MAX_CONNECT_WAIT_MINS\n",
    ")\n",
    "k_shortest_paths = flight_network.find_k_paths()\n",
    "\n",
    "# 3. Output Summary\n",
    "print(\"\\n--- Pathfinding Summary ---\")\n",
    "total_paths_found = sum(len(p) for p in k_shortest_paths.values())\n",
    "num_odts = len(k_shortest_paths)\n",
    "avg_paths = total_paths_found / num_odts if num_odts > 0 else 0\n",
    "print(f\"Found results for {num_odts} ODTs.\")\n",
    "print(f\"Total paths found: {total_paths_found}\")\n",
    "print(f\"Average paths per ODT: {avg_paths:.2f} (Target K={K_PATHS})\")\n",
    "\n",
    "# Example ODT output (optional)\n",
    "if num_odts > 0:\n",
    "    first_odt = list(k_shortest_paths.keys())[0]\n",
    "    print(f\"\\nExample for ODT '{first_odt}':\")\n",
    "    if k_shortest_paths[first_odt]:\n",
    "        for i, path in enumerate(k_shortest_paths[first_odt]):\n",
    "                print(f\"  Path {i+1}: Time={path['total_time']:.0f}, Cap={path['min_capacity']:.2f}, Flights={path['flight_ids']}\")\n",
    "    else:\n",
    "        print(\"  No paths found for this ODT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Simplified Flight Path Analysis...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Simplified Network (MaxWait=2880 min)...\n",
      "Building simplified graph...\n",
      "Graph building completed in 0.08 seconds.\n",
      "\n",
      "Finding 3 paths per demand (Heuristic Method)...\n",
      "  Processed 500/3185... (597.7 req/s)\n",
      "  Processed 1000/3185... (645.9 req/s)\n",
      "  Processed 1500/3185... (559.7 req/s)\n",
      "  Processed 2000/3185... (505.4 req/s)\n",
      "  Processed 2500/3185... (479.7 req/s)\n",
      "  Processed 3000/3185... (504.3 req/s)\n",
      "\n",
      "Finished finding paths in 6.38 seconds.\n",
      "\n",
      "--- Pathfinding Summary ---\n",
      "Found results for 3185 ODTs.\n",
      "Total paths found: 5226\n",
      "Average paths per ODT: 1.64 (Target K=3)\n",
      "\n",
      "Example for ODT 'AMS/LAX/1080':\n",
      "  Path 1: Time=1850, Cap=47650.00, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Time=1853, Cap=46000.00, Flights=[25, 1307, 1177, 536]\n",
      "  Path 3: Time=1869, Cap=47650.00, Flights=[24, 1307, 1177, 536]\n"
     ]
    }
   ],
   "source": [
    "# --- Simplified Network Class ---\n",
    "class SimpleFlightNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins, max_wait_mins):\n",
    "        print(f\"\\nInitializing Simplified Network (MaxWait={max_wait_mins} min)...\")\n",
    "        if schedule_df.empty or demand_df.empty: raise ValueError(\"Input data is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "        self.max_wait_mins = max_wait_mins\n",
    "\n",
    "        # --- Essential Lookups ---\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "        # Flights grouped by origin, containing sorted lists of IDs and departure times\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        schedule_sorted = schedule_df.sort_values(by='dep_time')\n",
    "        for idx, row in schedule_sorted.iterrows():\n",
    "             key = row['ori']\n",
    "             self.flights_by_origin[key]['ids'].append(row['flight_id'])\n",
    "             self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # --- Graph Representation ---\n",
    "        self.graph = defaultdict(list)\n",
    "        self._build_graph() # Underscore indicates intended private use\n",
    "\n",
    "    def _add_edge(self, u, v, elapsed_time, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        \"\"\"Adds edge to the graph.\"\"\"\n",
    "        if elapsed_time < 0: return\n",
    "        cap = float(capacity) if math.isfinite(capacity) else float('inf')\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v, 'weight': float(elapsed_time), 'flight_id': flight_id,\n",
    "            'capacity': cap, 'is_flight': is_flight\n",
    "        })\n",
    "\n",
    "    def _find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        \"\"\"Finds index using bisect_left.\"\"\"\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        return idx if idx < len(dep_times_list) else -1\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"Builds pruned time-expanded graph with destination sinks.\"\"\"\n",
    "        print(\"Building simplified graph...\")\n",
    "        start_time = timer.time()\n",
    "        # Node Types: ('source', odt), (flight_id, 'dep'), (flight_id, 'arr'), ('dest_sink', airport)\n",
    "\n",
    "        # 1. Flight Edges (Dep -> Arr)\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            self._add_edge((flight_id, 'dep'), (flight_id, 'arr'), flight['arr_time'] - flight['dep_time'],\n",
    "                           flight_id, flight['cap_kg'], True)\n",
    "\n",
    "        # 2. Connection (Arr -> Dep) and Sink (Arr -> Dest_Sink) Edges\n",
    "        for flight1_id, flight1 in self.flight_data.items():\n",
    "            arrival_node = (flight1_id, 'arr')\n",
    "            arrival_time = flight1['arr_time']\n",
    "            arrival_airport = flight1['des']\n",
    "\n",
    "            # a) Destination Sink Edge (Arr -> Dest_Sink)\n",
    "            self._add_edge(arrival_node, ('dest_sink', arrival_airport), 0)\n",
    "\n",
    "            # b) Connection Edges (Arr -> Dep) with pruning\n",
    "            origin_data = self.flights_by_origin.get(arrival_airport)\n",
    "            if origin_data:\n",
    "                min_dep_time = arrival_time + self.min_connect_mins\n",
    "                start_idx = self._find_first_flight_idx_after(origin_data['dep_times'], min_dep_time)\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        wait_time = origin_data['dep_times'][i] - arrival_time\n",
    "                        if wait_time <= self.max_wait_mins: # Pruning\n",
    "                            self._add_edge(arrival_node, (origin_data['ids'][i], 'dep'), wait_time)\n",
    "                        else: break\n",
    "\n",
    "        # 3. Source Edges (Source -> Dep) with pruning\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            origin_data = self.flights_by_origin.get(demand['ori'])\n",
    "            if origin_data:\n",
    "                start_idx = self._find_first_flight_idx_after(origin_data['dep_times'], demand['time'])\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        initial_wait = origin_data['dep_times'][i] - demand['time']\n",
    "                        if initial_wait <= self.max_wait_mins: # Pruning\n",
    "                             self._add_edge(source_node, (origin_data['ids'][i], 'dep'), initial_wait)\n",
    "                        else: break\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    def _a_star(self, start_node, end_node, edge_penalties=None):\n",
    "        \"\"\"A* Search (heuristic=0 -> Dijkstra). Returns (cost, path_list).\"\"\"\n",
    "        global tie_breaker\n",
    "        if edge_penalties is None: edge_penalties = {}\n",
    "        heuristic = lambda u, v: 0.0 # Simple heuristic (Dijkstra)\n",
    "\n",
    "        pq = [(heuristic(start_node, end_node), next(tie_breaker), 0.0, start_node, [{'node': start_node, 'edge_info': None}])] # f, tie, g, node, path\n",
    "        visited_g_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_g_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            f, _, g, curr_node, path = heapq.heappop(pq)\n",
    "            if g > visited_g_costs[curr_node]: continue\n",
    "            if curr_node == end_node: return g, path # Return actual cost g\n",
    "\n",
    "            if curr_node not in self.graph: continue\n",
    "            for edge in self.graph[curr_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                edge_rep = (curr_node, neighbor, edge['flight_id'])\n",
    "                penalty = edge_penalties.get(edge_rep, 1.0)\n",
    "                penalized_cost = edge['weight'] * penalty\n",
    "                new_g = g + penalized_cost\n",
    "\n",
    "                if new_g < visited_g_costs[neighbor]:\n",
    "                    visited_g_costs[neighbor] = new_g\n",
    "                    h = heuristic(neighbor, end_node)\n",
    "                    new_f = new_g + h\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    heapq.heappush(pq, (new_f, next(tie_breaker), new_g, neighbor, path + [new_step]))\n",
    "        return float('inf'), None\n",
    "\n",
    "    def _format_path(self, path_list, total_elapsed_time):\n",
    "        \"\"\"Formats path list into desired output.\"\"\"\n",
    "        if not path_list: return None\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        for step in path_list[1:]:\n",
    "            if isinstance(step['node'], tuple) and step['node'][0] == 'dest_sink': break\n",
    "            edge = step['edge_info']\n",
    "            if edge and edge['is_flight']:\n",
    "                flight_ids.append(edge['flight_id'])\n",
    "                min_capacity = min(min_capacity, edge['capacity'])\n",
    "        min_cap = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "        return {'total_time': total_elapsed_time, 'flight_ids': flight_ids, 'min_capacity': min_cap}\n",
    "\n",
    "    def find_k_paths(self, penalty_factor=1.01):\n",
    "        \"\"\"Finds K paths using A* and edge penalization heuristic.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} paths per demand (Heuristic Method)...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 500 == 0: # Progress update\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Processed {i+1}/{total_demands}... ({rate:.1f} req/s)\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            target_node = ('dest_sink', demand['des'])\n",
    "            found_paths = []\n",
    "            edge_penalties = {}\n",
    "            found_sequences = set()\n",
    "\n",
    "            for k in range(self.k_paths):\n",
    "                cost, path_list = self._a_star(start_node, target_node, edge_penalties)\n",
    "                if path_list:\n",
    "                    nodes_tuple = tuple(s['node'] for s in path_list)\n",
    "                    if nodes_tuple not in found_sequences:\n",
    "                        found_paths.append((cost, path_list))\n",
    "                        found_sequences.add(nodes_tuple)\n",
    "                        # Apply penalties\n",
    "                        for step_idx in range(1, len(path_list)):\n",
    "                            edge = path_list[step_idx]['edge_info']\n",
    "                            if edge:\n",
    "                                u, v, f_id = path_list[step_idx-1]['node'], path_list[step_idx]['node'], edge['flight_id']\n",
    "                                edge_rep = (u, v, f_id)\n",
    "                                edge_penalties[edge_rep] = edge_penalties.get(edge_rep, 1.0) * penalty_factor\n",
    "                    else: break # Duplicate found, stop for this ODT\n",
    "                else: break # No more paths found\n",
    "\n",
    "            # Format results\n",
    "            formatted = []\n",
    "            found_paths.sort(key=lambda x: x[0])\n",
    "            for cost, p_list in found_paths:\n",
    "                 fmt = self._format_path(p_list, cost)\n",
    "                 if fmt: formatted.append(fmt)\n",
    "            all_results[odt_id] = formatted\n",
    "\n",
    "        print(f\"\\nFinished finding paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting Simplified Flight Path Analysis...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run\n",
    "\n",
    "flight_network = SimpleFlightNetwork(\n",
    "    schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS, MAX_CONNECT_WAIT_MINS\n",
    ")\n",
    "k_shortest_paths = flight_network.find_k_paths() # Renamed method slightly\n",
    "\n",
    "# 3. Output Summary\n",
    "print(\"\\n--- Pathfinding Summary ---\")\n",
    "total_paths_found = sum(len(p) for p in k_shortest_paths.values())\n",
    "num_odts = len(k_shortest_paths)\n",
    "avg_paths = total_paths_found / num_odts if num_odts > 0 else 0\n",
    "print(f\"Found results for {num_odts} ODTs.\")\n",
    "print(f\"Total paths found: {total_paths_found}\")\n",
    "print(f\"Average paths per ODT: {avg_paths:.2f} (Target K={K_PATHS})\")\n",
    "\n",
    "# Example output for one ODT (optional)\n",
    "first_odt = list(k_shortest_paths.keys())[0]\n",
    "print(f\"\\nExample for ODT '{first_odt}':\")\n",
    "for i, path in enumerate(k_shortest_paths[first_odt]):\n",
    "     print(f\"  Path {i+1}: Time={path['total_time']:.0f}, Cap={path['min_capacity']:.2f}, Flights={path['flight_ids']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight path analysis (Destination Sink + Heuristic KSP)...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Network with Destination Sinks (MaxWait=2880 min)...\n",
      "Precomputing lookups...\n",
      "Building graph with destination sinks...\n",
      "Graph building completed in 0.12 seconds.\n",
      "Graph nodes estimated around: 7376\n",
      "Edge Counts: Flight=2057, Conn=52153, Sink=2057, Source=52686\n",
      "\n",
      "Finding 3 shortest paths (Dest Sink Heuristic, Penalty=1.01)...\n",
      "  Processed 500/3185 demands... Elapsed: 0.8s (596.0 req/s)\n",
      "  Processed 1000/3185 demands... Elapsed: 1.6s (629.2 req/s)\n",
      "  Processed 1500/3185 demands... Elapsed: 2.8s (540.5 req/s)\n",
      "  Processed 2000/3185 demands... Elapsed: 4.1s (487.2 req/s)\n",
      "  Processed 2500/3185 demands... Elapsed: 5.5s (457.8 req/s)\n",
      "  Processed 3000/3185 demands... Elapsed: 6.2s (485.8 req/s)\n",
      "\n",
      "Finished finding K shortest paths (Dest Sink Heuristic) in 6.61 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample - Dest Sink Heuristic) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Total Time=1853 min, Min Capacity=46000.00 kg, Flights=[25, 1307, 1177, 536]\n",
      "  Path 3: Total Time=1869 min, Min Capacity=47650.00 kg, Flights=[24, 1307, 1177, 536]\n",
      "---------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1: Total Time=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902]\n",
      "  Path 2: Total Time=1666 min, Min Capacity=46000.00 kg, Flights=[26, 1376, 902]\n",
      "---------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612]\n",
      "  Path 2: Total Time=1853 min, Min Capacity=46000.00 kg, Flights=[28, 1391, 1189, 612]\n",
      "  Path 3: Total Time=1869 min, Min Capacity=46000.00 kg, Flights=[30, 1391, 1189, 612]\n",
      "---------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1: Total Time=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884]\n",
      "  Path 2: Total Time=2239 min, Min Capacity=46000.00 kg, Flights=[32, 1460, 914, 1884]\n",
      "  Path 3: Total Time=2251 min, Min Capacity=47650.00 kg, Flights=[31, 1446, 914, 1884]\n",
      "---------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1: Total Time=2075 min, Min Capacity=46000.00 kg, Flights=[34, 1486, 925]\n",
      "---------------\n",
      "\n",
      "... (output truncated) ...\n",
      "\n",
      "Found path results for 3185 ODTs (Average 1.64 paths/ODT).\n",
      "NOTE: Average paths found is less than K=3. This can happen with pruning or the heuristic KSP method.\n"
     ]
    }
   ],
   "source": [
    "# --- Network with Destination Sinks & Heuristic KSP ---\n",
    "class FlightNetworkDestSinkHeuristic:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins, max_wait_mins):\n",
    "        print(f\"\\nInitializing Network with Destination Sinks (MaxWait={max_wait_mins} min)...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "             raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "        self.max_wait_mins = max_wait_mins\n",
    "\n",
    "        print(\"Precomputing lookups...\")\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        schedule_sorted = schedule_df.sort_values(by='dep_time')\n",
    "        for idx, row in schedule_sorted.iterrows():\n",
    "             key = row['ori']\n",
    "             self.flights_by_origin[key]['ids'].append(row['flight_id'])\n",
    "             self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # Get list of unique destination airports in demands\n",
    "        self.destination_airports = demand_df['des'].unique()\n",
    "\n",
    "        # Graph Representation (Forward only needed for A*)\n",
    "        self.graph = defaultdict(list)\n",
    "        self.build_graph()\n",
    "\n",
    "    def find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        return idx if idx < len(dep_times_list) else -1\n",
    "\n",
    "    def _add_edge(self, u, v, elapsed_time, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        \"\"\"Adds edge to the forward graph.\"\"\"\n",
    "        if elapsed_time < 0: return\n",
    "        cap = float(capacity) if isinstance(capacity, (int, float)) and math.isfinite(capacity) else float('inf')\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v, 'weight': float(elapsed_time), 'flight_id': flight_id,\n",
    "            'capacity': cap, 'is_flight': is_flight\n",
    "        })\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds pruned time-expanded graph with destination sinks.\"\"\"\n",
    "        print(\"Building graph with destination sinks...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # Node Types:\n",
    "        # ('source', odt_str)\n",
    "        # (flight_id_int, 'dep')\n",
    "        # (flight_id_int, 'arr')\n",
    "        # ('dest_sink', airport_str) # NEW SINK TYPE\n",
    "\n",
    "        # 1. Flight Edges (Dep -> Arr)\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            duration = flight['arr_time'] - flight['dep_time']\n",
    "            self._add_edge((flight_id, 'dep'), (flight_id, 'arr'), duration, flight_id, flight['cap_kg'], True)\n",
    "\n",
    "        # 2. Connection (Arr -> Dep) and Sink (Arr -> Dest_Sink) Edges\n",
    "        connection_edge_count = 0\n",
    "        sink_edge_count = 0\n",
    "        for flight1_id, flight1 in self.flight_data.items():\n",
    "            arrival_node = (flight1_id, 'arr')\n",
    "            arrival_time = flight1['arr_time']\n",
    "            arrival_airport = flight1['des']\n",
    "\n",
    "            # a) Destination Sink Edge (Arr -> Dest_Sink, weight 0)\n",
    "            # Only one edge per arriving flight to its destination airport sink\n",
    "            dest_sink_node = ('dest_sink', arrival_airport)\n",
    "            self._add_edge(arrival_node, dest_sink_node, 0)\n",
    "            sink_edge_count += 1\n",
    "\n",
    "            # b) Connection Edges (Arr -> Dep)\n",
    "            origin_data = self.flights_by_origin.get(arrival_airport)\n",
    "            if origin_data:\n",
    "                min_dep_time = arrival_time + self.min_connect_mins\n",
    "                start_idx = self.find_first_flight_idx_after(origin_data['dep_times'], min_dep_time)\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        flight2_id = origin_data['ids'][i]\n",
    "                        flight2_dep_time = origin_data['dep_times'][i]\n",
    "                        wait_time = flight2_dep_time - arrival_time\n",
    "                        if wait_time <= self.max_wait_mins: # PRUNING\n",
    "                            self._add_edge(arrival_node, (flight2_id, 'dep'), wait_time)\n",
    "                            connection_edge_count += 1\n",
    "                        else: break # Pruning based on wait time\n",
    "\n",
    "        # 3. Source Edges (Source -> Dep)\n",
    "        source_edge_count = 0\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            origin_airport = demand['ori']\n",
    "            ready_time = demand['time']\n",
    "            origin_data = self.flights_by_origin.get(origin_airport)\n",
    "            if origin_data:\n",
    "                start_idx = self.find_first_flight_idx_after(origin_data['dep_times'], ready_time)\n",
    "                if start_idx != -1:\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        flight_id = origin_data['ids'][i]\n",
    "                        flight_dep_time = origin_data['dep_times'][i]\n",
    "                        initial_wait = flight_dep_time - ready_time\n",
    "                        if initial_wait <= self.max_wait_mins: # PRUNING\n",
    "                            self._add_edge(source_node, (flight_id, 'dep'), initial_wait)\n",
    "                            source_edge_count += 1\n",
    "                        else: break # Pruning based on wait time\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "        # Node count estimate: |Sources| + |Airports| + 2 * |Flights|\n",
    "        est_nodes = len(self.demand_details) + len(self.destination_airports) + len(self.flight_data) * 2\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "        print(f\"Edge Counts: Flight={len(self.flight_data)}, Conn={connection_edge_count}, Sink={sink_edge_count}, Source={source_edge_count}\")\n",
    "        if sink_edge_count != len(self.flight_data):\n",
    "             print(\"Warning: Sink edge count doesn't match flight count. Check logic.\")\n",
    "\n",
    "\n",
    "    def _a_star(self, start_node, end_node, heuristic=lambda u, v: 0, edge_penalties=None):\n",
    "        \"\"\"A* Search. Returns (cost, path_list).\"\"\"\n",
    "        # (Same as previous version)\n",
    "        global tie_breaker\n",
    "        if edge_penalties is None: edge_penalties = {}\n",
    "        g_cost_start = 0.0\n",
    "        h_cost_start = heuristic(start_node, end_node)\n",
    "        f_cost_start = g_cost_start + h_cost_start\n",
    "        pq = [(f_cost_start, next(tie_breaker), g_cost_start, start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_g_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_g_costs[start_node] = g_cost_start\n",
    "\n",
    "        while pq:\n",
    "            f_cost, _, g_cost, current_node, path_list = heapq.heappop(pq)\n",
    "            if g_cost > visited_g_costs[current_node]: continue\n",
    "            if current_node == end_node: return g_cost, path_list\n",
    "\n",
    "            if current_node not in self.graph: continue\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                edge_elapsed_time = edge['weight']\n",
    "                flight_id = edge['flight_id']\n",
    "                edge_rep = (current_node, neighbor, flight_id)\n",
    "                penalty_factor = edge_penalties.get(edge_rep, 1.0)\n",
    "                penalized_edge_time = edge_elapsed_time * penalty_factor\n",
    "                new_g_cost = g_cost + penalized_edge_time\n",
    "\n",
    "                if new_g_cost < visited_g_costs[neighbor]:\n",
    "                    visited_g_costs[neighbor] = new_g_cost\n",
    "                    h_cost_neighbor = heuristic(neighbor, end_node)\n",
    "                    new_f_cost = new_g_cost + h_cost_neighbor\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    new_path = path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_f_cost, next(tie_breaker), new_g_cost, neighbor, new_path))\n",
    "        return float('inf'), None\n",
    "\n",
    "    def _format_path(self, path_list, total_elapsed_time):\n",
    "        \"\"\"Formats path list into desired output.\"\"\"\n",
    "        # (Same as previous correct version)\n",
    "        if not path_list or len(path_list) < 2: return None\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        for step in path_list[1:]:\n",
    "            edge = step['edge_info']\n",
    "            # Stop processing if we hit the destination sink node\n",
    "            if isinstance(step['node'], tuple) and step['node'][0] == 'dest_sink':\n",
    "                break\n",
    "            if edge and edge['is_flight']:\n",
    "                flight_ids.append(edge['flight_id'])\n",
    "                min_capacity = min(min_capacity, edge['capacity'])\n",
    "        min_cap_final = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "        return {'total_time': total_elapsed_time, 'flight_ids': flight_ids, 'min_capacity': min_cap_final}\n",
    "\n",
    "    def find_k_shortest_paths_heuristic(self, penalty_factor=1.01):\n",
    "        \"\"\"Finds K shortest paths using A* and edge penalization heuristic with destination sinks.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths (Dest Sink Heuristic, Penalty={penalty_factor})...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "        heuristic = lambda u, v: 0.0 # Simple Dijkstra-like heuristic\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 500 == 0:\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Processed {i+1}/{total_demands} demands... Elapsed: {elapsed:.1f}s ({rate:.1f} req/s)\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            # TARGET is now the destination airport sink\n",
    "            target_node = ('dest_sink', demand['des'])\n",
    "\n",
    "            found_paths_for_odt = [] # Stores (actual_cost, path_list)\n",
    "            edge_penalties = {}\n",
    "            found_path_node_sequences = set() # Track sequences to avoid duplicates\n",
    "\n",
    "            for k in range(self.k_paths):\n",
    "                actual_cost, path_list = self._a_star(start_node, target_node, heuristic, edge_penalties)\n",
    "\n",
    "                if path_list:\n",
    "                    nodes_tuple = tuple(s['node'] for s in path_list)\n",
    "                    if nodes_tuple not in found_path_node_sequences:\n",
    "                        found_paths_for_odt.append((actual_cost, path_list))\n",
    "                        found_path_node_sequences.add(nodes_tuple) # Cache it\n",
    "\n",
    "                        # Apply penalties for next iteration\n",
    "                        for step_idx in range(1, len(path_list)):\n",
    "                            edge = path_list[step_idx]['edge_info']\n",
    "                            if edge:\n",
    "                                u = path_list[step_idx-1]['node']\n",
    "                                v = path_list[step_idx]['node']\n",
    "                                f_id = edge['flight_id']\n",
    "                                edge_rep = (u, v, f_id)\n",
    "                                edge_penalties[edge_rep] = edge_penalties.get(edge_rep, 1.0) * penalty_factor\n",
    "                    else:\n",
    "                         # Found a duplicate path sequence, stop for this ODT\n",
    "                         # print(f\"  WARN: Duplicate path seq found for ODT {odt_id} at k={k+1}, stopping.\")\n",
    "                         break\n",
    "                else:\n",
    "                    break # No more paths found\n",
    "\n",
    "            # Format results for this ODT\n",
    "            formatted_paths = []\n",
    "            found_paths_for_odt.sort(key=lambda x: x[0]) # Sort by actual cost\n",
    "            for cost, path_list in found_paths_for_odt:\n",
    "                 formatted = self._format_path(path_list, cost)\n",
    "                 if formatted: formatted_paths.append(formatted)\n",
    "            all_results[odt_id] = formatted_paths # Store results for this ODT\n",
    "\n",
    "        print(f\"\\nFinished finding K shortest paths (Dest Sink Heuristic) in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting flight path analysis (Destination Sink + Heuristic KSP)...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run only if data is valid\n",
    "if not schedule_data.empty and not demand_data.empty:\n",
    "    try:\n",
    "        flight_network = FlightNetworkDestSinkHeuristic(\n",
    "            schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS, MAX_CONNECT_WAIT_MINS\n",
    "        )\n",
    "        k_shortest_paths = flight_network.find_k_shortest_paths_heuristic()\n",
    "\n",
    "        # 3. Output Sample Results\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample - Dest Sink Heuristic) ---\")\n",
    "        output_count = 0\n",
    "        total_paths_found_count = 0\n",
    "        for odt, paths in k_shortest_paths.items():\n",
    "            total_paths_found_count += len(paths)\n",
    "            if output_count < 5:\n",
    "                demand_info = flight_network.demand_details.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        print(f\"  Path {i+1}: Total Time={path['total_time']:.0f} min, Min Capacity={path['min_capacity']:.2f} kg, Flights={path['flight_ids']}\")\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 15)\n",
    "            elif output_count == 5:\n",
    "                 print(\"\\n... (output truncated) ...\")\n",
    "            output_count += 1\n",
    "\n",
    "        avg_paths = total_paths_found_count / len(k_shortest_paths) if k_shortest_paths else 0\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths)} ODTs (Average {avg_paths:.2f} paths/ODT).\")\n",
    "        if avg_paths < K_PATHS:\n",
    "            print(f\"NOTE: Average paths found is less than K={K_PATHS}. This can happen with pruning or the heuristic KSP method.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nError: Could not read valid schedule or demand data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight path analysis (Efficient Time-Expanded Model)...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Efficient Time-Expanded Flight Network...\n",
      "Precomputing lookups...\n",
      "Building time-expanded graph...\n",
      "Graph building completed in 0.32 seconds.\n",
      "Graph nodes estimated around: 10484\n",
      "Edge Counts: Flight=2057, Connection=96571, Sink=121331, Source=99076\n",
      "\n",
      "Finding 3 shortest paths...\n",
      "  Processed 50/3185 demands... Elapsed: 1.3s (39.2 req/s)\n",
      "  Processed 100/3185 demands... Elapsed: 2.4s (41.2 req/s)\n",
      "  Processed 150/3185 demands... Elapsed: 3.6s (41.9 req/s)\n",
      "  Processed 200/3185 demands... Elapsed: 5.4s (36.8 req/s)\n",
      "  Processed 250/3185 demands... Elapsed: 6.9s (36.1 req/s)\n",
      "  Processed 300/3185 demands... Elapsed: 8.2s (36.5 req/s)\n",
      "  Processed 350/3185 demands... Elapsed: 10.0s (34.8 req/s)\n",
      "  Processed 400/3185 demands... Elapsed: 11.5s (34.9 req/s)\n",
      "  Processed 450/3185 demands... Elapsed: 14.0s (32.1 req/s)\n",
      "  Processed 500/3185 demands... Elapsed: 15.8s (31.6 req/s)\n",
      "  Processed 550/3185 demands... Elapsed: 17.6s (31.2 req/s)\n",
      "  Processed 600/3185 demands... Elapsed: 18.5s (32.4 req/s)\n",
      "  Processed 650/3185 demands... Elapsed: 19.9s (32.6 req/s)\n",
      "  Processed 700/3185 demands... Elapsed: 21.7s (32.3 req/s)\n",
      "  Processed 750/3185 demands... Elapsed: 23.7s (31.7 req/s)\n",
      "  Processed 800/3185 demands... Elapsed: 25.7s (31.1 req/s)\n",
      "  Processed 850/3185 demands... Elapsed: 26.2s (32.5 req/s)\n",
      "  Processed 900/3185 demands... Elapsed: 26.4s (34.0 req/s)\n",
      "  Processed 950/3185 demands... Elapsed: 27.0s (35.2 req/s)\n",
      "  Processed 1000/3185 demands... Elapsed: 27.3s (36.6 req/s)\n",
      "  Processed 1050/3185 demands... Elapsed: 27.7s (38.0 req/s)\n",
      "  Processed 1100/3185 demands... Elapsed: 28.4s (38.8 req/s)\n",
      "  Processed 1150/3185 demands... Elapsed: 29.4s (39.1 req/s)\n",
      "  Processed 1200/3185 demands... Elapsed: 31.3s (38.3 req/s)\n",
      "  Processed 1250/3185 demands... Elapsed: 33.9s (36.8 req/s)\n",
      "  Processed 1300/3185 demands... Elapsed: 36.6s (35.6 req/s)\n",
      "  Processed 1350/3185 demands... Elapsed: 38.1s (35.4 req/s)\n",
      "  Processed 1400/3185 demands... Elapsed: 41.2s (34.0 req/s)\n",
      "  Processed 1450/3185 demands... Elapsed: 43.4s (33.4 req/s)\n",
      "  Processed 1500/3185 demands... Elapsed: 46.3s (32.4 req/s)\n",
      "  Processed 1550/3185 demands... Elapsed: 48.2s (32.2 req/s)\n",
      "  Processed 1600/3185 demands... Elapsed: 49.8s (32.1 req/s)\n",
      "  Processed 1650/3185 demands... Elapsed: 51.6s (32.0 req/s)\n",
      "  Processed 1700/3185 demands... Elapsed: 54.5s (31.2 req/s)\n",
      "  Processed 1750/3185 demands... Elapsed: 56.4s (31.0 req/s)\n",
      "  Processed 1800/3185 demands... Elapsed: 59.4s (30.3 req/s)\n",
      "  Processed 1850/3185 demands... Elapsed: 62.4s (29.7 req/s)\n",
      "  Processed 1900/3185 demands... Elapsed: 65.5s (29.0 req/s)\n",
      "  Processed 1950/3185 demands... Elapsed: 68.0s (28.7 req/s)\n",
      "  Processed 2000/3185 demands... Elapsed: 70.6s (28.3 req/s)\n",
      "  Processed 2050/3185 demands... Elapsed: 71.7s (28.6 req/s)\n",
      "  Processed 2100/3185 demands... Elapsed: 74.1s (28.3 req/s)\n",
      "  Processed 2150/3185 demands... Elapsed: 76.7s (28.0 req/s)\n",
      "  Processed 2200/3185 demands... Elapsed: 79.5s (27.7 req/s)\n",
      "  Processed 2250/3185 demands... Elapsed: 82.5s (27.3 req/s)\n",
      "  Processed 2300/3185 demands... Elapsed: 86.8s (26.5 req/s)\n",
      "  Processed 2350/3185 demands... Elapsed: 88.9s (26.4 req/s)\n",
      "  Processed 2400/3185 demands... Elapsed: 90.2s (26.6 req/s)\n",
      "  Processed 2450/3185 demands... Elapsed: 93.1s (26.3 req/s)\n",
      "  Processed 2500/3185 demands... Elapsed: 95.3s (26.2 req/s)\n",
      "  Processed 2550/3185 demands... Elapsed: 97.5s (26.2 req/s)\n",
      "  Processed 2600/3185 demands... Elapsed: 98.5s (26.4 req/s)\n",
      "  Processed 2650/3185 demands... Elapsed: 100.0s (26.5 req/s)\n",
      "  Processed 2700/3185 demands... Elapsed: 100.9s (26.8 req/s)\n",
      "  Processed 2750/3185 demands... Elapsed: 102.3s (26.9 req/s)\n",
      "  Processed 2800/3185 demands... Elapsed: 103.5s (27.0 req/s)\n",
      "  Processed 2850/3185 demands... Elapsed: 105.4s (27.0 req/s)\n",
      "  Processed 2900/3185 demands... Elapsed: 106.7s (27.2 req/s)\n",
      "  Processed 2950/3185 demands... Elapsed: 108.4s (27.2 req/s)\n",
      "  Processed 3000/3185 demands... Elapsed: 109.8s (27.3 req/s)\n",
      "  Processed 3050/3185 demands... Elapsed: 111.4s (27.4 req/s)\n",
      "  Processed 3100/3185 demands... Elapsed: 113.5s (27.3 req/s)\n",
      "  Processed 3150/3185 demands... Elapsed: 116.0s (27.2 req/s)\n",
      "\n",
      "Finished finding K shortest paths in 118.25 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[25, 1306, 1685, 536]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[25, 1307, 1177, 536]\n",
      "---------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1: Total Time=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902]\n",
      "  Path 2: Total Time=1655 min, Min Capacity=46000.00 kg, Flights=[26, 1376, 902]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[26, 1347, 1694, 575]\n",
      "---------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612]\n",
      "  Path 2: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[28, 1390, 1703, 612]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[28, 1391, 1189, 612]\n",
      "---------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1: Total Time=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884]\n",
      "  Path 2: Total Time=2230 min, Min Capacity=46000.00 kg, Flights=[32, 1447, 914, 1884]\n",
      "  Path 3: Total Time=2230 min, Min Capacity=46000.00 kg, Flights=[32, 1460, 914, 1884]\n",
      "---------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1: Total Time=2075 min, Min Capacity=46000.00 kg, Flights=[34, 1486, 925]\n",
      "  Path 2: Total Time=3475 min, Min Capacity=46000.00 kg, Flights=[36, 1605, 923, 1893, 1215]\n",
      "---------------\n",
      "\n",
      "... (output truncated) ...\n",
      "\n",
      "Found path results for 3185 ODTs (Average 1.86 paths/ODT).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import math\n",
    "import time as timer\n",
    "from bisect import bisect_left # Can potentially optimize connection finding slightly\n",
    "\n",
    "# --- Global Tie-breaker for Dijkstra Heapq ---\n",
    "tie_breaker = itertools.count()\n",
    "\n",
    "# --- Efficient Time-Expanded Flight Network ---\n",
    "class FlightNetworkEfficient:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins):\n",
    "        print(\"\\nInitializing Efficient Time-Expanded Flight Network...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "             raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "\n",
    "        # --- Efficient Lookups ---\n",
    "        print(\"Precomputing lookups...\")\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "\n",
    "        # Group flights by origin AND store sorted departure times list for bisect\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        # Sort once globally by departure time\n",
    "        schedule_sorted = schedule_df.sort_values(by='dep_time')\n",
    "        for idx, row in schedule_sorted.iterrows():\n",
    "             key = row['ori']\n",
    "             self.flights_by_origin[key]['ids'].append(row['flight_id'])\n",
    "             self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # Pre-group demands by destination airport for faster sink edge lookup\n",
    "        self.demands_by_dest = defaultdict(list)\n",
    "        for odt_id, demand_info in self.demand_details.items():\n",
    "             self.demands_by_dest[demand_info['des']].append(odt_id)\n",
    "\n",
    "\n",
    "        # --- Graph Representation: Adjacency List ---\n",
    "        self.graph = defaultdict(list)\n",
    "        self.build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, elapsed_time, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        \"\"\"Adds edge with elapsed_time as weight.\"\"\"\n",
    "        if elapsed_time < 0: return\n",
    "\n",
    "        cap = float(capacity) if isinstance(capacity, (int, float)) and math.isfinite(capacity) else float('inf')\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v, 'weight': float(elapsed_time), 'flight_id': flight_id,\n",
    "            'capacity': cap, 'is_flight': is_flight\n",
    "        })\n",
    "\n",
    "    def find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        \"\"\"Finds index of first flight >= min_departure_time using bisect_left.\"\"\"\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        return idx if idx < len(dep_times_list) else -1\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds the time-expanded graph efficiently.\"\"\"\n",
    "        print(\"Building time-expanded graph...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # Node Types: ('source', odt), ('sink', odt), (flight_id, 'dep'), (flight_id, 'arr')\n",
    "\n",
    "        # 1. Flight Edges (Dep -> Arr)\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            duration = flight['arr_time'] - flight['dep_time']\n",
    "            self._add_edge((flight_id, 'dep'), (flight_id, 'arr'), duration, flight_id, flight['cap_kg'], True)\n",
    "\n",
    "        # 2. Connection (Arr -> Dep) and Sink (Arr -> Sink) Edges\n",
    "        connection_edge_count = 0\n",
    "        sink_edge_count = 0\n",
    "        for flight1_id, flight1 in self.flight_data.items():\n",
    "            arrival_node = (flight1_id, 'arr')\n",
    "            arrival_time = flight1['arr_time']\n",
    "            arrival_airport = flight1['des']\n",
    "\n",
    "            # a) Sink Edges (Efficiently using precomputed demands_by_dest)\n",
    "            for odt_id in self.demands_by_dest.get(arrival_airport, []):\n",
    "                 self._add_edge(arrival_node, ('sink', odt_id), 0)\n",
    "                 sink_edge_count += 1\n",
    "\n",
    "            # b) Connection Edges (Using bisect for potential speedup)\n",
    "            origin_data = self.flights_by_origin.get(arrival_airport)\n",
    "            if origin_data:\n",
    "                min_dep_time = arrival_time + self.min_connect_mins\n",
    "                # Find index of first potentially valid flight\n",
    "                start_idx = self.find_first_flight_idx_after(origin_data['dep_times'], min_dep_time)\n",
    "\n",
    "                if start_idx != -1:\n",
    "                    # Add edges for all valid flights from this index onwards\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        flight2_id = origin_data['ids'][i]\n",
    "                        flight2_dep_time = origin_data['dep_times'][i] # Already available\n",
    "                        wait_time = flight2_dep_time - arrival_time\n",
    "                        self._add_edge(arrival_node, (flight2_id, 'dep'), wait_time)\n",
    "                        connection_edge_count += 1\n",
    "\n",
    "        # 3. Source Edges (Source -> Dep)\n",
    "        source_edge_count = 0\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            origin_airport = demand['ori']\n",
    "            ready_time = demand['time']\n",
    "\n",
    "            origin_data = self.flights_by_origin.get(origin_airport)\n",
    "            if origin_data:\n",
    "                # Find index of first potentially valid flight\n",
    "                start_idx = self.find_first_flight_idx_after(origin_data['dep_times'], ready_time)\n",
    "                if start_idx != -1:\n",
    "                    # Add edges for all valid flights from this index onwards\n",
    "                    for i in range(start_idx, len(origin_data['ids'])):\n",
    "                        flight_id = origin_data['ids'][i]\n",
    "                        flight_dep_time = origin_data['dep_times'][i]\n",
    "                        initial_wait = flight_dep_time - ready_time\n",
    "                        self._add_edge(source_node, (flight_id, 'dep'), initial_wait)\n",
    "                        source_edge_count += 1\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "        est_nodes = len(self.demand_details) * 2 + len(self.flight_data) * 2\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "        print(f\"Edge Counts: Flight={len(self.flight_data)}, Connection={connection_edge_count}, Sink={sink_edge_count}, Source={source_edge_count}\")\n",
    "\n",
    "\n",
    "    def _dijkstra(self, start_node, end_node, forbidden_edges=None, forbidden_nodes=None):\n",
    "        \"\"\"Standard Dijkstra minimizing total elapsed time.\"\"\"\n",
    "        global tie_breaker\n",
    "        if forbidden_edges is None: forbidden_edges = set()\n",
    "        if forbidden_nodes is None: forbidden_nodes = set()\n",
    "\n",
    "        pq = [(0.0, next(tie_breaker), start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            cost, _, current_node, path_list = heapq.heappop(pq)\n",
    "\n",
    "            if cost > visited_costs[current_node]: continue\n",
    "            if current_node == end_node: return cost, path_list\n",
    "\n",
    "            if current_node not in self.graph: continue\n",
    "\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                edge_elapsed_time = edge['weight']\n",
    "\n",
    "                if neighbor in forbidden_nodes: continue\n",
    "                edge_rep = (current_node, neighbor, edge['flight_id'])\n",
    "                if edge_rep in forbidden_edges: continue\n",
    "\n",
    "                new_cost = cost + edge_elapsed_time\n",
    "                if new_cost < visited_costs[neighbor]:\n",
    "                    visited_costs[neighbor] = new_cost\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    new_path = path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_cost, next(tie_breaker), neighbor, new_path))\n",
    "\n",
    "        return float('inf'), None\n",
    "\n",
    "\n",
    "    def _format_path(self, path_list, total_elapsed_time):\n",
    "        \"\"\"Formats path list into desired output.\"\"\"\n",
    "        if not path_list or len(path_list) < 2: return None\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        for step in path_list[1:]:\n",
    "            edge = step['edge_info']\n",
    "            if edge and edge['is_flight']:\n",
    "                flight_ids.append(edge['flight_id'])\n",
    "                min_capacity = min(min_capacity, edge['capacity'])\n",
    "        min_cap_final = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "        return {'total_time': total_elapsed_time, 'flight_ids': flight_ids, 'min_capacity': min_cap_final}\n",
    "\n",
    "\n",
    "    def find_k_shortest_paths(self):\n",
    "        \"\"\"Finds K shortest paths using Yen's.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 50 == 0: # Progress update every 50 demands\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                rate = (i + 1) / elapsed if elapsed > 0 else 0\n",
    "                print(f\"  Processed {i+1}/{total_demands} demands... Elapsed: {elapsed:.1f}s ({rate:.1f} req/s)\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            end_node = ('sink', odt_id)\n",
    "\n",
    "            A = [] # Stores final paths: (total_time_cost, path_list)\n",
    "            B = [] # Candidate heap: (total_time_cost, tie_id, path_list)\n",
    "            found_path_nodes = set() # Cache node sequences of paths added to A or B\n",
    "\n",
    "            # 1. Find first shortest path\n",
    "            cost1, path1 = self._dijkstra(start_node, end_node)\n",
    "            if path1:\n",
    "                A.append((cost1, path1))\n",
    "                found_path_nodes.add(tuple(s['node'] for s in path1))\n",
    "            else:\n",
    "                all_results[odt_id] = []\n",
    "                continue\n",
    "\n",
    "            # 2. Find paths k = 2 to K\n",
    "            for k in range(1, self.k_paths):\n",
    "                if k > len(A): break\n",
    "                prev_cost, prev_path = A[k-1]\n",
    "\n",
    "                # Iterate through nodes of path k-1 to find spur points\n",
    "                for i in range(len(prev_path) - 1):\n",
    "                    spur_node = prev_path[i]['node']\n",
    "                    root_path = prev_path[:i+1]\n",
    "                    root_nodes_tuple = tuple(step['node'] for step in root_path)\n",
    "\n",
    "                    forbidden_nodes = {step['node'] for step in root_path[:-1]}\n",
    "                    forbidden_edges = set()\n",
    "\n",
    "                    # Forbid edges leaving spur node used by paths A[0]..A[k-1] sharing the same root\n",
    "                    for cost_j, path_j in A:\n",
    "                        if len(path_j) > i + 1 and tuple(step['node'] for step in path_j[:i+1]) == root_nodes_tuple:\n",
    "                            edge_info_j = path_j[i+1]['edge_info']\n",
    "                            if edge_info_j:\n",
    "                                edge_rep = (spur_node, edge_info_j['neighbor'], edge_info_j['flight_id'])\n",
    "                                forbidden_edges.add(edge_rep)\n",
    "\n",
    "                    # Rerun Dijkstra from START with accumulated forbids\n",
    "                    spur_cost, spur_path_list = self._dijkstra(start_node, end_node, forbidden_edges, forbidden_nodes)\n",
    "\n",
    "                    if spur_path_list:\n",
    "                        spur_nodes_tuple = tuple(s['node'] for s in spur_path_list)\n",
    "                        # Add to candidate heap B only if it's a genuinely new path sequence\n",
    "                        if spur_nodes_tuple not in found_path_nodes:\n",
    "                             heapq.heappush(B, (spur_cost, next(tie_breaker), spur_path_list))\n",
    "                             found_path_nodes.add(spur_nodes_tuple) # Add to cache\n",
    "\n",
    "                # Select the best path from B (lowest cost) that isn't already in A\n",
    "                found_next = False\n",
    "                while B:\n",
    "                    potential_cost, _, potential_path = heapq.heappop(B)\n",
    "                    # Check if this exact path was already added to A in a previous K iteration\n",
    "                    # (Uniqueness based on cost AND sequence is implicitly handled by found_path_nodes)\n",
    "                    # If we reach here, it's a valid candidate for the k-th path\n",
    "                    A.append((potential_cost, potential_path))\n",
    "                    found_next = True\n",
    "                    break\n",
    "\n",
    "                if not found_next: break\n",
    "\n",
    "            # Format results for ODT\n",
    "            formatted_paths = []\n",
    "            A.sort(key=lambda x: x[0]) # Ensure sorted output by total time\n",
    "            for cost, path_list in A:\n",
    "                 formatted = self._format_path(path_list, cost)\n",
    "                 if formatted: formatted_paths.append(formatted)\n",
    "            all_results[odt_id] = formatted_paths[:self.k_paths]\n",
    "\n",
    "        print(f\"\\nFinished finding K shortest paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting flight path analysis (Efficient Time-Expanded Model)...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run only if data is valid\n",
    "if not schedule_data.empty and not demand_data.empty:\n",
    "    try:\n",
    "        flight_network = FlightNetworkEfficient(schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS)\n",
    "        k_shortest_paths = flight_network.find_k_shortest_paths()\n",
    "\n",
    "        # 3. Output Sample Results\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample) ---\")\n",
    "        output_count = 0\n",
    "        total_paths_found_count = 0\n",
    "        for odt, paths in k_shortest_paths.items():\n",
    "            total_paths_found_count += len(paths)\n",
    "            if output_count < 5:\n",
    "                demand_info = flight_network.demand_details.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        print(f\"  Path {i+1}: Total Time={path['total_time']:.0f} min, Min Capacity={path['min_capacity']:.2f} kg, Flights={path['flight_ids']}\")\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 15)\n",
    "            elif output_count == 5:\n",
    "                 print(\"\\n... (output truncated) ...\")\n",
    "            output_count += 1\n",
    "\n",
    "        avg_paths = total_paths_found_count / len(k_shortest_paths) if k_shortest_paths else 0\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths)} ODTs (Average {avg_paths:.2f} paths/ODT).\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nError: Could not read valid schedule or demand data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight path analysis (Optimized Flight-Vertex Model)...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Optimized Flight-Vertex Network...\n",
      "Precomputing lookups...\n",
      "Building optimized flight-vertex graph...\n",
      "1. Adding Source -> Flight edges...\n",
      "   Added 22420 source edges.\n",
      "2. Adding Flight -> Flight edges...\n",
      "   Added 23969 connection edges.\n",
      "   Added 1670 'waiting' edges.\n",
      "3. Adding Flight -> Sink edges...\n",
      "   Added 121331 flight-to-sink edges.\n",
      "Graph building completed in 0.16 seconds.\n",
      "Graph nodes estimated around: 8427\n",
      "\n",
      "Finding 3 shortest paths (Flight-Vertex Model, ranked by user_cost)...\n",
      "NOTE: Pathfinding uses user-defined costs. Ranking is based on the sum, which equals total duration.\n",
      "      Graph pruning (first unique OD) may exclude globally optimal paths.\n",
      "  Processed 100/3185 demands... Elapsed: 1.57s\n",
      "  Processed 200/3185 demands... Elapsed: 3.64s\n",
      "  Processed 300/3185 demands... Elapsed: 5.66s\n",
      "  Processed 400/3185 demands... Elapsed: 7.99s\n",
      "  Processed 500/3185 demands... Elapsed: 10.85s\n",
      "  Processed 600/3185 demands... Elapsed: 12.57s\n",
      "  Processed 700/3185 demands... Elapsed: 14.57s\n",
      "  Processed 800/3185 demands... Elapsed: 17.00s\n",
      "  Processed 900/3185 demands... Elapsed: 17.62s\n",
      "  Processed 1000/3185 demands... Elapsed: 18.20s\n",
      "  Processed 1100/3185 demands... Elapsed: 18.73s\n",
      "  Processed 1200/3185 demands... Elapsed: 20.19s\n",
      "  Processed 1300/3185 demands... Elapsed: 23.12s\n",
      "  Processed 1400/3185 demands... Elapsed: 25.94s\n",
      "  Processed 1500/3185 demands... Elapsed: 28.93s\n",
      "  Processed 1600/3185 demands... Elapsed: 31.05s\n",
      "  Processed 1700/3185 demands... Elapsed: 33.84s\n",
      "  Processed 1800/3185 demands... Elapsed: 36.80s\n",
      "  Processed 1900/3185 demands... Elapsed: 40.09s\n",
      "  Processed 2000/3185 demands... Elapsed: 42.89s\n",
      "  Processed 2100/3185 demands... Elapsed: 44.97s\n",
      "  Processed 2200/3185 demands... Elapsed: 47.97s\n",
      "  Processed 2300/3185 demands... Elapsed: 51.78s\n",
      "  Processed 2400/3185 demands... Elapsed: 53.75s\n",
      "  Processed 2500/3185 demands... Elapsed: 56.44s\n",
      "  Processed 2600/3185 demands... Elapsed: 57.97s\n",
      "  Processed 2700/3185 demands... Elapsed: 58.85s\n",
      "  Processed 2800/3185 demands... Elapsed: 60.66s\n",
      "  Processed 2900/3185 demands... Elapsed: 62.55s\n",
      "  Processed 3000/3185 demands... Elapsed: 64.54s\n",
      "  Processed 3100/3185 demands... Elapsed: 66.66s\n",
      "\n",
      "Finished finding K shortest paths in 69.28 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample - Ranked by Total Time) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Total Time=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1307, 1177, 536]\n",
      "---------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1: Total Time=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902]\n",
      "  Path 2: Total Time=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[27, 1347, 1694, 575]\n",
      "---------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612]\n",
      "  Path 2: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612]\n",
      "  Path 3: Total Time=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1391, 1189, 612]\n",
      "---------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1: Total Time=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884]\n",
      "  Path 2: Total Time=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884]\n",
      "  Path 3: Total Time=2230 min, Min Capacity=46000.00 kg, Flights=[31, 1435, 1583, 914, 1884]\n",
      "---------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1: Total Time=2075 min, Min Capacity=46000.00 kg, Flights=[34, 1486, 925]\n",
      "  Path 2: Total Time=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1481, 1859]\n",
      "  Path 3: Total Time=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1503, 402, 1859]\n",
      "---------------\n",
      "\n",
      "... (output truncated) ...\n",
      "\n",
      "Found path results for 3185 ODTs.\n"
     ]
    }
   ],
   "source": [
    "# --- Flight-Vertex Network Class (Optimized within User's Model) ---\n",
    "class FlightVertexNetworkOptimized:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins):\n",
    "        print(\"\\nInitializing Optimized Flight-Vertex Network...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "            raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "\n",
    "        # --- Essential Lookups ---\n",
    "        print(\"Precomputing lookups...\")\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index')\n",
    "\n",
    "        # Store departure times separately for quick access during bisect\n",
    "        self.flight_dep_times = schedule_df.set_index('flight_id')['dep_time'].to_dict()\n",
    "\n",
    "        # Group flights by (ori, des) and sort by departure time\n",
    "        # Store both flight_ids and corresponding dep_times for efficient bisect\n",
    "        self.flights_by_od = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        schedule_sorted_od = schedule_df.sort_values(by=['ori', 'des', 'dep_time'])\n",
    "        for idx, row in schedule_sorted_od.iterrows():\n",
    "            key = (row['ori'], row['des'])\n",
    "            self.flights_by_od[key]['ids'].append(row['flight_id'])\n",
    "            self.flights_by_od[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # Group flights by origin, sorted by departure (needed for connections)\n",
    "        # Store both flight_ids and dep_times\n",
    "        self.flights_by_origin = defaultdict(lambda: {'ids': [], 'dep_times': []})\n",
    "        schedule_sorted_ori = schedule_df.sort_values(by=['ori', 'dep_time'])\n",
    "        for idx, row in schedule_sorted_ori.iterrows():\n",
    "             key = row['ori']\n",
    "             self.flights_by_origin[key]['ids'].append(row['flight_id'])\n",
    "             self.flights_by_origin[key]['dep_times'].append(row['dep_time'])\n",
    "\n",
    "        # --- Graph Representation (Adjacency List) ---\n",
    "        # Node -> list of outgoing edges\n",
    "        # Node types: ('source', odt_str), flight_id_int, ('sink', odt_str)\n",
    "        # Edge dict: {'neighbor': node, 'cost': float (user_defined!),\n",
    "        #             'capacity': float, 'is_waiting_edge': bool}\n",
    "        # Note: We don't strictly need 'arr_time' on the edge if Dijkstra uses the cost correctly\n",
    "        self.graph = defaultdict(list)\n",
    "        self.build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, user_cost, capacity=None, is_waiting_edge=False):\n",
    "        \"\"\"Adds edge with user-defined cost.\"\"\"\n",
    "        if u is None or v is None or user_cost < 0: return\n",
    "\n",
    "        cap = float(capacity) if isinstance(capacity, (int, float)) and math.isfinite(capacity) else float('inf')\n",
    "\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v,\n",
    "            'cost': float(user_cost), # The cost metric requested by the user\n",
    "            'capacity': cap,\n",
    "            'is_waiting_edge': is_waiting_edge\n",
    "        })\n",
    "\n",
    "    def find_first_flight_idx_after(self, dep_times_list, min_departure_time):\n",
    "        \"\"\"Finds the index of the first flight departing at or after min_departure_time using bisect.\"\"\"\n",
    "        # bisect_left finds the insertion point for min_departure_time in the sorted list\n",
    "        # This insertion point is the index of the first element >= min_departure_time\n",
    "        idx = bisect_left(dep_times_list, min_departure_time)\n",
    "        if idx < len(dep_times_list):\n",
    "            return idx # Found a valid flight index\n",
    "        else:\n",
    "            return -1 # No flight found after the specified time\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds the graph based on user's flight-vertex model rules using optimizations.\"\"\"\n",
    "        print(\"Building optimized flight-vertex graph...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # 1. Source to Flight Edges (Optimized)\n",
    "        print(\"1. Adding Source -> Flight edges...\")\n",
    "        source_edge_count = 0\n",
    "        # Get unique origins from demands for faster iteration\n",
    "        demand_origins = self.demand_details.keys()\n",
    "\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            demand_ori = demand['ori']\n",
    "            demand_time = demand['time']\n",
    "            processed_first_ods = set() # Track ODs processed for *this specific source*\n",
    "\n",
    "            # Iterate relevant OD pairs starting from demand_ori more efficiently\n",
    "            # Get all OD pairs starting from demand_ori\n",
    "            relevant_od_pairs = [od for od in self.flights_by_od.keys() if od[0] == demand_ori]\n",
    "\n",
    "            for od_pair in relevant_od_pairs:\n",
    "                 if od_pair not in processed_first_ods:\n",
    "                     od_data = self.flights_by_od[od_pair]\n",
    "                     # Find index of first flight using bisect_left\n",
    "                     idx = self.find_first_flight_idx_after(od_data['dep_times'], demand_time)\n",
    "\n",
    "                     if idx != -1: # Found a valid flight\n",
    "                         first_flight_id = od_data['ids'][idx]\n",
    "                         flight = self.flight_data[first_flight_id]\n",
    "                         # User Cost: dep_time - ready_time\n",
    "                         user_cost = flight['dep_time'] - demand_time\n",
    "                         self._add_edge(source_node, first_flight_id, user_cost, capacity=flight['cap_kg'])\n",
    "                         processed_first_ods.add(od_pair)\n",
    "                         source_edge_count += 1\n",
    "        print(f\"   Added {source_edge_count} source edges.\")\n",
    "\n",
    "\n",
    "        # 2. Flight to Flight Edges (Connections and Waiting - Optimized)\n",
    "        print(\"2. Adding Flight -> Flight edges...\")\n",
    "        connection_edge_count = 0\n",
    "        waiting_edge_count = 0\n",
    "        for flight_id_A, flight_A in self.flight_data.items():\n",
    "            arrival_airport_A = flight_A['des']\n",
    "            arrival_time_A = flight_A['arr_time']\n",
    "            departure_time_A = flight_A['dep_time']\n",
    "            ori_A, des_A = flight_A['ori'], flight_A['des']\n",
    "\n",
    "            # a) Connection Edges (A -> B)\n",
    "            processed_first_conn_ods = set()\n",
    "            origin_data = self.flights_by_origin.get(arrival_airport_A)\n",
    "            if origin_data: # Check if any flights depart from arrival airport\n",
    "                # Find first potential connecting flight using bisect\n",
    "                min_dep_time_B = arrival_time_A + self.min_connect_mins\n",
    "                start_idx_B = self.find_first_flight_idx_after(origin_data['dep_times'], min_dep_time_B)\n",
    "\n",
    "                if start_idx_B != -1:\n",
    "                    # Check flights from start_idx_B onwards to find first unique ODs\n",
    "                    for i in range(start_idx_B, len(origin_data['ids'])):\n",
    "                        flight_id_B = origin_data['ids'][i]\n",
    "                        flight_B = self.flight_data[flight_id_B]\n",
    "                        od_pair_B = (flight_B['ori'], flight_B['des'])\n",
    "\n",
    "                        if od_pair_B not in processed_first_conn_ods:\n",
    "                            # User Cost: B.dep_time - A.dep_time\n",
    "                            user_cost = flight_B['dep_time'] - departure_time_A\n",
    "                            self._add_edge(flight_id_A, flight_id_B, user_cost, capacity=flight_B['cap_kg'])\n",
    "                            processed_first_conn_ods.add(od_pair_B)\n",
    "                            connection_edge_count += 1\n",
    "                            # Optimization: Could potentially break if we only need *one* connection total?\n",
    "                            # User rule says \"first unique OD\", so we continue checking others.\n",
    "\n",
    "            # b) Waiting Edges (A -> C, same OD)\n",
    "            od_data = self.flights_by_od.get((ori_A, des_A))\n",
    "            if od_data:\n",
    "                 # Find the index of flight_A efficiently using bisect_left on dep_times\n",
    "                 # This gives the insertion point, which might be the index if value exists\n",
    "                 # A direct list.index() might be faster if lists are typically short\n",
    "                 try:\n",
    "                     # Use list.index() - likely faster for non-huge lists than recreating times\n",
    "                     idx_A = od_data['ids'].index(flight_id_A)\n",
    "                 except ValueError:\n",
    "                     idx_A = -1 # Should not happen\n",
    "\n",
    "                 if idx_A != -1 and idx_A + 1 < len(od_data['ids']):\n",
    "                    flight_id_C = od_data['ids'][idx_A + 1]\n",
    "                    flight_C = self.flight_data[flight_id_C]\n",
    "                    # User Cost: C.dep_time - A.dep_time\n",
    "                    user_cost = flight_C['dep_time'] - departure_time_A\n",
    "                    self._add_edge(flight_id_A, flight_id_C, user_cost, capacity=flight_C['cap_kg'], is_waiting_edge=True)\n",
    "                    waiting_edge_count += 1\n",
    "\n",
    "        print(f\"   Added {connection_edge_count} connection edges.\")\n",
    "        print(f\"   Added {waiting_edge_count} 'waiting' edges.\")\n",
    "\n",
    "        # 3. Flight to Sink Edges (No change in logic needed, still potentially many)\n",
    "        print(\"3. Adding Flight -> Sink edges...\")\n",
    "        sink_edge_count = 0\n",
    "        # Pre-group demands by destination for efficiency\n",
    "        demands_by_dest = defaultdict(list)\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "             demands_by_dest[demand['des']].append(odt_id)\n",
    "\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            dest_airport = flight['des']\n",
    "            # Connect to ALL demand sinks that require this destination\n",
    "            for odt_id in demands_by_dest.get(dest_airport, []):\n",
    "                 sink_node = ('sink', odt_id)\n",
    "                 # User Cost: Duration of flight F\n",
    "                 user_cost = flight['arr_time'] - flight['dep_time']\n",
    "                 # No extra attributes needed on edge for basic Dijkstra with this cost model\n",
    "                 self._add_edge(flight_id, sink_node, user_cost)\n",
    "                 sink_edge_count += 1\n",
    "        print(f\"   Added {sink_edge_count} flight-to-sink edges.\")\n",
    "\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "        est_nodes = len(self.demand_details) + len(self.flight_data) + len(self.demand_details)\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "\n",
    "\n",
    "    def _dijkstra(self, start_node, end_node, forbidden_edges=None, forbidden_nodes=None):\n",
    "        \"\"\"\n",
    "        Standard Dijkstra minimizing the sum of user-defined edge costs.\n",
    "        Returns (min_user_cost, path_list)\n",
    "        \"\"\"\n",
    "        global tie_breaker\n",
    "        if forbidden_edges is None: forbidden_edges = set()\n",
    "        if forbidden_nodes is None: forbidden_nodes = set()\n",
    "\n",
    "        # PQ: (user_cost, tie_id, current_node, path_list)\n",
    "        # path_list: [{'node': node, 'edge_info': edge_dict_or_None}]\n",
    "        pq = [(0.0, next(tie_breaker), start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_user_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_user_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            user_cost, _, current_node, path_list = heapq.heappop(pq)\n",
    "\n",
    "            if user_cost > visited_user_costs[current_node]: continue\n",
    "            if current_node == end_node: return user_cost, path_list # Found shortest path based on user_cost\n",
    "\n",
    "            if current_node not in self.graph: continue\n",
    "\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor_node = edge['neighbor']\n",
    "                edge_user_cost = edge['cost']\n",
    "\n",
    "                # --- Forbidden checks ---\n",
    "                if neighbor_node in forbidden_nodes: continue\n",
    "                neighbor_flight_id = neighbor_node if isinstance(neighbor_node, int) else None\n",
    "                edge_rep = (current_node, neighbor_node, neighbor_flight_id)\n",
    "                if edge_rep in forbidden_edges: continue\n",
    "                # --- End Forbidden ---\n",
    "\n",
    "                new_user_cost = user_cost + edge_user_cost\n",
    "                if new_user_cost < visited_user_costs[neighbor_node]:\n",
    "                    visited_user_costs[neighbor_node] = new_user_cost\n",
    "                    new_step = {'node': neighbor_node, 'edge_info': edge}\n",
    "                    new_path = path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_user_cost, next(tie_breaker), neighbor_node, new_path))\n",
    "\n",
    "        return float('inf'), None # No path found\n",
    "\n",
    "\n",
    "    def _format_path(self, path_list, total_user_cost, demand_ready_time):\n",
    "        \"\"\"Formats path, extracting flights, capacity. Total time IS the user_cost sum.\"\"\"\n",
    "        if not path_list or len(path_list) < 2: return None\n",
    "\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        final_arrival_time = demand_ready_time # Initialize for duration calculation\n",
    "\n",
    "        for step in path_list[1:]: # Skip source\n",
    "            node = step['node']\n",
    "            edge = step['edge_info']\n",
    "\n",
    "            # Identify \"taken\" flights (not waiting edges leading to them)\n",
    "            # A flight is \"taken\" if the edge leading to it is NOT a waiting edge.\n",
    "            # Or if it's the first flight from the source.\n",
    "            # Or if it's the target of a connection edge.\n",
    "            # Exception: If the *last* edge is flight->sink, that flight was taken.\n",
    "            is_taken_flight = False\n",
    "            prev_node = path_list[path_list.index(step)-1]['node']\n",
    "\n",
    "            if isinstance(node, int): # Current step is a flight node\n",
    "                if edge and not edge['is_waiting_edge']:\n",
    "                     is_taken_flight = True\n",
    "                # Update final_arrival_time based on the flight data IF it's the last flight\n",
    "                # We need to know if the *next* node is the sink\n",
    "                current_index = path_list.index(step)\n",
    "                if current_index + 1 < len(path_list):\n",
    "                     next_node_info = path_list[current_index+1]\n",
    "                     if isinstance(next_node_info['node'], tuple) and next_node_info['node'][0] == 'sink':\n",
    "                          final_arrival_time = self.flight_data[node]['arr_time']\n",
    "                else: # This flight node is the last in path list (shouldn't happen if sink exists)\n",
    "                     final_arrival_time = self.flight_data[node]['arr_time']\n",
    "\n",
    "\n",
    "            if is_taken_flight and edge:\n",
    "                 flight_ids.append(node)\n",
    "                 min_capacity = min(min_capacity, edge['capacity'])\n",
    "\n",
    "        min_cap_final = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "\n",
    "        # total_user_cost *is* the total elapsed time in this model\n",
    "        total_elapsed_time = total_user_cost if total_user_cost != float('inf') else float('inf')\n",
    "        # Double check calculation using final arrival if available\n",
    "        if final_arrival_time > demand_ready_time:\n",
    "            calculated_duration = final_arrival_time - demand_ready_time\n",
    "            # If the sum didn't match (e.g., due to floating point), use calculated?\n",
    "            # For now, trust the Dijkstra sum matches the algebraic simplification.\n",
    "            # print(f\"Debug: Dijkstra Cost = {total_user_cost}, Calc Duration = {calculated_duration}\")\n",
    "        else:\n",
    "             # Handle cases where path doesn't end properly at a flight before sink?\n",
    "             pass\n",
    "\n",
    "\n",
    "        return {\n",
    "            'total_time': total_elapsed_time, # Actual elapsed duration is the sum of user costs\n",
    "            'flight_ids': flight_ids,    # Flights considered \"taken\"\n",
    "            'min_capacity': min_cap_final\n",
    "        }\n",
    "\n",
    "\n",
    "    def find_k_shortest_paths(self):\n",
    "        \"\"\"Finds K shortest paths using Yen's, ranking by the sum of user_costs (== total time).\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths (Flight-Vertex Model, ranked by user_cost)...\")\n",
    "        print(\"NOTE: Pathfinding uses user-defined costs. Ranking is based on the sum, which equals total duration.\")\n",
    "        print(\"      Graph pruning (first unique OD) may exclude globally optimal paths.\")\n",
    "\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                print(f\"  Processed {i+1}/{total_demands} demands... Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            end_node = ('sink', odt_id)\n",
    "            demand_ready_time = demand['time']\n",
    "\n",
    "            A = [] # Stores final paths: (user_cost, path_list) - Sort by user_cost\n",
    "            B = [] # Candidate heap: (user_cost, tie_id, path_list) - Heap by user_cost\n",
    "\n",
    "            # 1. Find first shortest path based on user_cost\n",
    "            cost1, path1 = self._dijkstra(start_node, end_node)\n",
    "            if path1:\n",
    "                A.append((cost1, path1))\n",
    "            else:\n",
    "                all_results[odt_id] = []\n",
    "                continue\n",
    "\n",
    "            found_path_nodes = {tuple(s['node'] for s in path1)} if path1 else set()\n",
    "\n",
    "            # 2. Find paths k = 2 to K\n",
    "            for k in range(1, self.k_paths):\n",
    "                if k > len(A): break\n",
    "                prev_cost, prev_path = A[k-1] # Path k-1 (0-indexed)\n",
    "\n",
    "                # Iterate through nodes of path k-1 to find spur points\n",
    "                for i in range(len(prev_path) - 1): # Spur node cannot be sink\n",
    "                    spur_node = prev_path[i]['node']\n",
    "                    root_path = prev_path[:i+1]\n",
    "\n",
    "                    forbidden_nodes = {step['node'] for step in root_path[:-1]}\n",
    "                    forbidden_edges = set()\n",
    "\n",
    "                    # Forbid edges leaving spur node used by paths A[0]..A[k-1] sharing the same root\n",
    "                    root_nodes_tuple = tuple(step['node'] for step in root_path)\n",
    "                    for cost_j, path_j in A:\n",
    "                        if len(path_j) > i + 1:\n",
    "                            if tuple(step['node'] for step in path_j[:i+1]) == root_nodes_tuple:\n",
    "                                edge_info_j = path_j[i+1]['edge_info']\n",
    "                                if edge_info_j:\n",
    "                                     neighbor_j = edge_info_j['neighbor']\n",
    "                                     neighbor_flight_id_j = neighbor_j if isinstance(neighbor_j, int) else None\n",
    "                                     edge_rep = (spur_node, neighbor_j, neighbor_flight_id_j)\n",
    "                                     forbidden_edges.add(edge_rep)\n",
    "\n",
    "                    # --- Calculate spur path ---\n",
    "                    # Rerun Dijkstra from START with accumulated forbids\n",
    "                    spur_cost, spur_path_list = self._dijkstra(start_node, end_node, forbidden_edges, forbidden_nodes)\n",
    "\n",
    "                    if spur_path_list:\n",
    "                        spur_nodes_tuple = tuple(s['node'] for s in spur_path_list)\n",
    "                        # Add to candidate heap B only if it's a new path sequence\n",
    "                        if spur_nodes_tuple not in found_path_nodes:\n",
    "                             heapq.heappush(B, (spur_cost, next(tie_breaker), spur_path_list))\n",
    "                             found_path_nodes.add(spur_nodes_tuple)\n",
    "\n",
    "                # Select the best path from B (lowest user_cost) not already in A\n",
    "                found_next = False\n",
    "                while B:\n",
    "                    potential_cost, _, potential_path = heapq.heappop(B)\n",
    "                    # Path uniqueness already handled by found_path_nodes cache when adding to B\n",
    "                    A.append((potential_cost, potential_path))\n",
    "                    found_next = True\n",
    "                    break # Found path k\n",
    "\n",
    "                if not found_next: break\n",
    "\n",
    "            # Format results for ODT\n",
    "            formatted_paths = []\n",
    "            A.sort(key=lambda x: x[0]) # Ensure sorted output by user_cost (== total time)\n",
    "            for cost, path_list in A:\n",
    "                 # Pass demand_ready_time for reference, although cost is the duration\n",
    "                 formatted = self._format_path(path_list, cost, demand_ready_time)\n",
    "                 if formatted: formatted_paths.append(formatted)\n",
    "            all_results[odt_id] = formatted_paths[:self.k_paths] # Ensure only K paths\n",
    "\n",
    "        print(f\"\\nFinished finding K shortest paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting flight path analysis (Optimized Flight-Vertex Model)...\")\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run only if data is valid\n",
    "if not schedule_data.empty and not demand_data.empty:\n",
    "    try:\n",
    "        # Use the Optimized Flight-Vertex class\n",
    "        flight_network = FlightVertexNetworkOptimized(schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS)\n",
    "        k_shortest_paths = flight_network.find_k_shortest_paths()\n",
    "\n",
    "        # 3. Output Sample Results\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample - Ranked by Total Time) ---\")\n",
    "        output_count = 0\n",
    "        for odt, paths in k_shortest_paths.items():\n",
    "            if output_count < 5:\n",
    "                demand_info = flight_network.demand_details.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        print(f\"  Path {i+1}: Total Time={path['total_time']:.0f} min, Min Capacity={path['min_capacity']:.2f} kg, Flights={path['flight_ids']}\")\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 15)\n",
    "            elif output_count == 5:\n",
    "                 print(\"\\n... (output truncated) ...\")\n",
    "                 break\n",
    "            output_count += 1\n",
    "\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths)} ODTs.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nError: Could not read valid schedule or demand data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight path analysis (Flight-Vertex Model)...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Flight-Vertex Network...\n",
      "Precomputing lookups...\n",
      "Building graph based on Flight-Vertex model...\n",
      "1. Adding Source -> Flight edges...\n",
      "   Added 22420 source edges (to first unique OD flights).\n",
      "2. Adding Flight -> Flight edges...\n",
      "   Added 23969 connection edges (to first unique OD).\n",
      "   Added 1670 'waiting' edges (to next same OD flight).\n",
      "3. Adding Flight -> Sink edges...\n",
      "   Added 121331 flight-to-sink edges.\n",
      "Graph building completed in 0.41 seconds.\n",
      "Graph nodes estimated around: 8427\n",
      "\n",
      "Finding 3 shortest paths (ranking by true duration)...\n",
      "WARNING: Underlying graph uses user-defined costs for pathfinding,\n",
      "         which may not align with minimizing true duration.\n",
      "  Processed 100/3185 demands... Elapsed: 2.12s\n",
      "  Processed 200/3185 demands... Elapsed: 5.07s\n",
      "  Processed 300/3185 demands... Elapsed: 7.89s\n",
      "  Processed 400/3185 demands... Elapsed: 11.22s\n",
      "  Processed 500/3185 demands... Elapsed: 15.44s\n",
      "  Processed 600/3185 demands... Elapsed: 17.91s\n",
      "  Processed 700/3185 demands... Elapsed: 20.75s\n",
      "  Processed 800/3185 demands... Elapsed: 24.28s\n",
      "  Processed 900/3185 demands... Elapsed: 25.07s\n",
      "  Processed 1000/3185 demands... Elapsed: 25.82s\n",
      "  Processed 1100/3185 demands... Elapsed: 26.56s\n",
      "  Processed 1200/3185 demands... Elapsed: 28.72s\n",
      "  Processed 1300/3185 demands... Elapsed: 33.12s\n",
      "  Processed 1400/3185 demands... Elapsed: 37.26s\n",
      "  Processed 1500/3185 demands... Elapsed: 41.78s\n",
      "  Processed 1600/3185 demands... Elapsed: 44.84s\n",
      "  Processed 1700/3185 demands... Elapsed: 48.97s\n",
      "  Processed 1800/3185 demands... Elapsed: 53.25s\n",
      "  Processed 1900/3185 demands... Elapsed: 58.29s\n",
      "  Processed 2000/3185 demands... Elapsed: 62.54s\n",
      "  Processed 2100/3185 demands... Elapsed: 65.65s\n",
      "  Processed 2200/3185 demands... Elapsed: 70.20s\n",
      "  Processed 2300/3185 demands... Elapsed: 76.17s\n",
      "  Processed 2400/3185 demands... Elapsed: 79.03s\n",
      "  Processed 2500/3185 demands... Elapsed: 83.00s\n",
      "  Processed 2600/3185 demands... Elapsed: 85.23s\n",
      "  Processed 2700/3185 demands... Elapsed: 86.44s\n",
      "  Processed 2800/3185 demands... Elapsed: 89.17s\n",
      "  Processed 2900/3185 demands... Elapsed: 91.86s\n",
      "  Processed 3000/3185 demands... Elapsed: 94.73s\n",
      "  Processed 3100/3185 demands... Elapsed: 97.86s\n",
      "\n",
      "Finished finding K shortest paths in 101.79 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample - Ranked by True Duration) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1: True Duration=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536] (UserCost=1850)\n",
      "  Path 2: True Duration=1850 min, Min Capacity=46000.00 kg, Flights=[24, 25, 1306, 1685, 536] (UserCost=1850)\n",
      "  Path 3: True Duration=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1307, 1177, 536] (UserCost=1850)\n",
      "---------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1: True Duration=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902] (UserCost=1655)\n",
      "  Path 2: True Duration=1655 min, Min Capacity=46000.00 kg, Flights=[27, 26, 1376, 902] (UserCost=1655)\n",
      "  Path 3: True Duration=1850 min, Min Capacity=46000.00 kg, Flights=[27, 1347, 1694, 575] (UserCost=1850)\n",
      "---------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1: True Duration=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612] (UserCost=1850)\n",
      "  Path 2: True Duration=1850 min, Min Capacity=46000.00 kg, Flights=[30, 28, 1390, 1703, 612] (UserCost=1850)\n",
      "  Path 3: True Duration=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1391, 1189, 612] (UserCost=1850)\n",
      "---------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1: True Duration=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884] (UserCost=2230)\n",
      "  Path 2: True Duration=2230 min, Min Capacity=46000.00 kg, Flights=[31, 32, 1447, 914, 1884] (UserCost=2230)\n",
      "  Path 3: True Duration=2230 min, Min Capacity=46000.00 kg, Flights=[31, 1435, 1583, 914, 1884] (UserCost=2230)\n",
      "---------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1: True Duration=2075 min, Min Capacity=46000.00 kg, Flights=[34, 1486, 925] (UserCost=2075)\n",
      "  Path 2: True Duration=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1481, 1859] (UserCost=2310)\n",
      "  Path 3: True Duration=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1503, 402, 1859] (UserCost=2310)\n",
      "---------------\n",
      "\n",
      "... (output truncated) ...\n",
      "\n",
      "Found path results for 3185 ODTs.\n"
     ]
    }
   ],
   "source": [
    "# --- Flight-Vertex Network Class ---\n",
    "class FlightVertexNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins):\n",
    "        print(\"\\nInitializing Flight-Vertex Network...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "            raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "\n",
    "        # --- Essential Lookups ---\n",
    "        print(\"Precomputing lookups...\")\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.demand_details = demand_df.set_index('ODT').to_dict('index') # ODT -> {ori, des, time, demand}\n",
    "\n",
    "        # Group flights by (ori, des) and sort by departure time\n",
    "        self.flights_by_od = defaultdict(list)\n",
    "        schedule_sorted_od = schedule_df.sort_values(by=['ori', 'des', 'dep_time'])\n",
    "        for idx, row in schedule_sorted_od.iterrows():\n",
    "            self.flights_by_od[(row['ori'], row['des'])].append(row['flight_id'])\n",
    "\n",
    "        # Group flights by origin, sorted by departure (needed for connections)\n",
    "        self.flights_by_origin = defaultdict(list)\n",
    "        schedule_sorted_ori = schedule_df.sort_values(by=['ori', 'dep_time'])\n",
    "        for idx, row in schedule_sorted_ori.iterrows():\n",
    "             self.flights_by_origin[row['ori']].append(row['flight_id'])\n",
    "\n",
    "        # --- Graph Representation (Adjacency List) ---\n",
    "        # Node -> list of outgoing edges\n",
    "        # Node types: ('source', odt_str), flight_id_int, ('sink', odt_str)\n",
    "        # Edge dict: {'neighbor': node, 'cost': float (user_defined!), 'flight_id': int|None, 'is_waiting_edge': bool}\n",
    "        # We also need to store extra info needed by Dijkstra/Path formatting\n",
    "        # Edge dict: {'neighbor': node, 'cost': user_cost, 'arr_time': arrival time if neighbor is flight, 'capacity': capacity if neighbor is flight, 'is_waiting_edge': bool}\n",
    "        self.graph = defaultdict(list)\n",
    "        self.build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, user_cost, arr_time=None, capacity=None, is_waiting_edge=False):\n",
    "        \"\"\"Adds edge with user-defined cost and necessary time/capacity info.\"\"\"\n",
    "        if u is None or v is None: return\n",
    "\n",
    "        # Ensure capacity is float/inf\n",
    "        cap = float(capacity) if isinstance(capacity, (int, float)) and math.isfinite(capacity) else float('inf')\n",
    "\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v,\n",
    "            'cost': float(user_cost), # The cost metric requested by the user\n",
    "            'arr_time': arr_time,     # Actual arrival time (needed for time checks)\n",
    "            'capacity': cap,\n",
    "            'is_waiting_edge': is_waiting_edge # Flag for the ambiguous waiting edge\n",
    "        })\n",
    "\n",
    "    def find_first_flight_after(self, flight_list, min_departure_time):\n",
    "        \"\"\"Finds the first flight_id in a sorted list departing at or after min_departure_time.\"\"\"\n",
    "        # Simple linear scan for now, could use binary search (bisect_left) if lists are very long\n",
    "        for flight_id in flight_list:\n",
    "            if self.flight_data[flight_id]['dep_time'] >= min_departure_time:\n",
    "                return flight_id\n",
    "        return None\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds the graph based on user's flight-vertex model rules.\"\"\"\n",
    "        print(\"Building graph based on Flight-Vertex model...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # --- Node Definitions ---\n",
    "        # ('source', odt_str)\n",
    "        # flight_id_int\n",
    "        # ('sink', odt_str)  <- REQUIRED for per-demand KSP\n",
    "\n",
    "        # 1. Source to Flight Edges\n",
    "        print(\"1. Adding Source -> Flight edges...\")\n",
    "        source_edge_count = 0\n",
    "        processed_first_ods = {} # ('source', odt_id) -> set((ori, des))\n",
    "        for odt_id, demand in self.demand_details.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            demand_ori = demand['ori']\n",
    "            demand_time = demand['time']\n",
    "            processed_first_ods[source_node] = set()\n",
    "\n",
    "            # Iterate through all OD pairs starting from demand_ori\n",
    "            for flight_ori, flight_des in [(f['ori'], f['des']) for f in self.flight_data.values() if f['ori'] == demand_ori]:\n",
    "                 od_pair = (flight_ori, flight_des)\n",
    "                 if od_pair not in processed_first_ods[source_node]:\n",
    "                     # Find the *first* flight for this OD pair departing after demand_time\n",
    "                     relevant_flights = self.flights_by_od.get(od_pair, [])\n",
    "                     first_flight_id = self.find_first_flight_after(relevant_flights, demand_time)\n",
    "\n",
    "                     if first_flight_id is not None:\n",
    "                         flight = self.flight_data[first_flight_id]\n",
    "                         # User Cost: dep_time - ready_time\n",
    "                         user_cost = flight['dep_time'] - demand_time\n",
    "                         # Add edge: Source -> flight_id\n",
    "                         self._add_edge(source_node, first_flight_id, user_cost,\n",
    "                                        arr_time=flight['arr_time'], # Store actual arrival time\n",
    "                                        capacity=flight['cap_kg'])\n",
    "                         processed_first_ods[source_node].add(od_pair)\n",
    "                         source_edge_count += 1\n",
    "        print(f\"   Added {source_edge_count} source edges (to first unique OD flights).\")\n",
    "\n",
    "\n",
    "        # 2. Flight to Flight Edges (Connections and Waiting)\n",
    "        print(\"2. Adding Flight -> Flight edges...\")\n",
    "        connection_edge_count = 0\n",
    "        waiting_edge_count = 0\n",
    "        for flight_id_A, flight_A in self.flight_data.items():\n",
    "            arrival_airport_A = flight_A['des']\n",
    "            arrival_time_A = flight_A['arr_time']\n",
    "            departure_time_A = flight_A['dep_time']\n",
    "            ori_A, des_A = flight_A['ori'], flight_A['des']\n",
    "\n",
    "            # a) Connection Edges (A -> B)\n",
    "            processed_first_conn_ods = set() # Track first unique OD for connections from A\n",
    "            # Iterate through all flights potentially departing from A's destination\n",
    "            for flight_id_B in self.flights_by_origin.get(arrival_airport_A, []):\n",
    "                 flight_B = self.flight_data[flight_id_B]\n",
    "                 od_pair_B = (flight_B['ori'], flight_B['des'])\n",
    "\n",
    "                 # Check temporal constraint first\n",
    "                 if flight_B['dep_time'] >= arrival_time_A + self.min_connect_mins:\n",
    "                     # Check if we already added an edge for this unique OD pair from flight_A\n",
    "                     if od_pair_B not in processed_first_conn_ods:\n",
    "                          # User Cost: B.dep_time - A.dep_time\n",
    "                          user_cost = flight_B['dep_time'] - departure_time_A\n",
    "                          self._add_edge(flight_id_A, flight_id_B, user_cost,\n",
    "                                         arr_time=flight_B['arr_time'], # Store B's arrival time\n",
    "                                         capacity=flight_B['cap_kg'])\n",
    "                          processed_first_conn_ods.add(od_pair_B)\n",
    "                          connection_edge_count += 1\n",
    "                 # Optimization: Since flights_by_origin is sorted, if B is too early,\n",
    "                 # subsequent flights might be okay. But if B is valid, we only take the first per OD.\n",
    "\n",
    "            # b) Waiting Edges (A -> C, same OD)\n",
    "            flights_same_od = self.flights_by_od.get((ori_A, des_A), [])\n",
    "            # Find the index of flight_A in this list\n",
    "            try:\n",
    "                idx_A = flights_same_od.index(flight_id_A)\n",
    "                # Check if there is a *next* flight in the list\n",
    "                if idx_A + 1 < len(flights_same_od):\n",
    "                    flight_id_C = flights_same_od[idx_A + 1]\n",
    "                    flight_C = self.flight_data[flight_id_C]\n",
    "                    # User Cost: C.dep_time - A.dep_time\n",
    "                    user_cost = flight_C['dep_time'] - departure_time_A\n",
    "                    # Add edge A -> C, marking it as a waiting edge\n",
    "                    self._add_edge(flight_id_A, flight_id_C, user_cost,\n",
    "                                   arr_time=flight_C['arr_time'], # Store C's arrival time\n",
    "                                   capacity=flight_C['cap_kg'], # Capacity of C is relevant?\n",
    "                                   is_waiting_edge=True)\n",
    "                    waiting_edge_count += 1\n",
    "            except ValueError:\n",
    "                # flight_id_A not found in its own OD list? Should not happen.\n",
    "                pass\n",
    "        print(f\"   Added {connection_edge_count} connection edges (to first unique OD).\")\n",
    "        print(f\"   Added {waiting_edge_count} 'waiting' edges (to next same OD flight).\")\n",
    "\n",
    "        # 3. Flight to Sink Edges\n",
    "        print(\"3. Adding Flight -> Sink edges...\")\n",
    "        sink_edge_count = 0\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            dest_airport = flight['des']\n",
    "            # Connect to ALL demand sinks that require this destination\n",
    "            # This requires iterating through demands again, maybe inefficient\n",
    "            # Alternative: Create sink nodes first?\n",
    "            for odt_id, demand in self.demand_details.items():\n",
    "                if demand['des'] == dest_airport:\n",
    "                     sink_node = ('sink', odt_id)\n",
    "                     # User Cost: Duration of flight F\n",
    "                     user_cost = flight['arr_time'] - flight['dep_time']\n",
    "                     # Need flight's arrival time to calculate final duration\n",
    "                     self._add_edge(flight_id, sink_node, user_cost,\n",
    "                                    arr_time=flight['arr_time']) # Store arrival time\n",
    "                     sink_edge_count += 1\n",
    "        print(f\"   Added {sink_edge_count} flight-to-sink edges.\")\n",
    "\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "        est_nodes = len(self.demand_details) + len(self.flight_data) + len(self.demand_details) # sources + flights + sinks\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "\n",
    "\n",
    "    def _dijkstra(self, start_node, end_node, forbidden_edges=None, forbidden_nodes=None):\n",
    "        \"\"\"\n",
    "        Modified Dijkstra for the Flight-Vertex model.\n",
    "        Tracks user_cost for minimization and actual_time for validation.\n",
    "        Returns (min_user_cost, final_actual_arrival_time, path_list)\n",
    "        \"\"\"\n",
    "        global tie_breaker\n",
    "        if forbidden_edges is None: forbidden_edges = set()\n",
    "        if forbidden_nodes is None: forbidden_nodes = set()\n",
    "\n",
    "        # Get demand ready time from start_node\n",
    "        demand_ready_time = self.demand_details[start_node[1]]['time']\n",
    "\n",
    "        # Priority Queue: (user_cost, tie_id, current_actual_arr_time, current_node, path_list)\n",
    "        # Path List: [{'node': node, 'edge_info': edge_dict_or_None}]\n",
    "        # current_actual_arr_time is the arrival time at current_node (if it's a flight) or ready_time (if source)\n",
    "        pq = [(0.0, next(tie_breaker), demand_ready_time, start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "\n",
    "        # Visited stores the *minimum user_cost* found to reach a node\n",
    "        visited_user_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_user_costs[start_node] = 0.0\n",
    "        # We also need to track min arrival time to handle cycles correctly with time check\n",
    "        # Note: This makes the state space complex again, similar to time-expansion!\n",
    "        min_arrival_time_at_node = defaultdict(lambda: float('inf'))\n",
    "        min_arrival_time_at_node[start_node] = demand_ready_time\n",
    "\n",
    "\n",
    "        final_arrival_time = float('inf') # Track the actual arrival time for the best path found so far\n",
    "\n",
    "        while pq:\n",
    "            user_cost, _, current_actual_time, current_node, path_list = heapq.heappop(pq)\n",
    "\n",
    "            # Pruning based on user_cost\n",
    "            if user_cost > visited_user_costs[current_node]:\n",
    "                continue\n",
    "\n",
    "            # Check if reached sink\n",
    "            if current_node == end_node:\n",
    "                # We found *a* path. Dijkstra guarantees this is the path with\n",
    "                # the minimum *user_cost*. Store its actual arrival time.\n",
    "                # The *true* shortest path in terms of duration might be found later\n",
    "                # if its user_cost is higher but arrival time is earlier.\n",
    "                # This basic Dijkstra finds only the min-user-cost path.\n",
    "                # Need modification for KSP based on actual time. Let's return the first found path for now.\n",
    "                final_arrival_time = current_actual_time # Time of arrival at the node *before* the sink\n",
    "                return user_cost, final_arrival_time, path_list\n",
    "\n",
    "\n",
    "            # Explore neighbors\n",
    "            if current_node not in self.graph: continue\n",
    "\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor_node = edge['neighbor']\n",
    "                edge_user_cost = edge['cost']\n",
    "                neighbor_actual_arr_time = edge['arr_time'] # Actual arrival time provided by edge\n",
    "                is_waiting_edge = edge['is_waiting_edge']\n",
    "\n",
    "                # --- Forbidden checks ---\n",
    "                if neighbor_node in forbidden_nodes: continue\n",
    "                # Edge representation for forbidden check: (from_node, to_node, neighbor_flight_id_or_None)\n",
    "                # Neighbor flight ID is the node itself if it's a flight_id node\n",
    "                neighbor_flight_id = neighbor_node if isinstance(neighbor_node, int) else None\n",
    "                edge_rep = (current_node, neighbor_node, neighbor_flight_id)\n",
    "                if edge_rep in forbidden_edges: continue\n",
    "                # --- End Forbidden ---\n",
    "\n",
    "                # --- **CRUCIAL TIME VALIDATION** ---\n",
    "                # This check MUST use actual time, simulating time-expansion logic\n",
    "                valid_connection = False\n",
    "                if isinstance(current_node, int): # If current node is a flight\n",
    "                    flight_A_data = self.flight_data[current_node]\n",
    "                    # Check if neighbor is a flight and connection time is valid\n",
    "                    if isinstance(neighbor_node, int):\n",
    "                        flight_B_data = self.flight_data[neighbor_node]\n",
    "                        # Use the actual arrival time at current_node for check\n",
    "                        if flight_B_data['dep_time'] >= current_actual_time + self.min_connect_mins:\n",
    "                            valid_connection = True\n",
    "                    elif isinstance(neighbor_node, tuple) and neighbor_node[0] == 'sink':\n",
    "                        valid_connection = True # Flight -> Sink is always valid temporally\n",
    "                elif isinstance(current_node, tuple) and current_node[0] == 'source':\n",
    "                    # Source -> Flight is always valid temporally by graph construction rule\n",
    "                     valid_connection = True\n",
    "                # Add logic for waiting edge? If A->C wait edge, when is C valid?\n",
    "                # Assuming C is valid if C.dep_time > A.dep_time (checked in build_graph)\n",
    "                if is_waiting_edge:\n",
    "                     valid_connection = True # Temporal validity checked during build\n",
    "\n",
    "\n",
    "                if not valid_connection:\n",
    "                    continue\n",
    "                # --- End Time Validation ---\n",
    "\n",
    "\n",
    "                new_user_cost = user_cost + edge_user_cost\n",
    "\n",
    "                # Relaxation based on user_cost\n",
    "                # Also consider actual arrival time to prevent suboptimal cycles in time\n",
    "                if new_user_cost < visited_user_costs[neighbor_node] or \\\n",
    "                   (neighbor_actual_arr_time is not None and neighbor_actual_arr_time < min_arrival_time_at_node[neighbor_node]):\n",
    "\n",
    "                    visited_user_costs[neighbor_node] = new_user_cost\n",
    "                    if neighbor_actual_arr_time is not None:\n",
    "                         min_arrival_time_at_node[neighbor_node] = neighbor_actual_arr_time\n",
    "\n",
    "                    new_step = {'node': neighbor_node, 'edge_info': edge}\n",
    "                    new_path = path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_user_cost, next(tie_breaker), neighbor_actual_arr_time, neighbor_node, new_path))\n",
    "\n",
    "        # If end_node wasn't reached\n",
    "        return float('inf'), float('inf'), None\n",
    "\n",
    "\n",
    "    def _format_path(self, path_list, final_arrival_time, demand_ready_time):\n",
    "        \"\"\"Formats path, calculating true duration.\"\"\"\n",
    "        if not path_list or len(path_list) < 2: return None\n",
    "\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "        actual_nodes_taken = [] # Track nodes excluding source/sink maybe\n",
    "\n",
    "        for step in path_list[1:]: # Skip source\n",
    "            node = step['node']\n",
    "            edge = step['edge_info']\n",
    "            actual_nodes_taken.append(node)\n",
    "\n",
    "            if isinstance(node, int) and edge and not edge['is_waiting_edge']: # If it's a flight node reached via non-waiting edge\n",
    "                 flight_ids.append(node)\n",
    "                 min_capacity = min(min_capacity, edge['capacity'])\n",
    "            # How to handle capacity if a waiting edge A->C was taken? Does A's capacity count? Or C's?\n",
    "            # Assuming C's capacity is stored on the waiting edge info.\n",
    "            elif isinstance(node, int) and edge and edge['is_waiting_edge']:\n",
    "                 flight_ids.append(node) # Add the flight C we waited *for*\n",
    "                 min_capacity = min(min_capacity, edge['capacity']) # Use C's capacity\n",
    "\n",
    "        min_cap_final = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "\n",
    "        # **Calculate True Duration**\n",
    "        if final_arrival_time == float('inf'):\n",
    "             true_duration = float('inf')\n",
    "        else:\n",
    "            # final_arrival_time is the arrival time of the *last flight* before the sink\n",
    "             true_duration = final_arrival_time - demand_ready_time\n",
    "\n",
    "        return {\n",
    "            'total_time': true_duration, # Actual elapsed duration\n",
    "            'flight_ids': flight_ids,    # Flights considered \"taken\"\n",
    "            'min_capacity': min_cap_final,\n",
    "            # 'internal_cost': user_cost # Can include for debugging\n",
    "            # 'nodes': actual_nodes_taken # Can include for debugging\n",
    "        }\n",
    "\n",
    "\n",
    "    def find_k_shortest_paths(self):\n",
    "        \"\"\"Finds K shortest paths using Yen's, ranking by TRUE DURATION.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths (ranking by true duration)...\")\n",
    "        print(\"WARNING: Underlying graph uses user-defined costs for pathfinding,\")\n",
    "        print(\"         which may not align with minimizing true duration.\")\n",
    "\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_details)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_details.items()):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                print(f\"  Processed {i+1}/{total_demands} demands... Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            end_node = ('sink', odt_id) # MUST be demand-specific sink\n",
    "            demand_ready_time = demand['time']\n",
    "\n",
    "            A = [] # Stores final paths: (true_duration, user_cost, path_list) - Sort by true_duration!\n",
    "            B_candidates = [] # Candidate heap: (user_cost, tie_id, actual_arrival_time, path_list) - Heap by user_cost\n",
    "\n",
    "            # 1. Find first shortest path (based on user_cost)\n",
    "            user_cost1, arrival1, path1 = self._dijkstra(start_node, end_node)\n",
    "\n",
    "            if path1:\n",
    "                duration1 = arrival1 - demand_ready_time if arrival1 != float('inf') else float('inf')\n",
    "                if duration1 != float('inf'):\n",
    "                     A.append((duration1, user_cost1, path1))\n",
    "                # Cannot add to B yet\n",
    "            else:\n",
    "                all_results[odt_id] = []\n",
    "                continue\n",
    "\n",
    "            # Cache for paths found (use node sequence tuple as key) to avoid adding duplicates to A\n",
    "            # Store the user_cost associated with the path found for that sequence\n",
    "            found_paths_cache = {}\n",
    "            if path1:\n",
    "                 found_paths_cache[tuple(s['node'] for s in path1)] = user_cost1\n",
    "\n",
    "\n",
    "            # 2. Find paths k = 2 to K\n",
    "            for k in range(1, self.k_paths):\n",
    "                if k > len(A): break\n",
    "\n",
    "                # Get the (k-1)th path *based on true duration ranking*\n",
    "                # A is sorted by duration, so A[k-1] is correct conceptually\n",
    "                prev_duration, prev_user_cost, prev_path = A[k-1]\n",
    "\n",
    "                # Iterate through nodes of path k-1 to find spur points\n",
    "                current_path_actual_time = demand_ready_time\n",
    "                for i in range(len(prev_path) - 1): # Spur node cannot be sink\n",
    "                    spur_node = prev_path[i]['node']\n",
    "                    spur_node_step = prev_path[i]\n",
    "                    edge_to_spur = spur_node_step['edge_info']\n",
    "\n",
    "                    # Update actual time at spur node\n",
    "                    if edge_to_spur:\n",
    "                         # Need the 'arr_time' from the edge LEADING TO the spur node\n",
    "                         # This requires looking at the edge info in the *current* step i\n",
    "                         current_path_actual_time = edge_to_spur.get('arr_time', current_path_actual_time) # Update time\n",
    "\n",
    "\n",
    "                    root_path = prev_path[:i+1]\n",
    "                    # Calculate root user_cost\n",
    "                    root_user_cost = sum(s['edge_info']['cost'] for s in root_path[1:] if s['edge_info'])\n",
    "\n",
    "                    forbidden_nodes = {step['node'] for step in root_path[:-1]}\n",
    "                    forbidden_edges = set()\n",
    "\n",
    "                    # Forbid edges leaving spur node used by paths in A sharing the same root\n",
    "                    for dur_j, cost_j, path_j in A:\n",
    "                        if len(path_j) > i + 1:\n",
    "                            if [step['node'] for step in path_j[:i+1]] == [step['node'] for step in root_path]:\n",
    "                                edge_info_j = path_j[i+1]['edge_info']\n",
    "                                if edge_info_j:\n",
    "                                     neighbor_j = edge_info_j['neighbor']\n",
    "                                     neighbor_flight_id_j = neighbor_j if isinstance(neighbor_j, int) else None\n",
    "                                     edge_rep = (spur_node, neighbor_j, neighbor_flight_id_j)\n",
    "                                     forbidden_edges.add(edge_rep)\n",
    "\n",
    "                    # --- Calculate spur path using _dijkstra ---\n",
    "                    # Need to run Dijkstra *from* the spur node with its *correct actual time*\n",
    "                    # Our current _dijkstra starts from ready_time. This requires modification\n",
    "                    # or a separate function that takes start_time.\n",
    "                    # Q: Can we reuse _dijkstra if we recalculate costs relative to spur? Maybe not easily.\n",
    "\n",
    "                    # --- SIMPLIFICATION FOR NOW: Rerun Dijkstra from global start with forbids ---\n",
    "                    # This is inefficient but follows Yen's structure more easily here.\n",
    "                    spur_user_cost, spur_arrival, spur_path_list = self._dijkstra(start_node, end_node, forbidden_edges, forbidden_nodes)\n",
    "\n",
    "                    # If a new path is found *from the original source*\n",
    "                    if spur_path_list:\n",
    "                        # Check if this path is genuinely new (different node sequence)\n",
    "                        spur_nodes_tuple = tuple(s['node'] for s in spur_path_list)\n",
    "                        # If this path wasn't found before OR if found with higher user_cost\n",
    "                        if spur_nodes_tuple not in found_paths_cache or spur_user_cost < found_paths_cache[spur_nodes_tuple]:\n",
    "                            spur_duration = spur_arrival - demand_ready_time if spur_arrival != float('inf') else float('inf')\n",
    "                            if spur_duration != float('inf'):\n",
    "                                 # Add to candidate list B (heap not strictly needed if we re-sort later)\n",
    "                                 # Store (duration, user_cost, path_list) for candidate\n",
    "                                 B_candidates.append((spur_duration, spur_user_cost, spur_path_list))\n",
    "                                 found_paths_cache[spur_nodes_tuple] = spur_user_cost # Update cache\n",
    "\n",
    "\n",
    "                # Select the best path from B_candidates based on true duration that isn't already in A\n",
    "                if not B_candidates:\n",
    "                     break # No more potential paths found\n",
    "\n",
    "                # Sort candidates by true duration\n",
    "                B_candidates.sort(key=lambda x: x[0])\n",
    "\n",
    "                found_next = False\n",
    "                processed_candidates = []\n",
    "                for cand_duration, cand_user_cost, cand_path in B_candidates:\n",
    "                    cand_nodes = tuple(s['node'] for s in cand_path)\n",
    "                    is_in_A = any(tuple(s['node'] for s in path_a) == cand_nodes for dur_a, cost_a, path_a in A)\n",
    "                    if not is_in_A:\n",
    "                        A.append((cand_duration, cand_user_cost, cand_path))\n",
    "                        # Remove this candidate from B list for next iteration\n",
    "                        # B_candidates.remove((cand_duration, cand_user_cost, cand_path)) # This is slow\n",
    "                        found_next = True\n",
    "                        break # Found path k\n",
    "                    else:\n",
    "                        # Keep track to rebuild B for the next k without duplicates already added to A\n",
    "                         processed_candidates.append((cand_duration, cand_user_cost, cand_path))\n",
    "\n",
    "                # Rebuild B for next iteration, removing paths just added to A\n",
    "                new_B = []\n",
    "                existing_A_nodes = {tuple(s['node'] for s in p) for d, c, p in A}\n",
    "                for cand_d, cand_c, cand_p in B_candidates:\n",
    "                     if tuple(s['node'] for s in cand_p) not in existing_A_nodes:\n",
    "                          new_B.append((cand_d, cand_c, cand_p))\n",
    "                B_candidates = new_B\n",
    "\n",
    "\n",
    "                if not found_next: break # No more new paths found\n",
    "\n",
    "            # Format results for ODT, A is already sorted by duration\n",
    "            formatted_paths = []\n",
    "            for duration, user_cost, path_list in A:\n",
    "                 formatted = self._format_path(path_list, duration + demand_ready_time, demand_ready_time) # Pass final arrival time\n",
    "                 if formatted:\n",
    "                     formatted['internal_cost'] = user_cost # Add user cost for info\n",
    "                     formatted_paths.append(formatted)\n",
    "            all_results[odt_id] = formatted_paths[:self.k_paths] # Ensure only K paths are stored\n",
    "\n",
    "\n",
    "        print(f\"\\nFinished finding K shortest paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting flight path analysis (Flight-Vertex Model)...\")\n",
    "\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "\n",
    "# 2. Initialize and Run only if data is valid\n",
    "if not schedule_data.empty and not demand_data.empty:\n",
    "    try:\n",
    "        flight_network = FlightVertexNetwork(schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS)\n",
    "        k_shortest_paths = flight_network.find_k_shortest_paths()\n",
    "\n",
    "        # 3. Output Sample Results\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample - Ranked by True Duration) ---\")\n",
    "        output_count = 0\n",
    "        for odt, paths in k_shortest_paths.items():\n",
    "            if output_count < 5:\n",
    "                demand_info = flight_network.demand_details.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        print(f\"  Path {i+1}: True Duration={path['total_time']:.0f} min, Min Capacity={path['min_capacity']:.2f} kg, Flights={path['flight_ids']} (UserCost={path.get('internal_cost',-1):.0f})\")\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 15)\n",
    "            elif output_count == 5:\n",
    "                 print(\"\\n... (output truncated) ...\")\n",
    "                 break\n",
    "            output_count += 1\n",
    "\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths)} ODTs.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nError: Could not read valid schedule or demand data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight path analysis...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "\n",
      "Initializing Flight Network...\n",
      "Precomputing lookups...\n",
      "Building graph...\n",
      "Graph building completed in 0.32 seconds.\n",
      "Graph nodes estimated around: 10484\n",
      "\n",
      "Finding 3 shortest paths for 3185 demands...\n",
      "  Processed 100/3185 demands... Elapsed: 0.94s\n",
      "  Processed 200/3185 demands... Elapsed: 2.18s\n",
      "  Processed 300/3185 demands... Elapsed: 3.37s\n",
      "  Processed 400/3185 demands... Elapsed: 4.72s\n",
      "  Processed 500/3185 demands... Elapsed: 6.64s\n",
      "  Processed 600/3185 demands... Elapsed: 7.67s\n",
      "  Processed 700/3185 demands... Elapsed: 8.78s\n",
      "  Processed 800/3185 demands... Elapsed: 10.34s\n",
      "  Processed 900/3185 demands... Elapsed: 10.97s\n",
      "  Processed 1000/3185 demands... Elapsed: 11.85s\n",
      "  Processed 1100/3185 demands... Elapsed: 12.89s\n",
      "  Processed 1200/3185 demands... Elapsed: 14.46s\n",
      "  Processed 1300/3185 demands... Elapsed: 16.30s\n",
      "  Processed 1400/3185 demands... Elapsed: 17.82s\n",
      "  Processed 1500/3185 demands... Elapsed: 19.69s\n",
      "  Processed 1600/3185 demands... Elapsed: 21.05s\n",
      "  Processed 1700/3185 demands... Elapsed: 22.75s\n",
      "  Processed 1800/3185 demands... Elapsed: 24.72s\n",
      "  Processed 1900/3185 demands... Elapsed: 26.88s\n",
      "  Processed 2000/3185 demands... Elapsed: 28.57s\n",
      "  Processed 2100/3185 demands... Elapsed: 29.66s\n",
      "  Processed 2200/3185 demands... Elapsed: 31.30s\n",
      "  Processed 2300/3185 demands... Elapsed: 33.58s\n",
      "  Processed 2400/3185 demands... Elapsed: 34.82s\n",
      "  Processed 2500/3185 demands... Elapsed: 36.64s\n",
      "  Processed 2600/3185 demands... Elapsed: 38.09s\n",
      "  Processed 2700/3185 demands... Elapsed: 39.17s\n",
      "  Processed 2800/3185 demands... Elapsed: 40.24s\n",
      "  Processed 2900/3185 demands... Elapsed: 41.50s\n",
      "  Processed 3000/3185 demands... Elapsed: 42.84s\n",
      "  Processed 3100/3185 demands... Elapsed: 44.23s\n",
      "\n",
      "Finished finding K shortest paths in 45.87 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1: Total Duration=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1306, 1685, 536]\n",
      "  Path 2: Total Duration=1850 min, Min Capacity=46000.00 kg, Flights=[25, 1306, 1685, 536]\n",
      "  Path 3: Total Duration=1850 min, Min Capacity=47650.00 kg, Flights=[24, 1307, 1177, 536]\n",
      "---------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1: Total Duration=1655 min, Min Capacity=46000.00 kg, Flights=[27, 1376, 902]\n",
      "  Path 2: Total Duration=1655 min, Min Capacity=46000.00 kg, Flights=[26, 1376, 902]\n",
      "  Path 3: Total Duration=1850 min, Min Capacity=46000.00 kg, Flights=[27, 1347, 1694, 575]\n",
      "---------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1: Total Duration=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1390, 1703, 612]\n",
      "  Path 2: Total Duration=1850 min, Min Capacity=46000.00 kg, Flights=[28, 1390, 1703, 612]\n",
      "  Path 3: Total Duration=1850 min, Min Capacity=46000.00 kg, Flights=[30, 1391, 1189, 612]\n",
      "---------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1: Total Duration=2230 min, Min Capacity=47650.00 kg, Flights=[31, 1447, 914, 1884]\n",
      "  Path 2: Total Duration=2230 min, Min Capacity=46000.00 kg, Flights=[32, 1447, 914, 1884]\n",
      "  Path 3: Total Duration=2230 min, Min Capacity=46000.00 kg, Flights=[31, 1460, 914, 1884]\n",
      "---------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1: Total Duration=2075 min, Min Capacity=46000.00 kg, Flights=[34, 1486, 925]\n",
      "  Path 2: Total Duration=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1481, 1859]\n",
      "  Path 3: Total Duration=2310 min, Min Capacity=46000.00 kg, Flights=[34, 1503, 402, 1859]\n",
      "---------------\n",
      "\n",
      "... (output truncated) ...\n",
      "\n",
      "Found path results for 3185 ODTs.\n"
     ]
    }
   ],
   "source": [
    "# --- Flight Network Class (Refined) ---\n",
    "class FlightNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins):\n",
    "        print(\"\\nInitializing Flight Network...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "             raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "\n",
    "        # Efficient Lookups (using integer flight_id)\n",
    "        print(\"Precomputing lookups...\")\n",
    "        self.flight_data = schedule_df.set_index('flight_id').to_dict('index')\n",
    "        self.flights_by_origin = schedule_df.sort_values(by='dep_time').groupby('ori')['flight_id'].apply(list).to_dict()\n",
    "        self.demand_dict = demand_df.set_index('ODT').to_dict('index')\n",
    "\n",
    "        # Graph Representation: Adjacency list\n",
    "        # node -> list_of_outgoing_edges\n",
    "        # edge = {'neighbor': node_tuple, 'weight': float, 'flight_id': int|None, 'capacity': float, 'is_flight': bool}\n",
    "        self.graph = defaultdict(list)\n",
    "        self.build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, weight, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        \"\"\"Adds a directed edge if weight is valid.\"\"\"\n",
    "        if weight < 0: return # Skip invalid edges\n",
    "\n",
    "        # Ensure capacity is float/inf\n",
    "        cap = float(capacity) if isinstance(capacity, (int, float)) and math.isfinite(capacity) else float('inf')\n",
    "\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v,\n",
    "            'weight': float(weight), # Use float for time\n",
    "            'flight_id': flight_id, # Int or None\n",
    "            'capacity': cap,\n",
    "            'is_flight': is_flight\n",
    "        })\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds the time-expanded graph.\"\"\"\n",
    "        print(\"Building graph...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # --- Node Definitions ---\n",
    "        # ('source', odt_str) : Start node for a specific demand ODT\n",
    "        # ('sink', odt_str)   : End node for a specific demand ODT\n",
    "        # (flight_id_int, 'dep') : Departure event of a flight\n",
    "        # (flight_id_int, 'arr') : Arrival event of a flight\n",
    "\n",
    "        # 1. Flight Edges (Dep -> Arr)\n",
    "        for flight_id, flight in self.flight_data.items():\n",
    "            u_node = (flight_id, 'dep')\n",
    "            v_node = (flight_id, 'arr')\n",
    "            duration = flight['arr_time'] - flight['dep_time']\n",
    "            self._add_edge(u_node, v_node, duration, flight_id, flight['cap_kg'], is_flight=True)\n",
    "\n",
    "        # Pre-group demands by destination for sink edge efficiency\n",
    "        demands_by_dest = defaultdict(list)\n",
    "        for odt_id, demand_info in self.demand_dict.items():\n",
    "             demands_by_dest[demand_info['des']].append(odt_id)\n",
    "\n",
    "        # 2. Connection (Arr -> Dep) and Sink (Arr -> Sink) Edges\n",
    "        for flight1_id, flight1 in self.flight_data.items():\n",
    "            arrival_node = (flight1_id, 'arr')\n",
    "            arrival_time = flight1['arr_time']\n",
    "            arrival_airport = flight1['des']\n",
    "\n",
    "            # a) Sink Edges: Connect to sinks of demands ending here\n",
    "            for odt_id in demands_by_dest.get(arrival_airport, []):\n",
    "                 sink_node = ('sink', odt_id)\n",
    "                 self._add_edge(arrival_node, sink_node, weight=0, is_flight=False)\n",
    "\n",
    "            # b) Connection Edges: Connect to valid next flights\n",
    "            for flight2_id in self.flights_by_origin.get(arrival_airport, []):\n",
    "                flight2 = self.flight_data[flight2_id]\n",
    "                if flight2['dep_time'] >= arrival_time + self.min_connect_mins:\n",
    "                    departure_node = (flight2_id, 'dep')\n",
    "                    wait_time = flight2['dep_time'] - arrival_time\n",
    "                    self._add_edge(arrival_node, departure_node, weight=wait_time, is_flight=False)\n",
    "                # Since flights_by_origin lists are sorted, we could potentially break\n",
    "                # if wait_time gets excessively large, but finding K shortest needs exploration.\n",
    "\n",
    "        # 3. Source Edges (Source -> Dep)\n",
    "        for odt_id, demand in self.demand_dict.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            origin_airport = demand['ori']\n",
    "            ready_time = demand['time']\n",
    "\n",
    "            for flight_id in self.flights_by_origin.get(origin_airport, []):\n",
    "                flight = self.flight_data[flight_id]\n",
    "                if flight['dep_time'] >= ready_time:\n",
    "                    departure_node = (flight_id, 'dep')\n",
    "                    wait_time = flight['dep_time'] - ready_time\n",
    "                    self._add_edge(source_node, departure_node, weight=wait_time, is_flight=False)\n",
    "                # else: flight departs too early\n",
    "\n",
    "        print(f\"Graph building completed in {timer.time() - start_time:.2f} seconds.\")\n",
    "        est_nodes = len(self.demand_dict) * 2 + len(self.flight_data) * 2\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "\n",
    "\n",
    "    def _dijkstra(self, start_node, end_node, forbidden_edges=None, forbidden_nodes=None):\n",
    "        \"\"\"Finds shortest path using Dijkstra with tie-breaker.\"\"\"\n",
    "        global tie_breaker\n",
    "        if forbidden_edges is None: forbidden_edges = set()\n",
    "        if forbidden_nodes is None: forbidden_nodes = set()\n",
    "\n",
    "        # Priority Queue: (cost, tie_id, current_node, path_list)\n",
    "        # path_list = [{'node': node_tuple, 'edge_info': edge_dict_or_None}, ...]\n",
    "        pq = [(0.0, next(tie_breaker), start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        visited_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            cost, _, current_node, path_list = heapq.heappop(pq)\n",
    "\n",
    "            if cost > visited_costs[current_node]: continue\n",
    "            if current_node == end_node: return cost, path_list\n",
    "\n",
    "            if current_node not in self.graph: continue # Sink nodes have no outgoing\n",
    "\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                if neighbor in forbidden_nodes: continue\n",
    "\n",
    "                # Edge representation for forbidden check: (from_node, to_node, flight_id_or_None)\n",
    "                edge_rep = (current_node, neighbor, edge['flight_id'])\n",
    "                if edge_rep in forbidden_edges: continue\n",
    "\n",
    "                new_cost = cost + edge['weight']\n",
    "                if new_cost < visited_costs[neighbor]:\n",
    "                    visited_costs[neighbor] = new_cost\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    new_path = path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_cost, next(tie_breaker), neighbor, new_path))\n",
    "\n",
    "        return float('inf'), None\n",
    "\n",
    "\n",
    "    def _format_path(self, path_list, total_cost):\n",
    "        \"\"\"Formats Dijkstra/Yen's path list into desired output.\"\"\"\n",
    "        if not path_list or len(path_list) < 2: return None\n",
    "\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "\n",
    "        for step in path_list[1:]: # Skip source node\n",
    "            edge = step['edge_info']\n",
    "            if edge and edge['is_flight']:\n",
    "                flight_ids.append(edge['flight_id'])\n",
    "                min_capacity = min(min_capacity, edge['capacity'])\n",
    "\n",
    "        # If min_capacity is still inf (no flights), set to 0.0\n",
    "        min_cap_final = 0.0 if min_capacity == float('inf') else min_capacity\n",
    "\n",
    "        # total_cost from Dijkstra *is* (arrival_at_sink - demand_ready_time)\n",
    "        return {\n",
    "            'total_time': total_cost,\n",
    "            'flight_ids': flight_ids,\n",
    "            'min_capacity': min_cap_final\n",
    "        }\n",
    "\n",
    "\n",
    "    def find_k_shortest_paths(self):\n",
    "        \"\"\"Finds K shortest paths for each demand using Yen's.\"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths for {len(self.demand_dict)} demands...\")\n",
    "        all_results = {}\n",
    "        total_demands = len(self.demand_dict)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for i, (odt_id, demand) in enumerate(self.demand_dict.items()):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                print(f\"  Processed {i+1}/{total_demands} demands... Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            end_node = ('sink', odt_id)\n",
    "\n",
    "            A = [] # Stores final paths: (cost, path_list)\n",
    "            B = [] # Candidate heap: (cost, tie_id, path_list)\n",
    "\n",
    "            # 1. Find first shortest path\n",
    "            cost1, path1 = self._dijkstra(start_node, end_node)\n",
    "            if path1:\n",
    "                A.append((cost1, path1))\n",
    "            else:\n",
    "                all_results[odt_id] = []\n",
    "                continue # No path exists\n",
    "\n",
    "            # 2. Find paths k = 2 to K\n",
    "            for k in range(1, self.k_paths):\n",
    "                if k > len(A): break # Cannot find k if k-1 doesn't exist\n",
    "\n",
    "                prev_cost, prev_path = A[k-1] # Path k-1 (0-indexed)\n",
    "\n",
    "                # Iterate through nodes of path k-1 to find spur points\n",
    "                for i in range(len(prev_path) - 1): # Spur node cannot be sink\n",
    "                    spur_node = prev_path[i]['node']\n",
    "                    root_path = prev_path[:i+1]\n",
    "                    root_cost = sum(s['edge_info']['weight'] for s in root_path[1:] if s['edge_info'])\n",
    "\n",
    "                    forbidden_nodes = {step['node'] for step in root_path[:-1]}\n",
    "                    forbidden_edges = set()\n",
    "\n",
    "                    # Forbid edges leaving spur node used by previous paths (A[0]..A[k-1]) sharing the same root\n",
    "                    for cost_j, path_j in A: # Check all paths found so far in A\n",
    "                        if len(path_j) > i + 1:\n",
    "                            # Check if node sequence of root matches\n",
    "                            if [step['node'] for step in path_j[:i+1]] == [step['node'] for step in root_path]:\n",
    "                                edge_info_j = path_j[i+1]['edge_info']\n",
    "                                if edge_info_j:\n",
    "                                    edge_rep = (spur_node, edge_info_j['neighbor'], edge_info_j['flight_id'])\n",
    "                                    forbidden_edges.add(edge_rep)\n",
    "\n",
    "                    # Calculate spur path\n",
    "                    spur_cost_delta, spur_path_segment = self._dijkstra(spur_node, end_node, forbidden_edges, forbidden_nodes)\n",
    "\n",
    "                    if spur_path_segment:\n",
    "                        # Combine root and spur\n",
    "                        full_path = root_path + spur_path_segment[1:]\n",
    "                        total_new_cost = root_cost + spur_cost_delta\n",
    "                        # Use tuple representation of nodes for quick duplicate check in B (optional but good practice)\n",
    "                        # path_node_tuple = tuple(item['node'] for item in full_path)\n",
    "                        heapq.heappush(B, (total_new_cost, next(tie_breaker), full_path))\n",
    "\n",
    "                # Find best candidate in B not already in A\n",
    "                found_next = False\n",
    "                while B:\n",
    "                    potential_cost, _, potential_path = heapq.heappop(B)\n",
    "                    # Check if path (by node sequence) is already in A\n",
    "                    potential_nodes = tuple(item['node'] for item in potential_path)\n",
    "                    is_in_A = any(tuple(item['node'] for item in path_a) == potential_nodes for cost_a, path_a in A)\n",
    "\n",
    "                    if not is_in_A:\n",
    "                        A.append((potential_cost, potential_path))\n",
    "                        found_next = True\n",
    "                        break # Found path k\n",
    "\n",
    "                if not found_next: break # No more paths found for this demand\n",
    "\n",
    "            # Format results for ODT\n",
    "            formatted_paths = []\n",
    "            A.sort(key=lambda x: x[0]) # Ensure sorted output\n",
    "            for cost, path_list in A:\n",
    "                 formatted = self._format_path(path_list, cost)\n",
    "                 if formatted: formatted_paths.append(formatted)\n",
    "            all_results[odt_id] = formatted_paths\n",
    "\n",
    "        print(f\"\\nFinished finding K shortest paths in {timer.time() - start_run_time:.2f} seconds.\")\n",
    "        return all_results\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "print(\"Starting flight path analysis...\")\n",
    "\n",
    "# 1. Read Data\n",
    "schedule_data = read_capacity(CAPACITY_FILE, airport_substitutions)\n",
    "demand_data = read_market(MARKET_FILE, airport_substitutions)\n",
    "#print(demand_data.head())\n",
    "\n",
    "# 2. Initialize and Run only if data is valid\n",
    "if not schedule_data.empty and not demand_data.empty:\n",
    "    try:\n",
    "        flight_network = FlightNetwork(schedule_data, demand_data, K_PATHS, MIN_CONNECT_MINS)\n",
    "        k_shortest_paths = flight_network.find_k_shortest_paths()\n",
    "\n",
    "        # 3. Output Sample Results\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample) ---\")\n",
    "        output_count = 0\n",
    "        for odt, paths in k_shortest_paths.items():\n",
    "            if output_count < 5: # Print details for first 5 demands\n",
    "                demand_info = flight_network.demand_dict.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        # The 'total_time' is already (arrival - ready_time)\n",
    "                        print(f\"  Path {i+1}: Total Duration={path['total_time']:.0f} min, Min Capacity={path['min_capacity']:.2f} kg, Flights={path['flight_ids']}\")\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 15)\n",
    "            elif output_count == 5:\n",
    "                 print(\"\\n... (output truncated) ...\")\n",
    "                 break\n",
    "            output_count += 1\n",
    "\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths)} ODTs.\")\n",
    "        # 'k_shortest_paths' dictionary holds all results\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\nError: Could not read valid schedule or demand data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/sbq4d0yx2vdcrx0_5_cy2hmh0000gn/T/ipykernel_21888/3429030786.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  paths_df[0][0], flight_network.flight_data[536]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'total_time': 1850.0,\n",
       "  'flight_ids': [24, 1306, 1685, 536],\n",
       "  'min_capacity': 47650.0},\n",
       " {'flight_number': 'GB880',\n",
       "  'ori': 'CVG',\n",
       "  'des': 'LAX',\n",
       "  'aircraft_type': '76Y',\n",
       "  'dep_time': 2640,\n",
       "  'arr_time': 2930,\n",
       "  'cap_kg': 47650})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_df = pd.DataFrame.from_dict(k_shortest_paths, orient='index')\n",
    "paths_df[0][0], flight_network.flight_data[536]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, K_PATHS, MIN_CONNECT_MINS, MAX_CONNECT_MINS):\n",
    "        # Settings\n",
    "        self.k_paths = K_PATHS\n",
    "        self.min_connect_mins = MIN_CONNECT_MINS\n",
    "        self.max_connect_mins = MAX_CONNECT_MINS\n",
    "        \n",
    "        # DATA\n",
    "        self.schedule_df = schedule_df\n",
    "        self.demand_df = demand_df\n",
    "        self.airports = set(schedule_df['ori']).union(set(schedule_df['des']))\n",
    "\n",
    "        self.flight_data_dict = dict(zip(schedule_df['flight_id'], schedule_df.to_dict(orient='records')))\n",
    "        self.flight_capacity_dict = dict(zip(schedule_df['flight_id'], schedule_df['cap_kg']))  \n",
    "        self.flight_id_to_orides = {row['flight_id']: (row['ori'], row['des']) for _, row in schedule_df.iterrows()}\n",
    "        self.flight_id_to_dep_arr = {row['flight_id']: (row['dep_time'], row['arr_time']) for _, row in schedule_df.iterrows()}\n",
    "        self.orides_to_flight_ids = schedule_df.groupby(['ori', 'des'])['flight_id'].apply(list).to_dict()\n",
    "        self.origin_to_orides = schedule_df.groupby('ori')['des'].apply(list).to_dict()\n",
    "        \n",
    "        self.demand_dict = dict(zip(demand_df['ODT'], demand_df.to_dict(orient='records')))\n",
    "        self.ODT_to_amount = dict(zip(demand_df['ODT'], demand_df['demand']))\n",
    "        self.ODT_to_orides = {row['ODT']: (row['ori'], row['des']) for _, row in demand_df.iterrows()}\n",
    "        \n",
    "    # OFC DONT USE ADJENCY MATRIX BUT FASTER DATASTRUCTURES WITH SIMILAR FUNCTIONALITY\n",
    "        # Sources to Flights connections - |D| x |F| - demand_id x flight_id - 1 to next, first of unique orides, flights - that start \n",
    "        #           from a given origin, else 0\n",
    "        \n",
    "        # Flights to Flights connections - |F| x |F| - flight_id x flight_id - 1 to next, first of unique orides, flights \n",
    "        #           zero to next same orides flights - free connection - trick to compact the network\n",
    "        #           -1 if no connection\n",
    "        \n",
    "        # Flights to Sinks connections - |F| x |D| - flight_id x demand_id -\n",
    "        \n",
    "        # Time Distance Between each airport - |A| x |A| - for aproximation of the time between each airport\n",
    "        # orides pair to time \n",
    "        \n",
    "        self.build_graph()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "   ori  des     demand  time           ODT\n",
      "0  AMS  LAX  4366.6250  1080  AMS/LAX/1080\n",
      "1  AMS  LAX  2481.6250  2520  AMS/LAX/2520\n",
      "2  AMS  LAX  3985.1125  3960  AMS/LAX/3960\n",
      "3  AMS  LAX  3415.7500  5400  AMS/LAX/5400\n",
      "4  AMS  LAX  3933.5000  6840  AMS/LAX/6840\n",
      "\n",
      "Initializing Flight Network...\n",
      "Precomputing flight data lookups...\n",
      "Building graph edges...\n",
      "Adding flight leg edges...\n",
      "Added 2057 flight leg edges.\n",
      "Adding connection and sink edges...\n",
      "Added 96571 connection edges.\n",
      "Added 121331 sink edges.\n",
      "Adding source edges...\n",
      "Added 99076 source edges.\n",
      "Graph building completed in 0.31 seconds.\n",
      "Graph nodes estimated around: 10484\n",
      "\n",
      "Finding 3 shortest paths for 3185 demands...\n",
      "  Processed 100/3185 demands... Elapsed: 0.90s\n",
      "  Processed 200/3185 demands... Elapsed: 2.12s\n",
      "  Processed 300/3185 demands... Elapsed: 3.34s\n",
      "  Processed 400/3185 demands... Elapsed: 4.72s\n",
      "  Processed 500/3185 demands... Elapsed: 6.66s\n",
      "  Processed 600/3185 demands... Elapsed: 7.73s\n",
      "  Processed 700/3185 demands... Elapsed: 8.85s\n",
      "  Processed 800/3185 demands... Elapsed: 10.42s\n",
      "  Processed 900/3185 demands... Elapsed: 11.05s\n",
      "  Processed 1000/3185 demands... Elapsed: 11.92s\n",
      "  Processed 1100/3185 demands... Elapsed: 12.98s\n",
      "  Processed 1200/3185 demands... Elapsed: 14.57s\n",
      "  Processed 1300/3185 demands... Elapsed: 16.42s\n",
      "  Processed 1400/3185 demands... Elapsed: 17.91s\n",
      "  Processed 1500/3185 demands... Elapsed: 19.76s\n",
      "  Processed 1600/3185 demands... Elapsed: 21.10s\n",
      "  Processed 1700/3185 demands... Elapsed: 22.78s\n",
      "  Processed 1800/3185 demands... Elapsed: 24.66s\n",
      "  Processed 1900/3185 demands... Elapsed: 26.81s\n",
      "  Processed 2000/3185 demands... Elapsed: 28.53s\n",
      "  Processed 2100/3185 demands... Elapsed: 29.61s\n",
      "  Processed 2200/3185 demands... Elapsed: 31.27s\n",
      "  Processed 2300/3185 demands... Elapsed: 33.57s\n",
      "  Processed 2400/3185 demands... Elapsed: 34.72s\n",
      "  Processed 2500/3185 demands... Elapsed: 36.48s\n",
      "  Processed 2600/3185 demands... Elapsed: 37.96s\n",
      "  Processed 2700/3185 demands... Elapsed: 38.98s\n",
      "  Processed 2800/3185 demands... Elapsed: 40.09s\n",
      "  Processed 2900/3185 demands... Elapsed: 41.32s\n",
      "  Processed 3000/3185 demands... Elapsed: 42.72s\n",
      "  Processed 3100/3185 demands... Elapsed: 44.03s\n",
      "\n",
      "Finished finding K shortest paths in 45.67 seconds.\n",
      "\n",
      "--- K Shortest Paths Results (Sample) ---\n",
      "ODT: AMS/LAX/1080 (Demand: AMS-LAX @ 1080)\n",
      "  Path 1:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 24(AMS-LEJ@1235) -> 1306(LEJ-MXP@1530) -> 1685(MXP-CVG@1795) -> 536(CVG-LAX@2640)\n",
      "    Min Capacity (kg): 47650.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 25(AMS-LEJ@1330) -> 1306(LEJ-MXP@1530) -> 1685(MXP-CVG@1795) -> 536(CVG-LAX@2640)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 24(AMS-LEJ@1235) -> 1307(LEJ-JFK@1565) -> 1177(JFK-CVG@2340) -> 536(CVG-LAX@2640)\n",
      "    Min Capacity (kg): 47650.00\n",
      "--------------------\n",
      "ODT: AMS/LAX/2520 (Demand: AMS-LAX @ 2520)\n",
      "  Path 1:\n",
      "    Total Time (mins): 1655.00\n",
      "    Flights: 27(AMS-LEJ@2675) -> 1376(LEJ-FRA@3070) -> 902(FRA-LAX@3440)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 1655.00\n",
      "    Flights: 26(AMS-LEJ@2770) -> 1376(LEJ-FRA@3070) -> 902(FRA-LAX@3440)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 27(AMS-LEJ@2675) -> 1347(LEJ-MXP@2970) -> 1694(MXP-CVG@3240) -> 575(CVG-LAX@4080)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "ODT: AMS/LAX/3960 (Demand: AMS-LAX @ 3960)\n",
      "  Path 1:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 30(AMS-LEJ@4115) -> 1390(LEJ-MXP@4410) -> 1703(MXP-CVG@4680) -> 612(CVG-LAX@5520)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 28(AMS-LEJ@4210) -> 1390(LEJ-MXP@4410) -> 1703(MXP-CVG@4680) -> 612(CVG-LAX@5520)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 1850.00\n",
      "    Flights: 30(AMS-LEJ@4115) -> 1391(LEJ-JFK@4445) -> 1189(JFK-CVG@5220) -> 612(CVG-LAX@5520)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "ODT: AMS/LAX/5400 (Demand: AMS-LAX @ 5400)\n",
      "  Path 1:\n",
      "    Total Time (mins): 2230.00\n",
      "    Flights: 31(AMS-LEJ@5555) -> 1447(LEJ-FRA@5935) -> 914(FRA-SEA@6725) -> 1884(SEA-LAX@7475)\n",
      "    Min Capacity (kg): 47650.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 2230.00\n",
      "    Flights: 32(AMS-LEJ@5650) -> 1447(LEJ-FRA@5935) -> 914(FRA-SEA@6725) -> 1884(SEA-LAX@7475)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 2230.00\n",
      "    Flights: 31(AMS-LEJ@5555) -> 1460(LEJ-FRA@5950) -> 914(FRA-SEA@6725) -> 1884(SEA-LAX@7475)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "ODT: AMS/LAX/6840 (Demand: AMS-LAX @ 6840)\n",
      "  Path 1:\n",
      "    Total Time (mins): 2075.00\n",
      "    Flights: 34(AMS-LEJ@7090) -> 1486(LEJ-FRA@8030) -> 925(FRA-LAX@8180)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 2310.00\n",
      "    Flights: 34(AMS-LEJ@7090) -> 1481(LEJ-PVG@7530) -> 1859(PVG-LAX@8415)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 2310.00\n",
      "    Flights: 34(AMS-LEJ@7090) -> 1503(LEJ-BRU@7330) -> 402(BRU-PVG@7530) -> 1859(PVG-LAX@8415)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "ODT: AMS/LAX/8280 (Demand: AMS-LAX @ 8280)\n",
      "  No paths found.\n",
      "--------------------\n",
      "ODT: AMS/LAX/9720 (Demand: AMS-LAX @ 9720)\n",
      "  No paths found.\n",
      "--------------------\n",
      "ODT: BAH/AMS/1080 (Demand: BAH-AMS @ 1080)\n",
      "  Path 1:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 136(BAH-DXB@1345) -> 780(DXB-LEJ@1915) -> 1380(LEJ-AMS@3035)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 166(BAH-LEJ@2030) -> 1380(LEJ-AMS@3035)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 136(BAH-DXB@1345) -> 782(DXB-LHE@1510) -> 1541(LHE-BAH@1785) -> 147(BAH-MXP@2255) -> 1683(MXP-LEJ@2765) -> 1380(LEJ-AMS@3035)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "ODT: BAH/AMS/2520 (Demand: BAH-AMS @ 2520)\n",
      "  Path 1:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 159(BAH-DXB@2785) -> 784(DXB-LEJ@3355) -> 1393(LEJ-AMS@4475)\n",
      "    Min Capacity (kg): 47650.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 188(BAH-LEJ@3485) -> 1393(LEJ-AMS@4475)\n",
      "    Min Capacity (kg): 47650.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 2050.00\n",
      "    Flights: 159(BAH-DXB@2785) -> 786(DXB-LHE@2950) -> 1542(LHE-BAH@3225) -> 186(BAH-LEJ@3795) -> 1393(LEJ-AMS@4475)\n",
      "    Min Capacity (kg): 47650.00\n",
      "--------------------\n",
      "ODT: BAH/AMS/3960 (Demand: BAH-AMS @ 3960)\n",
      "  Path 1:\n",
      "    Total Time (mins): 3040.00\n",
      "    Flights: 192(BAH-EMA@4980) -> 863(EMA-AMS@6915)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 2:\n",
      "    Total Time (mins): 3040.00\n",
      "    Flights: 201(BAH-DWC@4345) -> 771(DWC-BAH@4520) -> 192(BAH-EMA@4980) -> 863(EMA-AMS@6915)\n",
      "    Min Capacity (kg): 46000.00\n",
      "  Path 3:\n",
      "    Total Time (mins): 3040.00\n",
      "    Flights: 192(BAH-EMA@4980) -> 836(EMA-BRU@5700) -> 389(BRU-EMA@5860) -> 863(EMA-AMS@6915)\n",
      "    Min Capacity (kg): 46000.00\n",
      "--------------------\n",
      "\n",
      "... (output truncated for brevity) ...\n",
      "\n",
      "Found path results for 3185 ODTs.\n"
     ]
    }
   ],
   "source": [
    "# --- Flight Network Class (Simplified) ---\n",
    "class FlightNetwork:\n",
    "    def __init__(self, schedule_df, demand_df, k_paths, min_connect_mins):\n",
    "        print(\"\\nInitializing Flight Network...\")\n",
    "        if schedule_df.empty or demand_df.empty:\n",
    "             raise ValueError(\"Schedule or Demand dataframe is empty.\")\n",
    "\n",
    "        self.k_paths = k_paths\n",
    "        self.min_connect_mins = min_connect_mins\n",
    "        self.schedule_df = schedule_df # Keep original reference if needed\n",
    "        self.demand_df = demand_df     # Keep original reference if needed\n",
    "\n",
    "        # --- Precompute Lookups for Efficiency ---\n",
    "        print(\"Precomputing flight data lookups...\")\n",
    "        # flight_id (int index) -> flight details dictionary\n",
    "        self.flight_data = self.schedule_df.set_index('flight_id').to_dict('index')\n",
    "\n",
    "        # ori -> list of flight_ids sorted by dep_time\n",
    "        self.flights_by_origin = defaultdict(list)\n",
    "        # Sort once and group\n",
    "        schedule_sorted = self.schedule_df.sort_values(by=['ori', 'dep_time'])\n",
    "        for idx, row in schedule_sorted.iterrows():\n",
    "            self.flights_by_origin[row['ori']].append(row['flight_id']) # Store flight_id (int)\n",
    "\n",
    "        # ODT (str) -> demand details dictionary\n",
    "        self.demand_dict = self.demand_df.set_index('ODT').to_dict('index')\n",
    "\n",
    "        # --- Build Graph ---\n",
    "        self.graph = defaultdict(list) # Adjacency list: node -> list of edge dicts\n",
    "        self.build_graph()\n",
    "\n",
    "    def _add_edge(self, u, v, weight, flight_id=None, capacity=float('inf'), is_flight=False):\n",
    "        \"\"\"Adds a directed edge with attributes to the graph.\"\"\"\n",
    "        # Basic check for valid edge\n",
    "        if weight < 0 or u is None or v is None:\n",
    "            # print(f\"Warning: Invalid edge skipped: {u} -> {v} (Weight: {weight})\")\n",
    "            return\n",
    "\n",
    "        # Ensure capacity is float or inf\n",
    "        if not isinstance(capacity, (int, float)):\n",
    "            capacity = float('inf')\n",
    "        elif not math.isfinite(capacity):\n",
    "             capacity = float('inf')\n",
    "\n",
    "        self.graph[u].append({\n",
    "            'neighbor': v,          # Target node tuple\n",
    "            'weight': float(weight),# Time cost (float for precision)\n",
    "            'flight_id': flight_id, # Integer flight ID or None\n",
    "            'capacity': capacity,   # Float capacity (or inf)\n",
    "            'is_flight': is_flight  # Boolean flag\n",
    "        })\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Builds the graph with explicit source/sink per demand.\"\"\"\n",
    "        print(\"Building graph edges...\")\n",
    "        start_time = timer.time()\n",
    "\n",
    "        # Node Types:\n",
    "        # ('source', odt_id_str)\n",
    "        # ('sink', odt_id_str)\n",
    "        # (flight_id_int, 'dep')\n",
    "        # (flight_id_int, 'arr')\n",
    "\n",
    "        # 1. Add Flight Edges (Dep -> Arr)\n",
    "        print(\"Adding flight leg edges...\")\n",
    "        flight_edge_count = 0\n",
    "        for flight_id, flight in self.flight_data.items(): # flight_id is int\n",
    "            u_node = (flight_id, 'dep')\n",
    "            v_node = (flight_id, 'arr')\n",
    "            duration = flight['arr_time'] - flight['dep_time']\n",
    "            if duration >= 0: # Should be true based on read_capacity filter\n",
    "                self._add_edge(u_node, v_node, duration, flight_id, flight['cap_kg'], is_flight=True)\n",
    "                flight_edge_count += 1\n",
    "        print(f\"Added {flight_edge_count} flight leg edges.\")\n",
    "\n",
    "        # Pre-group demands by destination for faster sink edge creation\n",
    "        demands_by_dest = defaultdict(list)\n",
    "        for odt_id, demand_info in self.demand_dict.items():\n",
    "             demands_by_dest[demand_info['des']].append(odt_id)\n",
    "\n",
    "        # 2. Add Connection (Arr -> Dep) and Sink (Arr -> Sink) Edges\n",
    "        print(\"Adding connection and sink edges...\")\n",
    "        connection_count = 0\n",
    "        sink_edge_count = 0\n",
    "        for flight1_id, flight1 in self.flight_data.items():\n",
    "            arrival_node = (flight1_id, 'arr')\n",
    "            arrival_time = flight1['arr_time']\n",
    "            arrival_airport = flight1['des']\n",
    "\n",
    "            # a) Sink Edges: Connect flight arrival to relevant demand sinks\n",
    "            if arrival_airport in demands_by_dest:\n",
    "                 for odt_id in demands_by_dest[arrival_airport]:\n",
    "                     # This flight arrives at the destination needed by odt_id\n",
    "                     sink_node = ('sink', odt_id)\n",
    "                     self._add_edge(arrival_node, sink_node, weight=0, is_flight=False)\n",
    "                     sink_edge_count += 1\n",
    "\n",
    "            # b) Connection Edges: Connect flight arrival to potential next flights\n",
    "            if arrival_airport in self.flights_by_origin:\n",
    "                # Iterate through flights departing from arrival_airport (sorted by dep_time)\n",
    "                for flight2_id in self.flights_by_origin[arrival_airport]:\n",
    "                    flight2 = self.flight_data[flight2_id]\n",
    "                    departure_time = flight2['dep_time']\n",
    "                    connection_wait_time = departure_time - arrival_time\n",
    "\n",
    "                    # Check minimum connection time\n",
    "                    if connection_wait_time >= self.min_connect_mins:\n",
    "                        departure_node = (flight2_id, 'dep')\n",
    "                        self._add_edge(arrival_node, departure_node, weight=connection_wait_time, is_flight=False)\n",
    "                        connection_count += 1\n",
    "                    # else: Flight departs too soon for connection\n",
    "\n",
    "                    # Optimization idea (Optional): If flights are sorted by dep_time,\n",
    "                    # and connection_wait_time exceeds a reasonable MAX_CONNECT_MINS,\n",
    "                    # we could potentially 'break' early for this arrival_node.\n",
    "                    # However, without an explicit MAX limit, we check all possibilities.\n",
    "        print(f\"Added {connection_count} connection edges.\")\n",
    "        print(f\"Added {sink_edge_count} sink edges.\")\n",
    "\n",
    "        # 3. Add Source Edges (Source -> Dep)\n",
    "        print(\"Adding source edges...\")\n",
    "        source_edge_count = 0\n",
    "        for odt_id, demand in self.demand_dict.items():\n",
    "            source_node = ('source', odt_id)\n",
    "            origin_airport = demand['ori']\n",
    "            ready_time = demand['time']\n",
    "\n",
    "            if origin_airport in self.flights_by_origin:\n",
    "                # Iterate flights from origin (sorted by dep_time)\n",
    "                for flight_id in self.flights_by_origin[origin_airport]:\n",
    "                    flight = self.flight_data[flight_id]\n",
    "                    departure_time = flight['dep_time']\n",
    "\n",
    "                    # Connect if flight departs at or after ready time\n",
    "                    if departure_time >= ready_time:\n",
    "                        initial_wait_time = departure_time - ready_time\n",
    "                        departure_node = (flight_id, 'dep')\n",
    "                        self._add_edge(source_node, departure_node, weight=initial_wait_time, is_flight=False)\n",
    "                        source_edge_count += 1\n",
    "                    # else: Flight departs before demand is ready\n",
    "\n",
    "                    # Optimization: Since flights are sorted, if the current flight\n",
    "                    # departs *much* later than ready_time, subsequent flights will\n",
    "                    # depart even later. Could break if wait time exceeds a threshold,\n",
    "                    # but connecting to all valid first flights is safer for finding\n",
    "                    # the true K shortest paths.\n",
    "            else: # Handle case where no flights leave from the demand origin\n",
    "                 print(f\"Warning: No flights found departing from origin '{origin_airport}' for ODT '{odt_id}'. No paths possible.\")\n",
    "                 pass # Dijkstra will handle this by finding no path from source\n",
    "\n",
    "        print(f\"Added {source_edge_count} source edges.\")\n",
    "        end_time = timer.time()\n",
    "        print(f\"Graph building completed in {end_time - start_time:.2f} seconds.\")\n",
    "        # Estimate node count (sources + sinks + 2*flights)\n",
    "        est_nodes = len(self.demand_dict) * 2 + len(self.flight_data) * 2\n",
    "        print(f\"Graph nodes estimated around: {est_nodes}\")\n",
    "\n",
    "\n",
    "    def _dijkstra(self, start_node, end_node, forbidden_edges=None, forbidden_nodes=None):\n",
    "        \"\"\"\n",
    "        Finds the shortest path using Dijkstra's algorithm. (Modified for Yen's)\n",
    "        Uses a tie-breaker for heapq stability.\n",
    "        \"\"\"\n",
    "        global tie_breaker # Use the global counter\n",
    "\n",
    "        if forbidden_edges is None: forbidden_edges = set()\n",
    "        if forbidden_nodes is None: forbidden_nodes = set()\n",
    "\n",
    "        # Priority Queue: (cost, tie_breaker_id, current_node, path_list)\n",
    "        # path_list stores: [{'node': node_tuple, 'edge_info': edge_dict_or_None}, ...]\n",
    "        pq = [(0.0, next(tie_breaker), start_node, [{'node': start_node, 'edge_info': None}])]\n",
    "        # visited_costs stores the minimum cost found *so far* to reach a node\n",
    "        visited_costs = defaultdict(lambda: float('inf'))\n",
    "        visited_costs[start_node] = 0.0\n",
    "\n",
    "        while pq:\n",
    "            current_cost, _, current_node, current_path_list = heapq.heappop(pq)\n",
    "\n",
    "            # Optimization: If we already found a shorter path to this node, skip\n",
    "            if current_cost > visited_costs[current_node]:\n",
    "                continue\n",
    "\n",
    "            # Goal reached\n",
    "            if current_node == end_node:\n",
    "                return current_cost, current_path_list\n",
    "\n",
    "            # Explore neighbors\n",
    "            if current_node not in self.graph: # Node might not have outgoing edges (e.g., sink)\n",
    "                continue\n",
    "\n",
    "            for edge in self.graph[current_node]:\n",
    "                neighbor = edge['neighbor']\n",
    "                weight = edge['weight']\n",
    "                edge_flight_id = edge['flight_id'] # Integer or None\n",
    "\n",
    "                # --- Check Forbidden Nodes and Edges ---\n",
    "                if neighbor in forbidden_nodes:\n",
    "                    continue\n",
    "\n",
    "                # Edge representation for forbidden check: (from_node, to_node, flight_id_or_None)\n",
    "                edge_representation = (current_node, neighbor, edge_flight_id)\n",
    "                if edge_representation in forbidden_edges:\n",
    "                    continue\n",
    "                # --- End Forbidden Check ---\n",
    "\n",
    "                new_cost = current_cost + weight\n",
    "\n",
    "                # Relaxation: If this is a shorter path to neighbor\n",
    "                if new_cost < visited_costs[neighbor]:\n",
    "                    visited_costs[neighbor] = new_cost\n",
    "                    # Create the next step in the path list, storing the edge *leading* to the neighbor\n",
    "                    new_step = {'node': neighbor, 'edge_info': edge}\n",
    "                    new_path_list = current_path_list + [new_step]\n",
    "                    heapq.heappush(pq, (new_cost, next(tie_breaker), neighbor, new_path_list))\n",
    "\n",
    "        return float('inf'), None # No path found\n",
    "\n",
    "\n",
    "    def _format_path_output(self, path_list, total_cost):\n",
    "        \"\"\"Formats the raw path list from Dijkstra/Yen's into the desired output.\"\"\"\n",
    "        if not path_list or len(path_list) < 2: # Need source and at least one more node\n",
    "            return None\n",
    "\n",
    "        flight_ids = []\n",
    "        min_capacity = float('inf')\n",
    "\n",
    "        # Iterate through the path steps to find flight segments\n",
    "        # path_list = [{'node': n0, 'edge': None}, {'node': n1, 'edge': e01}, {'node': n2, 'edge': e12}, ...]\n",
    "        for step in path_list[1:]: # Skip the source node which has no incoming edge_info\n",
    "            edge_info = step['edge_info']\n",
    "            if edge_info and edge_info['is_flight']:\n",
    "                flight_id = edge_info['flight_id']\n",
    "                capacity = edge_info['capacity']\n",
    "                if flight_id is not None: # Should always be true if is_flight\n",
    "                    flight_ids.append(flight_id)\n",
    "                    # Ensure capacity is finite for comparison\n",
    "                    current_cap = capacity if math.isfinite(capacity) else float('inf')\n",
    "                    min_capacity = min(min_capacity, current_cap)\n",
    "\n",
    "        # If no flights were taken, min_capacity remains 'inf'. Set to 0 or None? Using 0.\n",
    "        if min_capacity == float('inf'):\n",
    "            min_capacity = 0.0\n",
    "\n",
    "        return {\n",
    "            'total_time': total_cost, # Time from ready_time to final arrival\n",
    "            'flight_ids': flight_ids, # List of integer flight IDs\n",
    "            'min_capacity': min_capacity\n",
    "        }\n",
    "\n",
    "\n",
    "    def find_k_shortest_paths(self):\n",
    "        \"\"\"\n",
    "        Finds the K shortest paths for each demand ODT using Yen's algorithm.\n",
    "        \"\"\"\n",
    "        print(f\"\\nFinding {self.k_paths} shortest paths for {len(self.demand_dict)} demands...\")\n",
    "        all_paths_results = {}\n",
    "        demand_count = 0\n",
    "        total_demands = len(self.demand_dict)\n",
    "        start_run_time = timer.time()\n",
    "\n",
    "        for odt_id, demand in self.demand_dict.items():\n",
    "            demand_count += 1\n",
    "            if demand_count % 100 == 0: # Progress indicator\n",
    "                elapsed = timer.time() - start_run_time\n",
    "                print(f\"  Processed {demand_count}/{total_demands} demands... Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "            start_node = ('source', odt_id)\n",
    "            end_node = ('sink', odt_id)   # Unique sink for this demand\n",
    "\n",
    "            A = [] # Stores final K paths: (cost, path_list)\n",
    "            B = [] # Candidate paths heap: (cost, tie_breaker, path_list)\n",
    "\n",
    "            # 1. Find the first shortest path\n",
    "            cost1, path_list1 = self._dijkstra(start_node, end_node)\n",
    "\n",
    "            if path_list1:\n",
    "                A.append((cost1, path_list1))\n",
    "                # Don't add to B yet, B is for *deviations* from paths in A\n",
    "            else:\n",
    "                all_paths_results[odt_id] = [] # No paths found\n",
    "                continue\n",
    "\n",
    "            # 2. Iterate to find paths k = 2 to K\n",
    "            for k in range(1, self.k_paths):\n",
    "                if k > len(A): # Cannot find k if k-1 doesn't exist\n",
    "                    break\n",
    "\n",
    "                # Get the (k-1)th shortest path (index k-1)\n",
    "                prev_cost, prev_path_list = A[k-1]\n",
    "\n",
    "                # Iterate through nodes in the (k-1)th path to find spur points\n",
    "                # Path structure: [{'node':n0,'edge':None},{'node':n1,'edge':e01},...]\n",
    "                for i in range(len(prev_path_list) - 1): # Spur node cannot be the sink\n",
    "                    spur_node_info = prev_path_list[i]\n",
    "                    spur_node = spur_node_info['node']\n",
    "\n",
    "                    # Root path: segment of the (k-1)th path up to spur_node\n",
    "                    root_path_list = prev_path_list[:i+1]\n",
    "                    # Calculate cost of the root path by summing edge weights\n",
    "                    root_cost = sum(step['edge_info']['weight'] for step in root_path_list[1:] if step['edge_info'])\n",
    "\n",
    "                    forbidden_edges_yen = set()\n",
    "                    forbidden_nodes_yen = set()\n",
    "\n",
    "                    # Forbid nodes in the root path (excluding spur node itself)\n",
    "                    for step in root_path_list[:-1]:\n",
    "                         forbidden_nodes_yen.add(step['node'])\n",
    "\n",
    "                    # Forbid the edge *leaving* the spur node if a previous path in A (0..k-1)\n",
    "                    # shares the same root path.\n",
    "                    edge_leaving_spur_in_prev = prev_path_list[i+1]['edge_info'] if (i+1 < len(prev_path_list)) else None\n",
    "\n",
    "                    for path_idx in range(k): # Check paths A[0] to A[k-1]\n",
    "                         cost_j, path_list_j = A[path_idx]\n",
    "                         # Check if path_j is long enough and shares the same root *node sequence*\n",
    "                         if len(path_list_j) > i + 1:\n",
    "                             path_j_root_nodes = [step['node'] for step in path_list_j[:i+1]]\n",
    "                             root_path_nodes = [step['node'] for step in root_path_list]\n",
    "                             if path_j_root_nodes == root_path_nodes:\n",
    "                                 # Paths share the root. Forbid the edge leaving the spur node in path_j.\n",
    "                                 edge_info_j = path_list_j[i+1]['edge_info']\n",
    "                                 if edge_info_j:\n",
    "                                     forbidden_edge_j = (spur_node, edge_info_j['neighbor'], edge_info_j['flight_id'])\n",
    "                                     forbidden_edges_yen.add(forbidden_edge_j)\n",
    "\n",
    "\n",
    "                    # --- Calculate spur path ---\n",
    "                    spur_cost_delta, spur_path_segment_list = self._dijkstra(spur_node, end_node,\n",
    "                                                                             forbidden_edges=forbidden_edges_yen,\n",
    "                                                                             forbidden_nodes=forbidden_nodes_yen)\n",
    "\n",
    "                    # If a valid spur path is found from spur_node to end_node\n",
    "                    if spur_path_segment_list:\n",
    "                        # Combine root and spur paths\n",
    "                        # spur_path_segment starts with spur_node (edge=None), which is the last node of root_path\n",
    "                        # Concatenate root_path with spur_path[1:]\n",
    "                        combined_path_list = root_path_list + spur_path_segment_list[1:]\n",
    "                        total_new_cost = root_cost + spur_cost_delta\n",
    "\n",
    "                        # Add the potential new path to the candidate heap B\n",
    "                        heapq.heappush(B, (total_new_cost, next(tie_breaker), combined_path_list))\n",
    "\n",
    "\n",
    "                # Select the best path from B that isn't already in A\n",
    "                found_next_path = False\n",
    "                while B:\n",
    "                    potential_cost, _, potential_path_list = heapq.heappop(B)\n",
    "\n",
    "                    # Check if this path (by node sequence) is already in A\n",
    "                    is_in_A = False\n",
    "                    potential_nodes = tuple(item['node'] for item in potential_path_list)\n",
    "                    for cost_a, path_a in A:\n",
    "                         if tuple(item['node'] for item in path_a) == potential_nodes:\n",
    "                            is_in_A = True\n",
    "                            break\n",
    "\n",
    "                    if not is_in_A:\n",
    "                         # Found the k-th shortest path\n",
    "                         A.append((potential_cost, potential_path_list))\n",
    "                         found_next_path = True\n",
    "                         break # Move to find the (k+1)th path\n",
    "\n",
    "                # If B is exhausted or no new paths found, stop for this demand\n",
    "                if not found_next_path:\n",
    "                    break\n",
    "\n",
    "            # Format the results for this ODT\n",
    "            formatted_paths = []\n",
    "            A.sort(key=lambda x: x[0]) # Ensure final paths are sorted by cost\n",
    "            for cost, path_list in A:\n",
    "                 formatted = self._format_path_output(path_list, cost)\n",
    "                 if formatted:\n",
    "                     formatted_paths.append(formatted)\n",
    "\n",
    "            all_paths_results[odt_id] = formatted_paths\n",
    "\n",
    "        end_run_time = timer.time()\n",
    "        print(f\"\\nFinished finding K shortest paths in {end_run_time - start_run_time:.2f} seconds.\")\n",
    "        return all_paths_results\n",
    "\n",
    "# --- Script Execution ---\n",
    "\n",
    "# 1. Read Data\n",
    "print(\"Reading data...\")\n",
    "schedule_df = read_capacity(CAPACITY_FILE, airport_substitutions=airport_substitutions)\n",
    "demand_df = read_market(MARKET_FILE, airport_substitutions=airport_substitutions)\n",
    "print(demand_df.head()) # Display sample demand data\n",
    "\n",
    "# 2. Initialize Network and Build Graph\n",
    "# Check if dataframes are valid before proceeding\n",
    "if not schedule_df.empty and not demand_df.empty:\n",
    "    try:\n",
    "        flight_network = FlightNetwork(schedule_df, demand_df, K_PATHS, MIN_CONNECT_MINS)\n",
    "\n",
    "        # 3. Find K Shortest Paths\n",
    "        k_shortest_paths_results = flight_network.find_k_shortest_paths()\n",
    "\n",
    "        # 4. Output Results (Example for first few demands)\n",
    "        print(\"\\n--- K Shortest Paths Results (Sample) ---\")\n",
    "        output_count = 0\n",
    "        for odt, paths in k_shortest_paths_results.items():\n",
    "            if output_count < 10: # Print details only for the first 10 demands\n",
    "                demand_info = flight_network.demand_dict.get(odt, {})\n",
    "                print(f\"ODT: {odt} (Demand: {demand_info.get('ori','?')}-{demand_info.get('des','?')} @ {demand_info.get('time','?')})\")\n",
    "                if paths:\n",
    "                    for i, path in enumerate(paths):\n",
    "                        print(f\"  Path {i+1}:\")\n",
    "                        print(f\"    Total Time (mins): {path['total_time']:.2f}\")\n",
    "                        # Optional: Print flight details\n",
    "                        flight_details_str = []\n",
    "                        for fid in path['flight_ids']:\n",
    "                             f_info = flight_network.flight_data.get(fid) # fid is int\n",
    "                             if f_info:\n",
    "                                 flight_details_str.append(f\"{fid}({f_info['ori']}-{f_info['des']}@{f_info['dep_time']})\")\n",
    "                             else:\n",
    "                                 flight_details_str.append(f\"{fid}(?)\")\n",
    "                        print(f\"    Flights: {' -> '.join(flight_details_str)}\")\n",
    "                        print(f\"    Min Capacity (kg): {path['min_capacity']:.2f}\") # Format capacity\n",
    "                else:\n",
    "                    print(\"  No paths found.\")\n",
    "                print(\"-\" * 20)\n",
    "            elif output_count == 10:\n",
    "                 print(\"\\n... (output truncated for brevity) ...\")\n",
    "                 break # Stop printing samples after 10\n",
    "            output_count += 1\n",
    "\n",
    "        print(f\"\\nFound path results for {len(k_shortest_paths_results)} ODTs.\")\n",
    "        # The 'k_shortest_paths_results' dictionary contains all the results.\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during FlightNetwork initialization: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during processing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print detailed traceback for debugging\n",
    "else:\n",
    "    print(\"\\nError: Failed to read valid schedule or demand data. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
