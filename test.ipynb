{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import heapq\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_airports = {\n",
    "    'DOH': \"BAH\",\n",
    "    'SZX': \"HKG\",\n",
    "    'CAN': \"HKG\",\n",
    "    'STN': 'LHR',\n",
    "    'LTN': 'LHR'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RE-DO Preporcessing solve the Remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Data Reading Functions\n",
    "# =============================================\n",
    "def read_capacity(CAPACITY_FILE, airport_substitutions=None):\n",
    "    capacity = pd.read_csv(CAPACITY_FILE, sep=',')\n",
    "\n",
    "    capacity['deptime'] = pd.to_datetime(capacity['deptime'])\n",
    "    capacity['arrtime'] = pd.to_datetime(capacity['arrtime'])\n",
    "\n",
    "    # Map Weekday_Z to day number (0=Mon, 6=Sun)\n",
    "    day_map = {'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6}\n",
    "    capacity['day'] = capacity['Weekday_Z'].map(day_map)\n",
    "\n",
    "    # Calculate total minutes from start of week (Monday 00:00)\n",
    "    # Dep Time = Day * 1440 + Hour * 60 + Minute\n",
    "    capacity['dep_time'] = capacity['day'] * 1440 + capacity['deptime'].dt.hour * 60 + capacity['deptime'].dt.minute\n",
    "    capacity['DD_Z'] = capacity['DD_Z'].fillna(0)\n",
    "    capacity['arr_time'] = capacity['day'] * 1440 + capacity['arrtime'].dt.hour * 60 + capacity['arrtime'].dt.minute + capacity['DD_Z']*1440\n",
    "\n",
    "    # Check for negative durations which indicate data errors\n",
    "    if (capacity['arr_time'] < capacity['dep_time']).any():\n",
    "        print(\"Warning: Some flights have arrival time earlier than departure time after processing. Check data.\")\n",
    "        # Consider dropping or fixing these rows\n",
    "\n",
    "    # --- Column Renaming and Selection ---\n",
    "    rename_columns = {\n",
    "        'Net Payload': 'cap_kg',\n",
    "        'Net Volume': 'cap_m3',\n",
    "        'Orig': 'ori',\n",
    "        'Dest': 'des',\n",
    "        'Flight Number': 'flight_number',\n",
    "        'A/C': 'aircraft_type'\n",
    "    }\n",
    "    capacity = capacity.rename(columns=rename_columns)\n",
    "\n",
    "    # Define desired columns\n",
    "    columns = ['flight_number', 'ori', 'des', 'aircraft_type', 'dep_time', 'arr_time', 'day', 'cap_kg', 'cap_m3']\n",
    "    capacity = capacity[[col for col in columns if col in capacity.columns]]\n",
    "\n",
    "    # CONVERT SAME AIRPORTS FROM DICTIONARY - same_airports - CONVERT EVERY KEY TO ITS VALUE\n",
    "    for key, value in airport_substitutions.items():\n",
    "        capacity.loc[capacity['ori'] == key, 'ori'] = value\n",
    "        capacity.loc[capacity['des'] == key, 'des'] = value\n",
    "    capacity['key'] = capacity['ori'] + '/'+ capacity['des'] +'/'+ capacity['dep_time'].astype(str)\n",
    "\n",
    "    capacity['dep_time'] = capacity['dep_time'].astype(int)\n",
    "    capacity['arr_time'] = capacity['arr_time'].astype(int)\n",
    "    capacity['day'] = capacity['day'].astype(int)\n",
    "    print(f\"Capacity data read: {len(capacity)} rows.\")\n",
    "    return capacity\n",
    "\n",
    "\n",
    "def read_market(MARKET_FILE, airport_substitutions=None):\n",
    "    market = pd.read_csv(MARKET_FILE, sep=';')\n",
    "\n",
    "    market = market.rename(columns={'origin': 'ori', 'destination': 'des', 'Market CHW': 'demand', 'Day': 'day'})\n",
    "    if 'product' in market.columns: market.drop(columns=['product'], inplace=True)\n",
    "    if 'Market Allin Yield' in market.columns: market.drop(columns=['Market Allin Yield'], inplace=True)\n",
    "\n",
    "    day_map = {'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6}\n",
    "    market['day'] = market['day'].map(day_map)\n",
    "\n",
    "    # convert HH:MM to minutes\n",
    "    time_minutes = market['time'].str.split(':', expand=True).astype(int).apply(lambda x: x[0] * 60 + x[1], axis=1)\n",
    "    market['time'] = market['day'] * 1440 + time_minutes\n",
    "\n",
    "    # SUBSITUTE AIRPORTS FROM same_airports DICTIONERY - CONVERT EVERY KEY TO ITS VALUE\n",
    "    for key, value in airport_substitutions.items():\n",
    "        market.loc[market['ori'] == key, 'ori'] = value\n",
    "        market.loc[market['des'] == key, 'des'] = value\n",
    "\n",
    "    # Add original key\n",
    "    market['key'] = market['ori'] + '/' + market['des'] + '/' + market['time'].astype(str)\n",
    "\n",
    "    # WE CREATED DUPLICATES KEY AS A RESULT OF CONVERTING SAME AIRPORTS\n",
    "    # MERGE THE DEMAND VALUES FOR THE SAME KEY\n",
    "    market = market.groupby(['key', 'ori', 'des', 'day', 'time']).agg({'demand': 'sum'}).reset_index()\n",
    "    # Select relevant columns\n",
    "    market = market[['ori', 'des', 'demand', 'day', 'time', 'key']].copy()\n",
    "\n",
    "    # Convert types\n",
    "    market['time'] = market['time'].astype(int)\n",
    "    market['day'] = market['day'].astype(int)\n",
    "    market['demand'] = pd.to_numeric(market['demand'], errors='coerce').fillna(0)\n",
    "    print(f\"Market data read: {len(market)} rows.\")\n",
    "    return market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting K-Shortest Path Calculation (Sequential)...\n",
      "------------------------------\n",
      "Capacity data read: 2057 rows.\n",
      "Market data read: 3185 rows.\n",
      "------------------------------\n",
      "Initializing Flight Network...\n",
      "Processing flight schedule...\n",
      "Schedule processed (0.04s)\n",
      "Processing demand data...\n",
      "Demand processed (0.04s)\n",
      "Data loaded. Network: 2057 flights (int IDs), 109 airports, 3185 demands.\n",
      "Building connectivity graph (using integer IDs)...\n",
      "Connectivity graph built (0.05s)\n",
      "  80665 flight-to-flight connections\n",
      "  189207 source-to-flight connections\n",
      "  All demands have at least one potential initial flight connection.\n",
      "------------------------------\n",
      "\n",
      "Finding up to 3 shortest paths for 3185 demands (sequentially)...\n",
      "  Processed 159/3185 demands... (0.31s)\n",
      "  Processed 318/3185 demands... (0.99s)\n",
      "  Processed 477/3185 demands... (1.75s)\n",
      "  Processed 636/3185 demands... (2.20s)\n",
      "  Processed 795/3185 demands... (2.92s)\n",
      "  Processed 954/3185 demands... (3.51s)\n",
      "  Processed 1113/3185 demands... (4.07s)\n",
      "  Processed 1272/3185 demands... (4.75s)\n",
      "  Processed 1431/3185 demands... (5.21s)\n",
      "  Processed 1590/3185 demands... (6.00s)\n",
      "  Processed 1749/3185 demands... (6.49s)\n",
      "  Processed 1908/3185 demands... (7.07s)\n",
      "  Processed 2067/3185 demands... (7.63s)\n",
      "  Processed 2226/3185 demands... (8.28s)\n",
      "  Processed 2385/3185 demands... (8.95s)\n",
      "  Processed 2544/3185 demands... (9.31s)\n",
      "  Processed 2703/3185 demands... (9.92s)\n",
      "  Processed 2862/3185 demands... (10.45s)\n",
      "  Processed 3021/3185 demands... (10.70s)\n",
      "  Processed 3180/3185 demands... (11.44s)\n",
      "  Processed 3185/3185 demands... (11.46s)\n",
      "\n",
      "Sequential path finding finished in 11.46s\n",
      "\n",
      "Connectivity Summary:\n",
      "  Total demands processed: 3185\n",
      "  All demands had at least one potential initial flight connection.\n",
      "  Demands for which at least 1 path was found: 3058 (96.0%)\n",
      "  Demands for which NO path was found (up to K): 127 (4.0%)\n",
      "  Total individual paths generated (up to K per demand): 8616\n",
      "  Average paths per connected demand: 2.82\n",
      "------------------------------\n",
      "\n",
      "Converting paths dictionary (int IDs) to DataFrame...\n",
      "DataFrame created with 8616 paths in 0.05s\n",
      "\n",
      "DataFrame Head (First 5 paths):\n",
      "      demand_id  path_rank  path_cost_minutes  path_duration_minutes  \\\n",
      "0  AMS/LAX/1080          1              18748                   9618   \n",
      "1  AMS/LAX/1080          2              18753                   9618   \n",
      "2  AMS/LAX/1080          3              18753                   9618   \n",
      "3  AMS/LAX/2520          1              17308                   8178   \n",
      "4  AMS/LAX/2520          2              17515                   8390   \n",
      "\n",
      "   num_flights   flight_int_ids  \n",
      "0            3  [37, 1476, 508]  \n",
      "1            3  [37, 1312, 508]  \n",
      "2            3  [37, 1356, 508]  \n",
      "3            3  [37, 1476, 508]  \n",
      "4            3  [37, 1476, 524]  \n",
      "\n",
      "Total execution time: 11.67 seconds\n",
      "Final Network Stats:\n",
      "  total_flights: 2057\n",
      "  total_demands: 3185\n",
      "  flight_connections: 80665\n",
      "  source_connections: 189207\n",
      "  disconnected_sources: 0\n",
      "  total_paths_found: 8616\n",
      "  demands_with_paths: 3058\n",
      "  time_data_loading: 0.08s\n",
      "  time_graph_building: 0.05s\n",
      "  time_path_finding: 11.46s\n",
      "------------------------------\n",
      "\n",
      "Script finished.\n",
      "Total paths generated in DataFrame: 8616\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "import sys\n",
    "import itertools # Still needed for ID generation if we keep _get_or_create_flight_int_id, but not essential if just iterating\n",
    "import os\n",
    "\n",
    "same_airports = {\n",
    "    'DOH': \"BAH\",\n",
    "    'SZX': \"HKG\",\n",
    "    'CAN': \"HKG\",\n",
    "    'STN': 'LHR',\n",
    "    'LTN': 'LHR'\n",
    "}\n",
    "\n",
    "# --- FlightNetwork Class (Sequential Implementation) ---\n",
    "\n",
    "class FlightNetwork:\n",
    "    \"\"\"\n",
    "    Represents the flight network and finds K-shortest paths sequentially.\n",
    "    Uses integer IDs for flights and minute-based times.\n",
    "    Costs represent wait/layover time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_connection_minutes=60, max_connection_minutes=7*24*60):\n",
    "        if not (0 <= min_connection_minutes <= max_connection_minutes):\n",
    "             raise ValueError(\"Invalid connection time parameters.\")\n",
    "        self.min_connection_minutes = min_connection_minutes\n",
    "        self.max_connection_minutes = max_connection_minutes\n",
    "        self.week_minutes = 7 * 24 * 60\n",
    "        self.flight_int_to_data = {}\n",
    "        self.flight_str_to_int = {}\n",
    "        self._next_flight_int_id = 0\n",
    "        self.airports = set()\n",
    "        self.demands = {}\n",
    "        self.flights_by_origin = defaultdict(list)\n",
    "        self.flights_by_destination = defaultdict(list)\n",
    "        self.outgoing_edges = defaultdict(list) # int_flight_id -> [(neighbor_int_flight_id, layover_cost)]\n",
    "        self.source_connections = defaultdict(list) # demand_id_str -> [(first_int_flight_id, wait_cost)]\n",
    "        self.demand_destinations = {}\n",
    "        self.stats = {\n",
    "            \"total_flights\": 0, \"total_demands\": 0, \"flight_connections\": 0,\n",
    "            \"source_connections\": 0, \"disconnected_sources\": 0,\n",
    "            \"total_paths_found\": 0, \"demands_with_paths\": 0,\n",
    "            \"time_data_loading\": 0.0, \"time_graph_building\": 0.0,\n",
    "            \"time_path_finding\": 0.0, # Will now be sequential time\n",
    "        }\n",
    "\n",
    "    def _get_or_create_flight_int_id(self, flight_str_id):\n",
    "        \"\"\"Assigns a unique integer ID to a flight string ID.\"\"\"\n",
    "        if flight_str_id not in self.flight_str_to_int:\n",
    "            int_id = self._next_flight_int_id\n",
    "            self.flight_str_to_int[flight_str_id] = int_id\n",
    "            self.flight_int_to_data[int_id] = {'original_str_id': flight_str_id}\n",
    "            self._next_flight_int_id += 1\n",
    "            return int_id\n",
    "        return self.flight_str_to_int[flight_str_id]\n",
    "\n",
    "    def load_and_process_data(self, schedule_df, demand_df):\n",
    "        \"\"\"Load and process data using integer IDs (Sequential).\"\"\"\n",
    "        # (Identical to the previous version's load_and_process_data)\n",
    "        print(\"Processing flight schedule...\")\n",
    "        start_time = time.time(); required_schedule_cols = ['ori', 'des', 'day', 'dep_time', 'arr_time', 'cap_kg', 'cap_m3', 'flight_number']\n",
    "        if not all(col in schedule_df.columns for col in required_schedule_cols): raise ValueError(f\"Schedule DataFrame missing required columns: {[c for c in required_schedule_cols if c not in schedule_df.columns]}\")\n",
    "        schedule_df['flight_str_id'] = schedule_df.apply(lambda r: f\"{r['flight_number']}_{r['day']}_{r['ori']}_{int(r['dep_time'])}\", axis=1)\n",
    "        if schedule_df['flight_str_id'].duplicated().any(): print(\"Warning: Duplicate flight string IDs generated. Keeping first.\"); schedule_df = schedule_df.drop_duplicates(subset=['flight_str_id'], keep='first')\n",
    "        for _, r in schedule_df.iterrows():\n",
    "            int_id = self._get_or_create_flight_int_id(r['flight_str_id'])\n",
    "            data = {'original_str_id': r['flight_str_id'], 'flight_number': r['flight_number'],'origin': r['ori'], 'destination': r['des'], 'day': int(r['day']),'dep_minutes': int(r['dep_time']), 'arr_minutes': int(r['arr_time']),'capacity_kg': r['cap_kg'], 'capacity_m3': r['cap_m3']}\n",
    "            self.flight_int_to_data[int_id].update(data)\n",
    "            self.flights_by_origin[r['ori']].append(int_id); self.flights_by_destination[r['des']].append(int_id)\n",
    "            self.airports.add(r['ori']); self.airports.add(r['des'])\n",
    "        self.stats[\"total_flights\"] = len(self.flight_int_to_data); load_time_schedule = time.time() - start_time; print(f\"Schedule processed ({load_time_schedule:.2f}s)\")\n",
    "        print(\"Processing demand data...\")\n",
    "        start_time_demand = time.time(); required_demand_cols = ['ori', 'des', 'day', 'time', 'demand', 'key']\n",
    "        if not all(col in demand_df.columns for col in required_demand_cols): raise ValueError(f\"Demand DataFrame missing required columns: {[c for c in required_demand_cols if c not in demand_df.columns]}\")\n",
    "        demand_df['demand_id'] = demand_df['key']\n",
    "        if demand_df['demand_id'].duplicated().any(): print(\"Warning: Duplicate demand_ids detected. Keeping first.\"); demand_df = demand_df.drop_duplicates(subset=['demand_id'], keep='first')\n",
    "        for _, r in demand_df.iterrows():\n",
    "            demand_id = r['demand_id']; data = {'id': demand_id, 'origin': r['ori'], 'destination': r['des'],'day': int(r['day']), 'minutes': int(r['time']),'demand': r['demand'], 'key': r['key']}\n",
    "            self.demands[demand_id] = data; self.demand_destinations[demand_id] = r['des']\n",
    "        self.stats[\"total_demands\"] = len(self.demands); load_time_demand = time.time() - start_time_demand; print(f\"Demand processed ({load_time_demand:.2f}s)\")\n",
    "        self.stats[\"time_data_loading\"] = load_time_schedule + load_time_demand; print(f\"Data loaded. Network: {self.stats['total_flights']} flights (int IDs), {len(self.airports)} airports, {self.stats['total_demands']} demands.\")\n",
    "        self._build_connectivity_graph() # Call graph build\n",
    "\n",
    "\n",
    "    def _calculate_time_diff_with_rollover(self, later_time, earlier_time):\n",
    "        \"\"\"Calculates time difference handling weekly rollover.\"\"\"\n",
    "        time_diff = later_time - earlier_time\n",
    "        if time_diff < 0:\n",
    "            time_diff += self.week_minutes * ((-time_diff + self.week_minutes - 1) // self.week_minutes)\n",
    "        return time_diff\n",
    "\n",
    "    def _build_connectivity_graph(self):\n",
    "        \"\"\"Build connectivity using integer flight IDs and optimize connections.\"\"\"\n",
    "        # (Identical to the previous version's _build_connectivity_graph)\n",
    "        print(\"Building connectivity graph (using integer IDs)...\"); start_time = time.time(); flight_connections_count = 0\n",
    "        for airport in self.airports:\n",
    "            arriving_ids = self.flights_by_destination.get(airport, []); departing_ids = self.flights_by_origin.get(airport, [])\n",
    "            if not arriving_ids or not departing_ids: continue\n",
    "            departing_sorted = sorted(departing_ids, key=lambda i: self.flight_int_to_data[i]['dep_minutes'])\n",
    "            for arr_id in arriving_ids:\n",
    "                arr_mins = self.flight_int_to_data[arr_id]['arr_minutes']\n",
    "                for dep_id in departing_sorted:\n",
    "                    dep_mins = self.flight_int_to_data[dep_id]['dep_minutes']\n",
    "                    layover = self._calculate_time_diff_with_rollover(dep_mins, arr_mins)\n",
    "                    if self.min_connection_minutes <= layover <= self.max_connection_minutes:\n",
    "                        self.outgoing_edges[arr_id].append((dep_id, layover)); flight_connections_count += 1\n",
    "                    elif layover > self.max_connection_minutes: break # Optimization\n",
    "        self.stats[\"flight_connections\"] = flight_connections_count\n",
    "        source_connections_count = 0; disconnected_sources_count = 0\n",
    "        for d_id, d in self.demands.items():\n",
    "            origin = d['origin']; d_mins = d['minutes']; has_conn = False\n",
    "            departing_ids = self.flights_by_origin.get(origin, [])\n",
    "            for f_id in departing_ids:\n",
    "                f_mins = self.flight_int_to_data[f_id]['dep_minutes']\n",
    "                wait = self._calculate_time_diff_with_rollover(f_mins, d_mins)\n",
    "                if 0 <= wait <= self.max_connection_minutes:\n",
    "                    self.source_connections[d_id].append((f_id, wait)); source_connections_count += 1; has_conn = True\n",
    "            if not has_conn: disconnected_sources_count += 1\n",
    "        self.stats[\"source_connections\"] = source_connections_count; self.stats[\"disconnected_sources\"] = disconnected_sources_count\n",
    "        self.stats[\"time_graph_building\"] = time.time() - start_time; print(f\"Connectivity graph built ({self.stats['time_graph_building']:.2f}s)\")\n",
    "        print(f\"  {self.stats['flight_connections']} flight-to-flight connections\"); print(f\"  {self.stats['source_connections']} source-to-flight connections\")\n",
    "        if self.stats['disconnected_sources'] > 0: print(f\"  WARNING: {self.stats['disconnected_sources']} demands ({ (self.stats['disconnected_sources']/self.stats['total_demands'])*100 if self.stats['total_demands'] > 0 else 0 :.1f}%) have NO initial flight connection.\")\n",
    "        else: print(\"  All demands have at least one potential initial flight connection.\")\n",
    "\n",
    "\n",
    "    # --- Internal Pathfinding Methods (Sequential) ---\n",
    "\n",
    "    def _dijkstra(self, start_node_id, target_airport, excluded_nodes=None, excluded_edges=None):\n",
    "        \"\"\"\n",
    "        Internal Dijkstra implementation for the class.\n",
    "        Uses integer IDs for flights. start_node_id can be demand_id (str) or int_flight_id.\n",
    "        \"\"\"\n",
    "        excluded_nodes = excluded_nodes or set() # Should contain int_flight_ids\n",
    "        excluded_edges = excluded_edges or set() # Should contain tuples (int_id, int_id) or (str_id, int_id)\n",
    "\n",
    "        pq = [(0, start_node_id)] # (cost, current_node_id (str or int))\n",
    "        distances = defaultdict(lambda: float('inf'))\n",
    "        distances[start_node_id] = 0\n",
    "        previous_nodes = {} # node_id -> predecessor_node_id\n",
    "\n",
    "        min_target_cost = float('inf')\n",
    "        final_target_int_flight_id = None # The int_flight_id of the best target found\n",
    "\n",
    "        while pq:\n",
    "            current_cost, current_id = heapq.heappop(pq)\n",
    "\n",
    "            if current_cost > distances[current_id] or current_cost >= min_target_cost:\n",
    "                 continue\n",
    "\n",
    "            is_flight = isinstance(current_id, int)\n",
    "            if is_flight:\n",
    "                if current_id in excluded_nodes:\n",
    "                     continue\n",
    "                flight_data = self.flight_int_to_data.get(current_id)\n",
    "                if flight_data and flight_data.get('destination') == target_airport:\n",
    "                    if current_cost < min_target_cost:\n",
    "                        min_target_cost = current_cost\n",
    "                        final_target_int_flight_id = current_id\n",
    "\n",
    "            # Determine outgoing edges based on node type\n",
    "            if isinstance(current_id, str): # Must be the starting demand_id\n",
    "                 edges = self.source_connections.get(current_id, []) # Edges are (int_flight_id, cost)\n",
    "            elif is_flight:\n",
    "                 edges = self.outgoing_edges.get(current_id, []) # Edges are (int_flight_id, cost)\n",
    "            else:\n",
    "                 edges = []\n",
    "\n",
    "            for neighbor_int_id, weight in edges:\n",
    "                edge = (current_id, neighbor_int_id) # Edge represented by (int_id, int_id) or (str_id, int_id)\n",
    "                if neighbor_int_id in excluded_nodes: continue\n",
    "                if is_flight and edge in excluded_edges: continue # Check edge exclusion only for flight->flight\n",
    "\n",
    "                new_cost = current_cost + weight\n",
    "                if new_cost < distances[neighbor_int_id]:\n",
    "                    distances[neighbor_int_id] = new_cost\n",
    "                    previous_nodes[neighbor_int_id] = current_id # Predecessor can be str or int\n",
    "                    heapq.heappush(pq, (new_cost, neighbor_int_id))\n",
    "\n",
    "        # Reconstruct path (will contain int_flight_ids)\n",
    "        if final_target_int_flight_id is not None:\n",
    "            path = deque()\n",
    "            curr = final_target_int_flight_id\n",
    "            while curr != start_node_id:\n",
    "                 path.appendleft(curr)\n",
    "                 if curr not in previous_nodes:\n",
    "                     print(f\"Error (Dijkstra): Path reconstruction failed. Predecessor missing for {curr}.\")\n",
    "                     return float('inf'), []\n",
    "                 curr = previous_nodes[curr]\n",
    "            return min_target_cost, list(path)\n",
    "        else:\n",
    "            return float('inf'), []\n",
    "\n",
    "    def _calculate_path_cost(self, demand_id_str, path_int_flight_ids):\n",
    "        \"\"\"Internal method to calculate cost for a path of integer flight IDs.\"\"\"\n",
    "        if demand_id_str not in self.demands: return float('inf')\n",
    "        if not path_int_flight_ids: return 0\n",
    "        total_cost = 0.0; current_node_id = demand_id_str\n",
    "        for i, int_flight_id in enumerate(path_int_flight_ids):\n",
    "            edge_found = False\n",
    "            if i == 0: edges_to_search = self.source_connections.get(current_node_id, [])\n",
    "            else:\n",
    "                if not isinstance(current_node_id, int): return float('inf') # Should be flight ID now\n",
    "                edges_to_search = self.outgoing_edges.get(current_node_id, [])\n",
    "            for neighbor_int_id, weight in edges_to_search:\n",
    "                if neighbor_int_id == int_flight_id:\n",
    "                    total_cost += weight; current_node_id = int_flight_id; edge_found = True; break\n",
    "            if not edge_found:\n",
    "                print(f\"Error (Cost Calc): Connection not found for leg {i+1} of demand {demand_id_str}\")\n",
    "                return float('inf')\n",
    "        return total_cost\n",
    "\n",
    "    def find_k_shortest_paths(self, demand_id_str, k):\n",
    "        \"\"\"\n",
    "        Internal method using Yen's algorithm (sequential).\n",
    "        Calls internal _dijkstra and _calculate_path_cost.\n",
    "        \"\"\"\n",
    "        if demand_id_str not in self.demands: return []\n",
    "        if k <= 0: return []\n",
    "\n",
    "        target_airport = self.demand_destinations.get(demand_id_str)\n",
    "        if not target_airport: return [] # Should not happen\n",
    "\n",
    "        A = []; B_heap = []; B_paths_set = set() # Use set for faster duplicate check in heap\n",
    "\n",
    "        cost1, path1_ints = self._dijkstra(demand_id_str, target_airport)\n",
    "        if cost1 == float('inf'): return [] # No path exists\n",
    "        A.append((cost1, path1_ints))\n",
    "\n",
    "        for i in range(1, k): # Yen's loop\n",
    "            if i - 1 >= len(A): break # Found fewer than k paths so far\n",
    "            prev_cost, prev_path_ints = A[i-1]\n",
    "            for spur_node_idx in range(len(prev_path_ints)):\n",
    "                spur_node_int_id = prev_path_ints[spur_node_idx]\n",
    "                root_path_ints = prev_path_ints[:spur_node_idx]\n",
    "                root_cost = self._calculate_path_cost(demand_id_str, root_path_ints)\n",
    "                if root_cost == float('inf'): continue\n",
    "\n",
    "                excluded_nodes = set(root_path_ints)\n",
    "                excluded_edges = set()\n",
    "                for _, path_a_ints in A:\n",
    "                    if len(path_a_ints) > spur_node_idx and path_a_ints[:spur_node_idx] == root_path_ints:\n",
    "                        if path_a_ints[spur_node_idx] == spur_node_int_id:\n",
    "                            if spur_node_idx + 1 < len(path_a_ints):\n",
    "                                excluded_edges.add((spur_node_int_id, path_a_ints[spur_node_idx + 1]))\n",
    "\n",
    "                # Call internal Dijkstra for spur path\n",
    "                spur_cost, spur_path_segment_ints = self._dijkstra(\n",
    "                    spur_node_int_id, target_airport, excluded_nodes, excluded_edges\n",
    "                )\n",
    "\n",
    "                if spur_cost != float('inf'):\n",
    "                    full_path_ints = root_path_ints + [spur_node_int_id] + spur_path_segment_ints\n",
    "                    total_cost = root_cost + spur_cost\n",
    "                    full_path_tuple = tuple(full_path_ints)\n",
    "                    if full_path_tuple not in B_paths_set:\n",
    "                        heapq.heappush(B_heap, (total_cost, full_path_ints))\n",
    "                        B_paths_set.add(full_path_tuple)\n",
    "\n",
    "            found_next = False\n",
    "            while B_heap:\n",
    "                best_cost, best_path_ints = heapq.heappop(B_heap)\n",
    "                B_paths_set.discard(tuple(best_path_ints)) # Use discard\n",
    "                is_in_A = any(p == best_path_ints for c, p in A)\n",
    "                if not is_in_A:\n",
    "                    A.append((best_cost, best_path_ints)); found_next = True; break\n",
    "            if not found_next: break # No more distinct paths found in heap\n",
    "\n",
    "        # Return list of (cost, path_list_of_int_ids)\n",
    "        return A\n",
    "\n",
    "    # --- Main Sequential Path Finding Method ---\n",
    "\n",
    "    def find_all_k_shortest_paths_sequential(self, k=3):\n",
    "        \"\"\"\n",
    "        Finds up to K shortest paths for all demands sequentially.\n",
    "        \"\"\"\n",
    "        overall_start_time = time.time()\n",
    "        all_paths_results = {} # demand_id_str -> list[list[int_flight_id]]\n",
    "        num_demands = len(self.demands)\n",
    "        if num_demands == 0: return {}\n",
    "\n",
    "        print(f\"\\nFinding up to {k} shortest paths for {num_demands} demands (sequentially)...\")\n",
    "\n",
    "        processed_count = 0\n",
    "        demands_with_paths_count = 0\n",
    "        total_paths_found_count = 0\n",
    "        report_interval = max(1, num_demands // 20) # Progress reporting\n",
    "\n",
    "        for demand_id in self.demands.keys():\n",
    "            # Call the internal find_k_shortest_paths method\n",
    "            paths_with_costs = self.find_k_shortest_paths(demand_id, k) # Gets list of (cost, path)\n",
    "\n",
    "            if paths_with_costs:\n",
    "                # Store only the paths (list of lists of int IDs)\n",
    "                paths_list_ints = [path for cost, path in paths_with_costs]\n",
    "                all_paths_results[demand_id] = paths_list_ints\n",
    "                demands_with_paths_count += 1\n",
    "                total_paths_found_count += len(paths_list_ints)\n",
    "\n",
    "            processed_count += 1\n",
    "            if processed_count % report_interval == 0 or processed_count == num_demands:\n",
    "                elapsed = time.time() - overall_start_time\n",
    "                print(f\"  Processed {processed_count}/{num_demands} demands... ({elapsed:.2f}s)\")\n",
    "\n",
    "        # Stats updates and Reporting\n",
    "        total_time = time.time() - overall_start_time\n",
    "        self.stats[\"total_paths_found\"] = total_paths_found_count\n",
    "        self.stats[\"demands_with_paths\"] = demands_with_paths_count\n",
    "        self.stats[\"time_path_finding\"] = total_time\n",
    "        print(f\"\\nSequential path finding finished in {total_time:.2f}s\")\n",
    "        # --- Connectivity Reporting ---\n",
    "        print(\"\\nConnectivity Summary:\")\n",
    "        print(f\"  Total demands processed: {num_demands}\")\n",
    "        disconnected_start = self.stats['disconnected_sources']\n",
    "        if disconnected_start > 0: pct_disconnected_start = (disconnected_start / num_demands) * 100 if num_demands > 0 else 0; print(f\"  Demands with NO initial flight connection: {disconnected_start} ({pct_disconnected_start:.1f}%)\")\n",
    "        else: print(\"  All demands had at least one potential initial flight connection.\")\n",
    "        demands_without_paths = num_demands - demands_with_paths_count\n",
    "        pct_with_paths = (demands_with_paths_count / num_demands) * 100 if num_demands > 0 else 0\n",
    "        pct_without_paths = 100.0 - pct_with_paths\n",
    "        print(f\"  Demands for which at least 1 path was found: {demands_with_paths_count} ({pct_with_paths:.1f}%)\")\n",
    "        print(f\"  Demands for which NO path was found (up to K): {demands_without_paths} ({pct_without_paths:.1f}%)\")\n",
    "        print(f\"  Total individual paths generated (up to K per demand): {total_paths_found_count}\")\n",
    "        if demands_with_paths_count > 0: avg_paths = total_paths_found_count / demands_with_paths_count; print(f\"  Average paths per connected demand: {avg_paths:.2f}\")\n",
    "\n",
    "        return all_paths_results\n",
    "\n",
    "\n",
    "    def get_paths_as_dataframe(self, paths_dict_ints):\n",
    "        \"\"\"Converts dict of paths (int IDs) to DataFrame (Sequential).\"\"\"\n",
    "        # (Identical to the previous version's get_paths_as_dataframe)\n",
    "        print(\"\\nConverting paths dictionary (int IDs) to DataFrame...\")\n",
    "        start_convert_time = time.time(); data = []\n",
    "        if not paths_dict_ints: return pd.DataFrame()\n",
    "        for demand_id, path_list_ints in paths_dict_ints.items():\n",
    "            if not path_list_ints or demand_id not in self.demands: continue\n",
    "            demand = self.demands[demand_id]\n",
    "            for i, path_ints in enumerate(path_list_ints):\n",
    "                if not path_ints: continue\n",
    "                # Use internal cost calculation\n",
    "                path_cost = self._calculate_path_cost(demand_id, path_ints)\n",
    "                if path_cost == float('inf'): continue\n",
    "                try:\n",
    "                    last_id = path_ints[-1]; final_arrival = self.flight_int_to_data[last_id]['arr_minutes']\n",
    "                    duration = self._calculate_time_diff_with_rollover(final_arrival, demand['minutes'])\n",
    "                except (KeyError, IndexError): final_arrival = np.nan; duration = np.nan\n",
    "                row = {\"demand_id\": demand_id, \"demand_key\": demand.get(\"key\", demand_id),\"path_rank\": i + 1, \"path_id\": f\"{demand_id}_p{i+1}\",\"origin\": demand[\"origin\"], \"destination\": demand[\"destination\"],\"demand_kg\": demand.get(\"demand\", np.nan),\"path_cost_minutes\": int(path_cost) if not np.isnan(path_cost) else np.nan,\"path_duration_minutes\": int(duration) if not np.isnan(duration) else np.nan,\"num_flights\": len(path_ints),\"final_arrival_minutes\": int(final_arrival) if not np.isnan(final_arrival) else np.nan,\"flight_int_ids\": path_ints}\n",
    "                data.append(row)\n",
    "        if not data: print(\"No valid paths found to convert to DataFrame.\"); return pd.DataFrame()\n",
    "        df = pd.DataFrame(data); cols_order = [\"demand_id\", \"demand_key\", \"path_rank\", \"path_id\", \"origin\", \"destination\",\"demand_kg\", \"path_cost_minutes\", \"path_duration_minutes\", \"num_flights\",\"final_arrival_minutes\", \"flight_int_ids\"]\n",
    "        df = df[[col for col in cols_order if col in df.columns]]; print(f\"DataFrame created with {len(df)} paths in {time.time() - start_convert_time:.2f}s\"); return df\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# Main Execution Block\n",
    "# =============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function using sequential pathfinding.\"\"\"\n",
    "    overall_start_time = time.time()\n",
    "    K_PATHS = 3; MIN_CONNECT_MINS = 60; MAX_CONNECT_MINS = 6 * 24 * 60\n",
    "    CAPACITY_FILE = 'files/capacity.csv'; MARKET_FILE = 'files/market.csv'\n",
    "    # MAX_WORKERS = None # No longer needed\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    schedule_df = read_capacity(CAPACITY_FILE, airport_substitutions=same_airports)\n",
    "    demand_df = read_market(MARKET_FILE, airport_substitutions=same_airports)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    if schedule_df.empty or demand_df.empty: return None, None\n",
    "\n",
    "    print(\"Initializing Flight Network...\")\n",
    "    network = FlightNetwork(min_connection_minutes=MIN_CONNECT_MINS, max_connection_minutes=MAX_CONNECT_MINS)\n",
    "    network.load_and_process_data(schedule_df, demand_df)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- Find K Shortest Paths (Sequential) ---\n",
    "    all_paths_dict_ints = network.find_all_k_shortest_paths_sequential(k=K_PATHS) # Call sequential method\n",
    "    # Summary is printed inside the method\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- Process Results ---\n",
    "    paths_df = network.get_paths_as_dataframe(all_paths_dict_ints)\n",
    "    if not paths_df.empty:\n",
    "        print(\"\\nDataFrame Head (First 5 paths):\")\n",
    "        print(paths_df[['demand_id', 'path_rank', 'path_cost_minutes', 'path_duration_minutes', 'num_flights', 'flight_int_ids']].head())\n",
    "    elif not all_paths_dict_ints: print(\"\\nNo paths were found for any demand.\")\n",
    "    else: print(\"\\nPaths dictionary generated, but DataFrame is empty.\") # Should be caught by df empty check\n",
    "\n",
    "    print(f\"\\nTotal execution time: {time.time() - overall_start_time:.2f} seconds\")\n",
    "    print(\"Final Network Stats:\")\n",
    "    for stat, value in network.stats.items():\n",
    "        if isinstance(value, float): print(f\"  {stat}: {value:.2f}s\")\n",
    "        else: print(f\"  {stat}: {value}\")\n",
    "    print(\"-\" * 30)\n",
    "    return network, paths_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Dummy file creation (Unchanged)\n",
    "    if not os.path.exists('files'): os.makedirs('files')\n",
    "    if not os.path.exists('files/capacity.csv'):\n",
    "        pd.DataFrame({'Flight Number': ['FL100', 'FL101', 'FL102'], 'Orig': ['AAA', 'BBB', 'AAA'], 'Dest': ['BBB', 'CCC', 'BBB'],'Weekday_Z': ['Mon', 'Mon', 'Tue'], 'deptime': ['2024-01-01 10:00', '2024-01-01 14:00', '2024-01-02 09:00'],'arrtime': ['2024-01-01 12:00', '2024-01-01 16:00', '2024-01-02 11:00'],'Net Payload': [1000, 1000, 500], 'Net Volume': [10, 10, 5]}).to_csv('files/capacity.csv', index=False)\n",
    "        print(\"Created dummy files/capacity.csv\")\n",
    "    if not os.path.exists('files/market.csv'):\n",
    "         pd.DataFrame({'origin': ['AAA', 'AAA'], 'destination': ['CCC', 'BBB'], 'Market CHW': [100, 50],'Day': ['Mon', 'Tue'], 'Time': ['08:00', '07:00']}).to_csv('files/market.csv', index=False, sep=';')\n",
    "         print(\"Created dummy files/market.csv\")\n",
    "\n",
    "    print(\"Starting K-Shortest Path Calculation (Sequential)...\")\n",
    "    network_obj, paths_df_result = main()\n",
    "\n",
    "    if network_obj:\n",
    "        print(\"\\nScript finished.\")\n",
    "        if paths_df_result is not None and not paths_df_result.empty:\n",
    "             print(f\"Total paths generated in DataFrame: {len(paths_df_result)}\")\n",
    "        elif paths_df_result is not None:\n",
    "             print(\"DataFrame was generated but is empty.\")\n",
    "        else:\n",
    "             print(\"DataFrame generation failed.\") # Indicates None was returned from main\n",
    "    else:\n",
    "        print(\"\\nScript finished with errors (likely during data loading or network init).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_id</th>\n",
       "      <th>demand_key</th>\n",
       "      <th>path_rank</th>\n",
       "      <th>path_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>demand_kg</th>\n",
       "      <th>path_cost_minutes</th>\n",
       "      <th>path_duration_minutes</th>\n",
       "      <th>num_flights</th>\n",
       "      <th>final_arrival_minutes</th>\n",
       "      <th>flight_int_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>1</td>\n",
       "      <td>AMS/LAX/1080_p1</td>\n",
       "      <td>AMS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>4366.625</td>\n",
       "      <td>18753</td>\n",
       "      <td>9618</td>\n",
       "      <td>3</td>\n",
       "      <td>618</td>\n",
       "      <td>[34, 1356, 508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>2</td>\n",
       "      <td>AMS/LAX/1080_p2</td>\n",
       "      <td>AMS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>4366.625</td>\n",
       "      <td>18960</td>\n",
       "      <td>9830</td>\n",
       "      <td>3</td>\n",
       "      <td>830</td>\n",
       "      <td>[34, 1356, 524]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>AMS/LAX/1080</td>\n",
       "      <td>3</td>\n",
       "      <td>AMS/LAX/1080_p3</td>\n",
       "      <td>AMS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>4366.625</td>\n",
       "      <td>19625</td>\n",
       "      <td>410</td>\n",
       "      <td>3</td>\n",
       "      <td>1490</td>\n",
       "      <td>[34, 1356, 496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMS/LAX/2520</td>\n",
       "      <td>AMS/LAX/2520</td>\n",
       "      <td>1</td>\n",
       "      <td>AMS/LAX/2520_p1</td>\n",
       "      <td>AMS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2481.625</td>\n",
       "      <td>17313</td>\n",
       "      <td>8178</td>\n",
       "      <td>3</td>\n",
       "      <td>618</td>\n",
       "      <td>[34, 1356, 508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMS/LAX/2520</td>\n",
       "      <td>AMS/LAX/2520</td>\n",
       "      <td>2</td>\n",
       "      <td>AMS/LAX/2520_p2</td>\n",
       "      <td>AMS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2481.625</td>\n",
       "      <td>17520</td>\n",
       "      <td>8390</td>\n",
       "      <td>3</td>\n",
       "      <td>830</td>\n",
       "      <td>[34, 1356, 524]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>YHM/VIT/8280</td>\n",
       "      <td>YHM/VIT/8280</td>\n",
       "      <td>2</td>\n",
       "      <td>YHM/VIT/8280_p2</td>\n",
       "      <td>YHM</td>\n",
       "      <td>VIT</td>\n",
       "      <td>3.400</td>\n",
       "      <td>12810</td>\n",
       "      <td>3490</td>\n",
       "      <td>3</td>\n",
       "      <td>1690</td>\n",
       "      <td>[2042, 634, 1343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>YHM/VIT/8280</td>\n",
       "      <td>YHM/VIT/8280</td>\n",
       "      <td>3</td>\n",
       "      <td>YHM/VIT/8280_p3</td>\n",
       "      <td>YHM</td>\n",
       "      <td>VIT</td>\n",
       "      <td>3.400</td>\n",
       "      <td>12810</td>\n",
       "      <td>3490</td>\n",
       "      <td>3</td>\n",
       "      <td>1690</td>\n",
       "      <td>[2042, 633, 1343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>1</td>\n",
       "      <td>YHM/VIT/9720_p1</td>\n",
       "      <td>YHM</td>\n",
       "      <td>VIT</td>\n",
       "      <td>9.600</td>\n",
       "      <td>11370</td>\n",
       "      <td>2050</td>\n",
       "      <td>3</td>\n",
       "      <td>1690</td>\n",
       "      <td>[2042, 632, 1343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>2</td>\n",
       "      <td>YHM/VIT/9720_p2</td>\n",
       "      <td>YHM</td>\n",
       "      <td>VIT</td>\n",
       "      <td>9.600</td>\n",
       "      <td>11370</td>\n",
       "      <td>2050</td>\n",
       "      <td>3</td>\n",
       "      <td>1690</td>\n",
       "      <td>[2042, 634, 1343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>YHM/VIT/9720</td>\n",
       "      <td>3</td>\n",
       "      <td>YHM/VIT/9720_p3</td>\n",
       "      <td>YHM</td>\n",
       "      <td>VIT</td>\n",
       "      <td>9.600</td>\n",
       "      <td>11370</td>\n",
       "      <td>2050</td>\n",
       "      <td>3</td>\n",
       "      <td>1690</td>\n",
       "      <td>[2042, 633, 1343]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8116 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         demand_id    demand_key  path_rank          path_id origin  \\\n",
       "0     AMS/LAX/1080  AMS/LAX/1080          1  AMS/LAX/1080_p1    AMS   \n",
       "1     AMS/LAX/1080  AMS/LAX/1080          2  AMS/LAX/1080_p2    AMS   \n",
       "2     AMS/LAX/1080  AMS/LAX/1080          3  AMS/LAX/1080_p3    AMS   \n",
       "3     AMS/LAX/2520  AMS/LAX/2520          1  AMS/LAX/2520_p1    AMS   \n",
       "4     AMS/LAX/2520  AMS/LAX/2520          2  AMS/LAX/2520_p2    AMS   \n",
       "...            ...           ...        ...              ...    ...   \n",
       "8111  YHM/VIT/8280  YHM/VIT/8280          2  YHM/VIT/8280_p2    YHM   \n",
       "8112  YHM/VIT/8280  YHM/VIT/8280          3  YHM/VIT/8280_p3    YHM   \n",
       "8113  YHM/VIT/9720  YHM/VIT/9720          1  YHM/VIT/9720_p1    YHM   \n",
       "8114  YHM/VIT/9720  YHM/VIT/9720          2  YHM/VIT/9720_p2    YHM   \n",
       "8115  YHM/VIT/9720  YHM/VIT/9720          3  YHM/VIT/9720_p3    YHM   \n",
       "\n",
       "     destination  demand_kg  path_cost_minutes  path_duration_minutes  \\\n",
       "0            LAX   4366.625              18753                   9618   \n",
       "1            LAX   4366.625              18960                   9830   \n",
       "2            LAX   4366.625              19625                    410   \n",
       "3            LAX   2481.625              17313                   8178   \n",
       "4            LAX   2481.625              17520                   8390   \n",
       "...          ...        ...                ...                    ...   \n",
       "8111         VIT      3.400              12810                   3490   \n",
       "8112         VIT      3.400              12810                   3490   \n",
       "8113         VIT      9.600              11370                   2050   \n",
       "8114         VIT      9.600              11370                   2050   \n",
       "8115         VIT      9.600              11370                   2050   \n",
       "\n",
       "      num_flights  final_arrival_minutes     flight_int_ids  \n",
       "0               3                    618    [34, 1356, 508]  \n",
       "1               3                    830    [34, 1356, 524]  \n",
       "2               3                   1490    [34, 1356, 496]  \n",
       "3               3                    618    [34, 1356, 508]  \n",
       "4               3                    830    [34, 1356, 524]  \n",
       "...           ...                    ...                ...  \n",
       "8111            3                   1690  [2042, 634, 1343]  \n",
       "8112            3                   1690  [2042, 633, 1343]  \n",
       "8113            3                   1690  [2042, 632, 1343]  \n",
       "8114            3                   1690  [2042, 634, 1343]  \n",
       "8115            3                   1690  [2042, 633, 1343]  \n",
       "\n",
       "[8116 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The time calculations are incorrect, make sure to not use days and time but just the minutes after start, where day 0 time 0 is the start..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nicelly working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_capacity():\n",
    "    capacity = pd.read_csv('files/capacity.csv', sep=';')\n",
    "    # turn STD-HH:MM into dep_time datetime, and START-HH:MM into arr_time datetime , datetime64[ns]!!!\n",
    "    capacity['dep_time'] = capacity['STD-HH:MM'].str.replace(':', '').astype(int)\n",
    "    capacity['arr_time'] = capacity['STA-HH:MM'].str.replace(':', '').astype(int)\n",
    "    # convert Weekday_Z into Day which is just a number, so turn Mon into 0, Tue into 1, ..., Sun into 6\n",
    "    capacity['day'] = capacity['Weekday_Z'].map({'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6})\n",
    "    capacity['date_time'] = capacity['day'].astype(str) + '/' + capacity['dep_time'].astype(str)\n",
    "    # delete the columns that are not needed, reorder the columns\n",
    "    rename_columns = {'Net Payload': 'cap_kg', 'Net Volume': 'cap_m3', 'Orig':'ori', 'Dest':'des', 'Flight Number':'flight_number', 'A/C':'aircraft_type'}\n",
    "    capacity = capacity.rename(columns=rename_columns)\n",
    "    columns = ['flight_number','ori','des','aircraft_type' ,'dep_time', 'arr_time', 'day', 'date_time','cap_kg', 'cap_m3', 'key']\n",
    "    capacity['key'] = capacity['ori'] + '/'+ capacity['des'] +'/'+ capacity['date_time']\n",
    "    capacity = capacity[columns]\n",
    "    return capacity\n",
    "\n",
    "def read_market():\n",
    "    market = pd.read_csv('files/market.csv', sep=';')\n",
    "    market = market.rename(columns={'origin':'ori', 'destination':'des', 'Market CHW': 'demand', 'Day':'day', 'Time':'time'})\n",
    "    market.drop(columns=['Market Allin Yield','product'], inplace=True)\n",
    "    # turn time into just a 4 digit number\n",
    "    market['time'] = market['time'].str.replace(':', '').astype(int)\n",
    "    market['day'] = market['day'].map({'Mon': 0, 'Tue': 1, 'Wed': 2, 'Thu': 3, 'Fri': 4, 'Sat': 5, 'Sun': 6})\n",
    "    market['date_time'] = market['day'].astype(str) + '/' + market['time'].astype(str)\n",
    "    market['key'] = market['ori'] + '/'+ market['des'] +'/'+ market['date_time']\n",
    "    return market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import time\n",
    "from itertools import islice\n",
    "\n",
    "class FlightNetwork:\n",
    "    \"\"\"\n",
    "    An optimized representation of the flight network for efficient path finding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, connection_window_hours=48, min_connection_minutes=60):\n",
    "        \"\"\"\n",
    "        Initialize the flight network.\n",
    "        \n",
    "        Args:\n",
    "            connection_window_hours: Maximum time window for connections in hours\n",
    "            min_connection_minutes: Minimum connection time in minutes\n",
    "        \"\"\"\n",
    "        self.connection_window_minutes = connection_window_hours * 60\n",
    "        self.min_connection_minutes = min_connection_minutes\n",
    "        \n",
    "        # Core data structures\n",
    "        self.flights = {}  # flight_id -> flight_data\n",
    "        self.airports = set()  # Set of all airports\n",
    "        self.demands = {}  # demand_id -> demand_data\n",
    "        \n",
    "        # Index structures for fast lookups\n",
    "        self.flights_by_origin = defaultdict(list)\n",
    "        self.flights_by_destination = defaultdict(list)\n",
    "        self.flights_by_day_time = defaultdict(list)  # (day, time) -> [flight_ids]\n",
    "        \n",
    "        # Path cache to avoid recomputing\n",
    "        self.path_cache = {}\n",
    "        \n",
    "        # Convert time to total minutes for faster comparison\n",
    "        self.time_to_minutes_cache = {}\n",
    "    \n",
    "    def time_to_minutes(self, day, time):\n",
    "        \"\"\"\n",
    "        Convert day and time to total minutes since start of week.\n",
    "        Cache results for better performance.\n",
    "        \"\"\"\n",
    "        key = (day, time)\n",
    "        if key not in self.time_to_minutes_cache:\n",
    "            # Convert time (HHMM) to hours and minutes\n",
    "            hours = time // 100\n",
    "            minutes = time % 100\n",
    "            \n",
    "            # Total minutes since start of week\n",
    "            self.time_to_minutes_cache[key] = (day * 24 * 60) + (hours * 60) + minutes\n",
    "            \n",
    "        return self.time_to_minutes_cache[key]\n",
    "    \n",
    "    def load_data(self, schedule_df, demand_df):\n",
    "        \"\"\"\n",
    "        Load and preprocess the schedule and demand data efficiently.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process schedule data\n",
    "        for _, flight in schedule_df.iterrows():\n",
    "            flight_id = f\"{flight['flight_number']}_{flight['day']}_{flight['dep_time']}\"\n",
    "            \n",
    "            # Precompute flight times in minutes for faster comparisons\n",
    "            dep_minutes = self.time_to_minutes(flight['day'], flight['dep_time'])\n",
    "            arr_minutes = self.time_to_minutes(flight['day'], flight['arr_time'])\n",
    "            \n",
    "            # Handle overnight flights (arrival time < departure time)\n",
    "            if arr_minutes < dep_minutes:\n",
    "                arr_minutes += 24 * 60  # Add a day's worth of minutes\n",
    "            \n",
    "            flight_data = {\n",
    "                'id': flight_id,\n",
    "                'flight_number': flight['flight_number'],\n",
    "                'origin': flight['ori'],\n",
    "                'destination': flight['des'],\n",
    "                'day': flight['day'],\n",
    "                'dep_time': flight['dep_time'],\n",
    "                'arr_time': flight['arr_time'],\n",
    "                'dep_minutes': dep_minutes,\n",
    "                'arr_minutes': arr_minutes,\n",
    "                'capacity_kg': flight['cap_kg'],\n",
    "                'capacity_m3': flight['cap_m3']\n",
    "            }\n",
    "            \n",
    "            self.flights[flight_id] = flight_data\n",
    "            self.flights_by_origin[flight['ori']].append(flight_id)\n",
    "            self.flights_by_destination[flight['des']].append(flight_id)\n",
    "            self.flights_by_day_time[(flight['day'], flight['dep_time'])].append(flight_id)\n",
    "            \n",
    "            self.airports.add(flight['ori'])\n",
    "            self.airports.add(flight['des'])\n",
    "        \n",
    "        # Sort flight lists by departure time for faster sequential access\n",
    "        for airport in self.flights_by_origin:\n",
    "            self.flights_by_origin[airport].sort(\n",
    "                key=lambda f_id: self.flights[f_id]['dep_minutes']\n",
    "            )\n",
    "        \n",
    "        for airport in self.flights_by_destination:\n",
    "            self.flights_by_destination[airport].sort(\n",
    "                key=lambda f_id: self.flights[f_id]['arr_minutes']\n",
    "            )\n",
    "        \n",
    "        # Process demand data\n",
    "        for _, demand in demand_df.iterrows():\n",
    "            demand_id = f\"{demand['ori']}_{demand['des']}_{demand['day']}_{demand['time']}\"\n",
    "            \n",
    "            demand_minutes = self.time_to_minutes(demand['day'], demand['time'])\n",
    "            \n",
    "            demand_data = {\n",
    "                'id': demand_id,\n",
    "                'origin': demand['ori'],\n",
    "                'destination': demand['des'],\n",
    "                'day': demand['day'],\n",
    "                'time': demand['time'],\n",
    "                'minutes': demand_minutes,\n",
    "                'demand': demand['demand'],\n",
    "                'key': demand['key']\n",
    "            }\n",
    "            \n",
    "            self.demands[demand_id] = demand_data\n",
    "        \n",
    "        print(f\"Data loaded and indexed in {time.time() - start_time:.2f} seconds\")\n",
    "        print(f\"Network has {len(self.flights)} flights and {len(self.demands)} demands across {len(self.airports)} airports\")\n",
    "    \n",
    "    def build_adjacency_lists(self):\n",
    "        \"\"\"\n",
    "        Build optimized adjacency lists for fast path finding.\n",
    "        This precomputes valid connections between flights.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize adjacency lists\n",
    "        self.outgoing_edges = defaultdict(list)\n",
    "        self.source_connections = defaultdict(list)\n",
    "        self.sink_connections = defaultdict(dict)\n",
    "        \n",
    "        # Build flight-to-flight connections efficiently\n",
    "        # Group flights by destination for faster processing\n",
    "        for origin_airport in self.flights_by_origin:\n",
    "            # Get all flights departing from this origin\n",
    "            arriving_flights = set()\n",
    "            \n",
    "            for flight1_id in self.flights_by_destination[origin_airport]:\n",
    "                flight1 = self.flights[flight1_id]\n",
    "                arriving_flights.add(flight1_id)\n",
    "                \n",
    "                # Find potential connecting flights efficiently\n",
    "                # Only consider flights that depart after flight1 arrives + min connection time\n",
    "                min_dep_minutes = flight1['arr_minutes'] + self.min_connection_minutes\n",
    "                max_dep_minutes = flight1['arr_minutes'] + self.connection_window_minutes\n",
    "                \n",
    "                for flight2_id in self.flights_by_origin[origin_airport]:\n",
    "                    flight2 = self.flights[flight2_id]\n",
    "                    \n",
    "                    # Fast time comparison using precomputed minutes\n",
    "                    if min_dep_minutes <= flight2['dep_minutes'] <= max_dep_minutes:\n",
    "                        wait_time = flight2['dep_minutes'] - flight1['arr_minutes']\n",
    "                        \n",
    "                        # Add connection to adjacency list\n",
    "                        self.outgoing_edges[flight1_id].append((flight2_id, wait_time))\n",
    "\n",
    "        # Build source-to-flight connections (demand to flight)\n",
    "        for demand_id, demand in self.demands.items():\n",
    "            origin = demand['origin']\n",
    "            dest = demand['destination']\n",
    "            demand_minutes = demand['minutes']\n",
    "            \n",
    "            # Optimization: Only consider flights from the same origin\n",
    "            for flight_id in self.flights_by_origin[origin]:\n",
    "                flight = self.flights[flight_id]\n",
    "                \n",
    "                # Check if flight departs after demand time but within window\n",
    "                if demand_minutes <= flight['dep_minutes'] <= demand_minutes + self.connection_window_minutes:\n",
    "                    wait_time = flight['dep_minutes'] - demand_minutes\n",
    "                    self.source_connections[demand_id].append((flight_id, wait_time))\n",
    "            \n",
    "            # Track sink connections for this demand\n",
    "            self.sink_connections[demand_id] = dest\n",
    "        \n",
    "        print(f\"Adjacency lists built in {time.time() - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Analyze connectivity\n",
    "        total_connections = sum(len(edges) for edges in self.outgoing_edges.values())\n",
    "        total_source_connections = sum(len(conns) for conns in self.source_connections.values())\n",
    "        \n",
    "        print(f\"Network has {total_connections} flight-to-flight connections\")\n",
    "        print(f\"Network has {total_source_connections} source-to-flight connections\")\n",
    "        \n",
    "        # Check for sources with no connections\n",
    "        disconnected_sources = [d_id for d_id in self.demands if not self.source_connections[d_id]]\n",
    "        print(f\"Found {len(disconnected_sources)} disconnected sources ({len(disconnected_sources)/len(self.demands):.1%} of total)\")\n",
    "    \n",
    "    def find_shortest_path(self, demand_id):\n",
    "        \"\"\"\n",
    "        Find the shortest path for a given demand using optimized Dijkstra's algorithm.\n",
    "        \"\"\"\n",
    "        if demand_id not in self.demands:\n",
    "            return None\n",
    "        \n",
    "        # Check cache first\n",
    "        if demand_id in self.path_cache:\n",
    "            return self.path_cache[demand_id]\n",
    "        \n",
    "        demand = self.demands[demand_id]\n",
    "        target_airport = demand['destination']\n",
    "        \n",
    "        # No outgoing connections for this source\n",
    "        if not self.source_connections[demand_id]:\n",
    "            return None\n",
    "        \n",
    "        # Initialize Dijkstra's algorithm\n",
    "        distances = {demand_id: 0}  # Source to itself has distance 0\n",
    "        previous = {}\n",
    "        pq = [(0, demand_id)]  # Priority queue (min-heap) of (distance, node)\n",
    "        visited = set()\n",
    "        found_sink = False\n",
    "        \n",
    "        while pq and not found_sink:\n",
    "            dist, current = heapq.heappop(pq)\n",
    "            \n",
    "            if current in visited:\n",
    "                continue\n",
    "            \n",
    "            visited.add(current)\n",
    "            \n",
    "            # If we've reached a flight going to the target destination, we're done\n",
    "            if current in self.flights:\n",
    "                flight = self.flights[current]\n",
    "                if flight['destination'] == target_airport:\n",
    "                    found_sink = True\n",
    "                    break\n",
    "            \n",
    "            # Process outgoing edges\n",
    "            if current == demand_id:\n",
    "                # Source connections\n",
    "                edges = self.source_connections[current]\n",
    "            elif current in self.flights:\n",
    "                # Flight-to-flight connections\n",
    "                edges = self.outgoing_edges[current]\n",
    "            else:\n",
    "                edges = []\n",
    "            \n",
    "            for neighbor, weight in edges:\n",
    "                if neighbor in visited:\n",
    "                    continue\n",
    "                \n",
    "                alt = distances[current] + weight\n",
    "                if neighbor not in distances or alt < distances[neighbor]:\n",
    "                    distances[neighbor] = alt\n",
    "                    previous[neighbor] = current\n",
    "                    heapq.heappush(pq, (alt, neighbor))\n",
    "        \n",
    "        # Reconstruct path if we found one\n",
    "        if found_sink:\n",
    "            # Find the flight to target destination with minimum total distance\n",
    "            min_dist = float('inf')\n",
    "            end_node = None\n",
    "            \n",
    "            for node in visited:\n",
    "                if node in self.flights and self.flights[node]['destination'] == target_airport:\n",
    "                    if distances[node] < min_dist:\n",
    "                        min_dist = distances[node]\n",
    "                        end_node = node\n",
    "            \n",
    "            path = []\n",
    "            while end_node:\n",
    "                path.append(end_node)\n",
    "                end_node = previous.get(end_node)\n",
    "            \n",
    "            path.reverse()  # Reverse to get source-to-sink order\n",
    "            \n",
    "            # Cache the result\n",
    "            self.path_cache[demand_id] = path\n",
    "            return path\n",
    "        \n",
    "        # No path found\n",
    "        self.path_cache[demand_id] = None\n",
    "        return None\n",
    "    \n",
    "    def find_k_shortest_paths(self, demand_id, k=3):\n",
    "        \"\"\"\n",
    "        Find up to k shortest paths for a demand using Yen's algorithm.\n",
    "        This is more efficient than NetworkX's implementation for large networks.\n",
    "        \"\"\"\n",
    "        if demand_id not in self.demands:\n",
    "            return []\n",
    "        \n",
    "        demand = self.demands[demand_id]\n",
    "        target_airport = demand['destination']\n",
    "        \n",
    "        # Find first shortest path\n",
    "        A = [self.find_shortest_path(demand_id)]\n",
    "        if not A[0]:\n",
    "            return []\n",
    "        \n",
    "        # Initialize potential paths\n",
    "        B = []\n",
    "        \n",
    "        # Find k-1 more paths\n",
    "        for k_idx in range(1, k):\n",
    "            # Previous path\n",
    "            prev_path = A[-1]\n",
    "            \n",
    "            # Try deviation at each node in the previous path (except the last)\n",
    "            for i in range(len(prev_path) - 1):\n",
    "                spur_node = prev_path[i]\n",
    "                root_path = prev_path[:i+1]\n",
    "                \n",
    "                # Remove edges in root_path from graph temporarily\n",
    "                excluded_edges = set()\n",
    "                for path_idx in range(len(A)):\n",
    "                    curr_path = A[path_idx]\n",
    "                    if len(curr_path) > i + 1 and curr_path[:i+1] == root_path:\n",
    "                        # Exclude this edge to find alternative path\n",
    "                        excluded_edges.add((curr_path[i], curr_path[i+1]))\n",
    "                \n",
    "                # Find shortest path from spur node to sink with excluded edges\n",
    "                spur_path = self._find_spur_path(spur_node, target_airport, excluded_edges)\n",
    "                if not spur_path:\n",
    "                    continue\n",
    "                \n",
    "                # Build the complete path\n",
    "                complete_path = root_path + spur_path[1:]\n",
    "                \n",
    "                # Add to candidates if not already there\n",
    "                if complete_path not in B:\n",
    "                    # Calculate path length (sum of wait times)\n",
    "                    path_length = self._calculate_path_length(complete_path)\n",
    "                    heapq.heappush(B, (path_length, complete_path))\n",
    "            \n",
    "            # No more candidates\n",
    "            if not B:\n",
    "                break\n",
    "            \n",
    "            # Add the next best path to A\n",
    "            _, next_path = heapq.heappop(B)\n",
    "            A.append(next_path)\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def _find_spur_path(self, start_node, target_airport, excluded_edges):\n",
    "        \"\"\"Helper method for Yen's k-shortest paths algorithm\"\"\"\n",
    "        # This is a simplified version - in a production system, you'd want to \n",
    "        # make a temporary copy of the graph excluding certain edges\n",
    "        \n",
    "        # For our purposes, we'll use a modified Dijkstra that avoids excluded edges\n",
    "        distances = {start_node: 0}\n",
    "        previous = {}\n",
    "        pq = [(0, start_node)]\n",
    "        visited = set()\n",
    "        found_sink = False\n",
    "        \n",
    "        while pq and not found_sink:\n",
    "            dist, current = heapq.heappop(pq)\n",
    "            \n",
    "            if current in visited:\n",
    "                continue\n",
    "            \n",
    "            visited.add(current)\n",
    "            \n",
    "            # If we've reached a flight going to the target destination, we're done\n",
    "            if current in self.flights and self.flights[current]['destination'] == target_airport:\n",
    "                found_sink = True\n",
    "                break\n",
    "            \n",
    "            # Process outgoing edges\n",
    "            if current == start_node and start_node in self.demands:\n",
    "                # Start node is a demand source\n",
    "                edges = self.source_connections[current]\n",
    "            elif current in self.flights:\n",
    "                # Flight-to-flight connections\n",
    "                edges = self.outgoing_edges[current]\n",
    "            else:\n",
    "                edges = []\n",
    "            \n",
    "            for neighbor, weight in edges:\n",
    "                # Skip excluded edges\n",
    "                if (current, neighbor) in excluded_edges:\n",
    "                    continue\n",
    "                    \n",
    "                if neighbor in visited:\n",
    "                    continue\n",
    "                \n",
    "                alt = distances[current] + weight\n",
    "                if neighbor not in distances or alt < distances[neighbor]:\n",
    "                    distances[neighbor] = alt\n",
    "                    previous[neighbor] = current\n",
    "                    heapq.heappush(pq, (alt, neighbor))\n",
    "        \n",
    "        # Reconstruct path if we found one\n",
    "        if found_sink:\n",
    "            # Find the flight to target destination with minimum total distance\n",
    "            min_dist = float('inf')\n",
    "            end_node = None\n",
    "            \n",
    "            for node in visited:\n",
    "                if node in self.flights and self.flights[node]['destination'] == target_airport:\n",
    "                    if distances[node] < min_dist:\n",
    "                        min_dist = distances[node]\n",
    "                        end_node = node\n",
    "            \n",
    "            path = []\n",
    "            while end_node:\n",
    "                path.append(end_node)\n",
    "                end_node = previous.get(end_node)\n",
    "            \n",
    "            path.reverse()  # Reverse to get source-to-sink order\n",
    "            return path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _calculate_path_length(self, path):\n",
    "        \"\"\"Calculate the total length (wait time) of a path\"\"\"\n",
    "        if not path or len(path) < 2:\n",
    "            return float('inf')\n",
    "            \n",
    "        total_length = 0\n",
    "        for i in range(len(path) - 1):\n",
    "            current, next_node = path[i], path[i+1]\n",
    "            \n",
    "            # Find the edge weight between these nodes\n",
    "            if current in self.demands:\n",
    "                # Source to flight\n",
    "                for neighbor, weight in self.source_connections[current]:\n",
    "                    if neighbor == next_node:\n",
    "                        total_length += weight\n",
    "                        break\n",
    "            else:\n",
    "                # Flight to flight\n",
    "                for neighbor, weight in self.outgoing_edges[current]:\n",
    "                    if neighbor == next_node:\n",
    "                        total_length += weight\n",
    "                        break\n",
    "        \n",
    "        return total_length\n",
    "    \n",
    "    def find_all_paths(self, k=3):\n",
    "        \"\"\"\n",
    "        Find k shortest paths for all demands.\n",
    "        Returns a dictionary {demand_id: [path1, path2, ...]}\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = {}\n",
    "        for i, (demand_id, demand) in enumerate(self.demands.items()):\n",
    "            paths = self.find_k_shortest_paths(demand_id, k)\n",
    "            results[demand_id] = paths\n",
    "            \n",
    "            # Print progress every 100 demands\n",
    "            if (i + 1) % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Processed {i+1}/{len(self.demands)} demands in {elapsed:.2f}s ({(i+1)/elapsed:.1f} demands/s)\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        avg_time = total_time / len(self.demands) if self.demands else 0\n",
    "        \n",
    "        print(f\"Found paths for all {len(self.demands)} demands in {total_time:.2f}s\")\n",
    "        print(f\"Average time: {avg_time*1000:.2f}ms per demand\")\n",
    "        \n",
    "        # Calculate some statistics\n",
    "        demands_with_paths = sum(1 for paths in results.values() if paths)\n",
    "        avg_paths_per_demand = sum(len(paths) for paths in results.values()) / len(self.demands)\n",
    "        \n",
    "        print(f\"{demands_with_paths}/{len(self.demands)} demands have at least one path ({demands_with_paths/len(self.demands):.1%})\")\n",
    "        print(f\"Average {avg_paths_per_demand:.2f} paths per demand\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def format_path(self, demand_id, path):\n",
    "        \"\"\"Format a path for human-readable display\"\"\"\n",
    "        if not path:\n",
    "            return \"No path found\"\n",
    "        \n",
    "        result = []\n",
    "        demand = self.demands[demand_id]\n",
    "        \n",
    "        # First node is the source\n",
    "        result.append(f\"Source: {demand['origin']} â†’ {demand['destination']} (Day {demand['day']}, Time {demand['time']})\")\n",
    "        \n",
    "        # Rest are flights\n",
    "        for node in path:\n",
    "            if node in self.flights:\n",
    "                flight = self.flights[node]\n",
    "                result.append(f\"Flight: {flight['flight_number']} from {flight['origin']} â†’ {flight['destination']} \" +\n",
    "                              f\"(Day {flight['day']}, Dep {flight['dep_time']}, Arr {flight['arr_time']})\")\n",
    "        \n",
    "        return \"\\n\".join(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_path_finding(network, sample_size=100):\n",
    "    \"\"\"Benchmark the path finding performance\"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Sample random demands\n",
    "    if len(network.demands) <= sample_size:\n",
    "        demand_sample = list(network.demands.keys())\n",
    "    else:\n",
    "        demand_sample = random.sample(list(network.demands.keys()), sample_size)\n",
    "    \n",
    "    print(f\"Benchmarking path finding with {len(demand_sample)} random demands...\")\n",
    "    \n",
    "    # Benchmark single path finding\n",
    "    start_time = time.time()\n",
    "    paths_found = 0\n",
    "    \n",
    "    for demand_id in demand_sample:\n",
    "        path = network.find_shortest_path(demand_id)\n",
    "        if path:\n",
    "            paths_found += 1\n",
    "    \n",
    "    single_path_time = time.time() - start_time\n",
    "    print(f\"Found {paths_found}/{len(demand_sample)} single shortest paths in {single_path_time:.2f}s\")\n",
    "    print(f\"Average: {single_path_time*1000/len(demand_sample):.2f}ms per demand\")\n",
    "    \n",
    "    # Benchmark k-shortest paths\n",
    "    k = 3\n",
    "    start_time = time.time()\n",
    "    total_paths = 0\n",
    "    \n",
    "    for demand_id in demand_sample:\n",
    "        paths = network.find_k_shortest_paths(demand_id, k)\n",
    "        total_paths += len(paths)\n",
    "    \n",
    "    k_paths_time = time.time() - start_time\n",
    "    print(f\"Found {total_paths} paths (max {k} per demand) in {k_paths_time:.2f}s\")\n",
    "    print(f\"Average: {k_paths_time*1000/len(demand_sample):.2f}ms per demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in 0.01s\n",
      "Schedule has 1731 flights\n",
      "Demand has 3689 entries\n",
      "Data loaded and indexed in 0.10 seconds\n",
      "Network has 1731 flights and 3689 demands across 102 airports\n",
      "Adjacency lists built in 0.02 seconds\n",
      "Network has 37197 flight-to-flight connections\n",
      "Network has 44845 source-to-flight connections\n",
      "Found 417 disconnected sources (11.3% of total)\n",
      "Benchmarking path finding with 100 random demands...\n",
      "Found 58/100 single shortest paths in 0.02s\n",
      "Average: 0.20ms per demand\n",
      "Found 170 paths (max 3 per demand) in 0.18s\n",
      "Average: 1.78ms per demand\n",
      "\n",
      "Finding paths for demand DXB/SIN/0/1800 (DXB â†’ SIN, 3004.1475 kg)\n",
      "Found 3 paths:\n",
      "\n",
      "Path 1:\n",
      "Source: DXB â†’ SIN (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES783 from BAH â†’ SIN (Day 1, Dep 1225, Arr 2040)\n",
      "\n",
      "Path 2:\n",
      "Source: DXB â†’ SIN (Day 0, Time 1800)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES783 from BAH â†’ SIN (Day 1, Dep 1225, Arr 2040)\n",
      "\n",
      "Path 3:\n",
      "Source: DXB â†’ SIN (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES729 from BAH â†’ HKG (Day 1, Dep 1135, Arr 1940)\n",
      "Flight: 3S593 from HKG â†’ DEL (Day 1, Dep 2220, Arr 435)\n",
      "Flight: BZ408 from DEL â†’ BAH (Day 2, Dep 600, Arr 1015)\n",
      "Flight: ES781 from BAH â†’ SIN (Day 2, Dep 1225, Arr 2040)\n",
      "\n",
      "Finding paths for demand DXB/EMA/0/1800 (DXB â†’ EMA, 5542.571249999999 kg)\n",
      "Found 3 paths:\n",
      "\n",
      "Path 1:\n",
      "Source: DXB â†’ EMA (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: D0790 from BAH â†’ BRU (Day 1, Dep 1300, Arr 1950)\n",
      "Flight: D01 from BRU â†’ EMA (Day 1, Dep 2245, Arr 2355)\n",
      "\n",
      "Path 2:\n",
      "Source: DXB â†’ EMA (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES729 from BAH â†’ HKG (Day 1, Dep 1135, Arr 1940)\n",
      "Flight: 3S593 from HKG â†’ DEL (Day 1, Dep 2220, Arr 435)\n",
      "Flight: 3S593 from DEL â†’ EMA (Day 2, Dep 635, Arr 1620)\n",
      "\n",
      "Path 3:\n",
      "Source: DXB â†’ EMA (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: 3S520 from BAH â†’ HKG (Day 1, Dep 1325, Arr 2105)\n",
      "Flight: 3S593 from HKG â†’ DEL (Day 1, Dep 2220, Arr 435)\n",
      "Flight: 3S593 from DEL â†’ EMA (Day 2, Dep 635, Arr 1620)\n",
      "\n",
      "Finding paths for demand DXB/CGN/0/1800 (DXB â†’ CGN, 194.625 kg)\n",
      "Found 3 paths:\n",
      "\n",
      "Path 1:\n",
      "Source: DXB â†’ CGN (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES729 from BAH â†’ HKG (Day 1, Dep 1135, Arr 1940)\n",
      "Flight: QY549 from HKG â†’ ALA (Day 1, Dep 2200, Arr 445)\n",
      "Flight: QY549 from ALA â†’ CGN (Day 2, Dep 615, Arr 1420)\n",
      "\n",
      "Path 2:\n",
      "Source: DXB â†’ CGN (Day 0, Time 1800)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES729 from BAH â†’ HKG (Day 1, Dep 1135, Arr 1940)\n",
      "Flight: QY549 from HKG â†’ ALA (Day 1, Dep 2200, Arr 445)\n",
      "Flight: QY549 from ALA â†’ CGN (Day 2, Dep 615, Arr 1420)\n",
      "\n",
      "Path 3:\n",
      "Source: DXB â†’ CGN (Day 0, Time 1800)\n",
      "Flight: ES262 from DXB â†’ BAH (Day 0, Dep 1900, Arr 2025)\n",
      "Flight: ES265 from BAH â†’ DXB (Day 0, Dep 2225, Arr 2350)\n",
      "Flight: ES547 from DXB â†’ LHE (Day 1, Dep 110, Arr 415)\n",
      "Flight: ES548 from LHE â†’ BAH (Day 1, Dep 545, Arr 1010)\n",
      "Flight: ES729 from BAH â†’ HKG (Day 1, Dep 1135, Arr 1940)\n",
      "Flight: 3S593 from HKG â†’ DEL (Day 1, Dep 2220, Arr 435)\n",
      "Flight: BZ408 from DEL â†’ BAH (Day 2, Dep 600, Arr 1015)\n",
      "Flight: ES725 from BAH â†’ HKG (Day 2, Dep 1135, Arr 1940)\n",
      "Flight: QY547 from HKG â†’ ALA (Day 2, Dep 2200, Arr 445)\n",
      "Flight: QY547 from ALA â†’ CGN (Day 3, Dep 615, Arr 1420)\n",
      "\n",
      "Finding paths for demand CVG/CPH/0/1800 (CVG â†’ CPH, 5042.6745 kg)\n",
      "Found 3 paths:\n",
      "\n",
      "Path 1:\n",
      "Source: CVG â†’ CPH (Day 0, Time 1800)\n",
      "Flight: GB880 from CVG â†’ LAX (Day 0, Dep 2000, Arr 50)\n",
      "Flight: GB410 from LAX â†’ CVG (Day 1, Dep 200, Arr 610)\n",
      "Flight: KF277 from CVG â†’ BRU (Day 1, Dep 1005, Arr 1815)\n",
      "Flight: 3S117 from BRU â†’ LEJ (Day 1, Dep 2230, Arr 2350)\n",
      "Flight: QY178 from LEJ â†’ CPH (Day 2, Dep 230, Arr 345)\n",
      "\n",
      "Path 2:\n",
      "Source: CVG â†’ CPH (Day 0, Time 1800)\n",
      "Flight: GB880 from CVG â†’ LAX (Day 0, Dep 2000, Arr 50)\n",
      "Flight: GB403 from LAX â†’ CVG (Day 1, Dep 358, Arr 808)\n",
      "Flight: KF277 from CVG â†’ BRU (Day 1, Dep 1005, Arr 1815)\n",
      "Flight: 3S117 from BRU â†’ LEJ (Day 1, Dep 2230, Arr 2350)\n",
      "Flight: QY178 from LEJ â†’ CPH (Day 2, Dep 230, Arr 345)\n",
      "\n",
      "Path 3:\n",
      "Source: CVG â†’ CPH (Day 0, Time 1800)\n",
      "Flight: GB880 from CVG â†’ LAX (Day 0, Dep 2000, Arr 50)\n",
      "Flight: GB403 from LAX â†’ CVG (Day 1, Dep 358, Arr 808)\n",
      "Flight: D01 from CVG â†’ BRU (Day 1, Dep 1235, Arr 2045)\n",
      "Flight: 3S117 from BRU â†’ LEJ (Day 1, Dep 2230, Arr 2350)\n",
      "Flight: QY178 from LEJ â†’ CPH (Day 2, Dep 230, Arr 345)\n",
      "\n",
      "Finding paths for demand BLR/VIT/0/1800 (BLR â†’ VIT, 2016.7 kg)\n",
      "Found 3 paths:\n",
      "\n",
      "Path 1:\n",
      "Source: BLR â†’ VIT (Day 0, Time 1800)\n",
      "Flight: ES732 from BLR â†’ BAH (Day 1, Dep 410, Arr 910)\n",
      "Flight: ES771 from BAH â†’ HKG (Day 1, Dep 1050, Arr 1855)\n",
      "Flight: D0523 from HKG â†’ CVG (Day 1, Dep 2000, Arr 1050)\n",
      "Flight: D03 from CVG â†’ BRU (Day 2, Dep 1235, Arr 2045)\n",
      "Flight: 3S117 from BRU â†’ LEJ (Day 2, Dep 2230, Arr 2350)\n",
      "Flight: QY196 from LEJ â†’ VIT (Day 3, Dep 120, Arr 410)\n",
      "\n",
      "Path 2:\n",
      "Source: BLR â†’ VIT (Day 0, Time 1800)\n",
      "Flight: ES732 from BLR â†’ BAH (Day 1, Dep 410, Arr 910)\n",
      "Flight: ES771 from BAH â†’ HKG (Day 1, Dep 1050, Arr 1855)\n",
      "Flight: K4287 from HKG â†’ LAX (Day 1, Dep 2000, Arr 905)\n",
      "Flight: K4287 from LAX â†’ LEJ (Day 2, Dep 1120, Arr 2220)\n",
      "Flight: QY196 from LEJ â†’ VIT (Day 3, Dep 120, Arr 410)\n",
      "\n",
      "Path 3:\n",
      "Source: BLR â†’ VIT (Day 0, Time 1800)\n",
      "Flight: ES732 from BLR â†’ BAH (Day 1, Dep 410, Arr 910)\n",
      "Flight: QY752 from BAH â†’ MXP (Day 1, Dep 1335, Arr 2005)\n",
      "Flight: QY752 from MXP â†’ LEJ (Day 1, Dep 2205, Arr 2345)\n",
      "Flight: QY196 from LEJ â†’ VIT (Day 2, Dep 120, Arr 410)\n",
      "\n",
      "Total execution time: 0.35s\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read data\n",
    "    schedule_df = read_capacity()\n",
    "    demand_df = read_market()\n",
    "    \n",
    "    print(f\"Data loaded in {time.time() - start_time:.2f}s\")\n",
    "    print(f\"Schedule has {len(schedule_df)} flights\")\n",
    "    print(f\"Demand has {len(demand_df)} entries\")\n",
    "    \n",
    "    # Create and populate our optimized network structure\n",
    "    network = FlightNetwork(connection_window_hours=48, min_connection_minutes=60)\n",
    "    network.load_data(schedule_df, demand_df)\n",
    "    network.build_adjacency_lists()\n",
    "    \n",
    "    # Benchmark path finding performance\n",
    "    benchmark_path_finding(network, sample_size=min(100, len(network.demands)))\n",
    "    \n",
    "    # Sample some demands and find their paths\n",
    "    sample_demands = list(islice(network.demands.items(), 5))\n",
    "    \n",
    "    for demand_id, demand in sample_demands:\n",
    "        print(f\"\\nFinding paths for demand {demand['key']} ({demand['origin']} â†’ {demand['destination']}, {demand['demand']} kg)\")\n",
    "        \n",
    "        # Find k shortest paths\n",
    "        paths = network.find_k_shortest_paths(demand_id, k=3)\n",
    "        \n",
    "        print(f\"Found {len(paths)} paths:\")\n",
    "        for i, path in enumerate(paths):\n",
    "            print(f\"\\nPath {i+1}:\")\n",
    "            print(network.format_path(demand_id, path))\n",
    "    \n",
    "    print(f\"\\nTotal execution time: {time.time() - start_time:.2f}s\")\n",
    "    \n",
    "    return network, schedule_df, demand_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    network, schedule_df, demand_df = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a schedule and demand for intercontinetal flights, now I want to develop a LP program that assigns optimally flow on some paths that i create. Hence I need to develop algorithms for finding such diverse paths to transport the goods in the network. But first I need a solid representation to base those calculations on. Fot that I want to construct a graph from data in schedule and demand files, whose snippets I ahve provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a source vertex for each demand start - time specific\n",
    "# create a sink vertex for each demand end - not time specific, we shall register last flight arrival as end time   \n",
    "# create a vertex for each flight - time specific\n",
    "\n",
    "# create an arc between every flight vertex if arr(f1)<dep(f2) - 60min, and des(f1)==ori(f2)\n",
    "# create an arc from every source to every flight if dep(f1)>=start(s1) and ori(f1)==airport(s1)\n",
    "# create an arc from every flight to sink if des(f1)==airport(sink)\n",
    "\n",
    "# PROBLEMS:\n",
    "# 1. A LOT OF UNUSED EDGES, WHICH ARE USELESS - DAY 1 FLIGHT CAN TRANISITION TO DAY 7 FLIGHT - STUPID, UNREALISTIC - 2 day time window??\n",
    "# 2. CREATES LOTS OF POTENTIAL PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1731 flights and 3689 demand entries\n",
      "Graph has 5524 nodes and 95465 edges\n",
      "\n",
      "Node counts by type:\n",
      "  flight: 1731\n",
      "  source: 3689\n",
      "  sink: 80\n",
      "  unknown: 24\n",
      "\n",
      "Edge counts by type:\n",
      "  connection: 42030\n",
      "  flight_to_sink: 1731\n",
      "  source_to_flight: 51704\n",
      "\n",
      "WARNING: 222 source nodes have no outgoing paths\n",
      "\n",
      "Checking connectivity between sources and sinks...\n",
      "  Path exists from SOURCE_DXB_SIN_0_1800 to SINK_SIN with 2 intermediate flights\n",
      "  Path exists from SOURCE_DXB_EMA_0_1800 to SINK_EMA with 2 intermediate flights\n",
      "  Path exists from SOURCE_DXB_CGN_0_1800 to SINK_CGN with 3 intermediate flights\n",
      "  Path exists from SOURCE_CVG_CPH_0_1800 to SINK_CPH with 2 intermediate flights\n",
      "  Path exists from SOURCE_BLR_VIT_0_1800 to SINK_VIT with 2 intermediate flights\n",
      "\n",
      "5 out of 5 sampled source-sink pairs have valid paths\n",
      "\n",
      "Path 1 for demand SZX/CGN/3/1800 (demand: 2175.79125 kg):\n",
      "  Source: SZX â†’ CGN (Day 3, Time 1800)\n",
      "    â†’ Wait time before flight: 790 minutes\n",
      "  Flight: I98849 from SZX â†’ LEJ (Day 4, Dep 710, Arr 1930)\n",
      "    â†’ Connection wait time: 2395 minutes\n",
      "  Flight: 3S508 from LEJ â†’ HKG (Day 6, Dep 1125, Arr 2250)\n",
      "    â†’ Connection wait time: 1390 minutes\n",
      "  Flight: QY547 from HKG â†’ ALA (Day 0, Dep 2200, Arr 445)\n",
      "    â†’ Connection wait time: 1530 minutes\n",
      "  Flight: QY547 from ALA â†’ CGN (Day 1, Dep 615, Arr 1420)\n",
      "  Sink: CGN\n",
      "\n",
      "Path 2 for demand SZX/CGN/3/1800 (demand: 2175.79125 kg):\n",
      "  Source: SZX â†’ CGN (Day 3, Time 1800)\n",
      "    â†’ Wait time before flight: 1590 minutes\n",
      "  Flight: D041 from SZX â†’ BAH (Day 4, Dep 2030, Arr 620)\n",
      "    â†’ Connection wait time: 1660 minutes\n",
      "  Flight: ES695 from BAH â†’ HKG (Day 5, Dep 1000, Arr 1805)\n",
      "    â†’ Connection wait time: 2555 minutes\n",
      "  Flight: 3V400 from HKG â†’ ALA (Day 0, Dep 1240, Arr 1910)\n",
      "    â†’ Connection wait time: 665 minutes\n",
      "  Flight: QY547 from ALA â†’ CGN (Day 1, Dep 615, Arr 1420)\n",
      "  Sink: CGN\n",
      "Found 2 paths for demand SZX/CGN/3/1800\n",
      "\n",
      "Path 1 for demand JED/CVG/0/1800 (demand: 3229.78 kg):\n",
      "  Source: JED â†’ CVG (Day 0, Time 1800)\n",
      "    â†’ Wait time before flight: 70 minutes\n",
      "  Flight: ES103 from JED â†’ BAH (Day 0, Dep 1910, Arr 2125)\n",
      "    â†’ Connection wait time: 970 minutes\n",
      "  Flight: QY752 from BAH â†’ MXP (Day 1, Dep 1335, Arr 2005)\n",
      "    â†’ Connection wait time: 595 minutes\n",
      "  Flight: QY372 from MXP â†’ CVG (Day 2, Dep 600, Arr 1605)\n",
      "  Sink: CVG\n",
      "\n",
      "Path 2 for demand JED/CVG/0/1800 (demand: 3229.78 kg):\n",
      "  Source: JED â†’ CVG (Day 0, Time 1800)\n",
      "    â†’ Wait time before flight: 1510 minutes\n",
      "  Flight: ES103 from JED â†’ BAH (Day 1, Dep 1910, Arr 2125)\n",
      "    â†’ Connection wait time: 970 minutes\n",
      "  Flight: QY752 from BAH â†’ MXP (Day 2, Dep 1335, Arr 2005)\n",
      "    â†’ Connection wait time: 595 minutes\n",
      "  Flight: QY372 from MXP â†’ CVG (Day 3, Dep 600, Arr 1605)\n",
      "  Sink: CVG\n",
      "Found 2 paths for demand JED/CVG/0/1800\n",
      "\n",
      "Path 1 for demand CAI/MXP/4/1800 (demand: 1.575 kg):\n",
      "  Source: CAI â†’ MXP (Day 4, Time 1800)\n",
      "    â†’ Wait time before flight: 150 minutes\n",
      "  Flight: ES195 from CAI â†’ BAH (Day 4, Dep 2030, Arr 2315)\n",
      "    â†’ Connection wait time: 2305 minutes\n",
      "  Flight: ES752 from BAH â†’ MXP (Day 6, Dep 1340, Arr 2100)\n",
      "  Sink: MXP\n",
      "\n",
      "Path 2 for demand CAI/MXP/4/1800 (demand: 1.575 kg):\n",
      "  Source: CAI â†’ MXP (Day 4, Time 1800)\n",
      "    â†’ Wait time before flight: 150 minutes\n",
      "  Flight: ES195 from CAI â†’ BAH (Day 4, Dep 2030, Arr 2315)\n",
      "    â†’ Connection wait time: 1240 minutes\n",
      "  Flight: QY752 from BAH â†’ LEJ (Day 5, Dep 1955, Arr 230)\n",
      "    â†’ Connection wait time: 110 minutes\n",
      "  Flight: QY755 from LEJ â†’ MXP (Day 5, Dep 420, Arr 610)\n",
      "  Sink: MXP\n",
      "Found 2 paths for demand CAI/MXP/4/1800\n"
     ]
    }
   ],
   "source": [
    "def build_time_expanded_network(schedule_df, demand_df, connection_window_hours=48):\n",
    "    \"\"\"\n",
    "    Build a time-expanded network for flight scheduling optimization.\n",
    "    \n",
    "    Args:\n",
    "        schedule_df: DataFrame with flight schedule information\n",
    "        demand_df: DataFrame with demand information\n",
    "        connection_window_hours: Maximum time window for connections in hours\n",
    "    \n",
    "    Returns:\n",
    "        G: NetworkX DiGraph object representing the time-expanded network\n",
    "    \"\"\"\n",
    "    # Initialize directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create a helper function to calculate time difference considering day wrap\n",
    "    def time_diff_minutes(day1, time1, day2, time2):\n",
    "        \"\"\"Calculate difference in minutes between two times on specific days\"\"\"\n",
    "        # Convert times to minutes since beginning of week\n",
    "        mins1 = day1 * 24 * 60 + (time1 // 100) * 60 + (time1 % 100)\n",
    "        mins2 = day2 * 24 * 60 + (time2 // 100) * 60 + (time2 % 100)\n",
    "        \n",
    "        # Handle week wrap (if needed)\n",
    "        if mins2 < mins1:\n",
    "            mins2 += 7 * 24 * 60  # Add a week's worth of minutes\n",
    "            \n",
    "        return mins2 - mins1\n",
    "    \n",
    "    # Calculate maximum connection window in minutes\n",
    "    max_connection_minutes = connection_window_hours * 60\n",
    "    \n",
    "    # Step 1: Create flight vertices\n",
    "    flight_nodes = []\n",
    "    for _, flight in schedule_df.iterrows():\n",
    "        flight_node = f\"FLIGHT_{flight['flight_number']}_{flight['day']}_{flight['dep_time']}\"\n",
    "        flight_nodes.append(flight_node)\n",
    "        G.add_node(\n",
    "            flight_node, \n",
    "            type='flight',\n",
    "            flight_number=flight['flight_number'],\n",
    "            origin=flight['ori'],\n",
    "            destination=flight['des'],\n",
    "            day=flight['day'],\n",
    "            dep_time=flight['dep_time'],\n",
    "            arr_time=flight['arr_time'],\n",
    "            capacity_kg=flight['cap_kg'],\n",
    "            capacity_m3=flight['cap_m3']\n",
    "        )\n",
    "    \n",
    "    # Step 2: Create source vertices for each demand start - time specific\n",
    "    source_nodes = []\n",
    "    for _, demand in demand_df.iterrows():\n",
    "        source_node = f\"SOURCE_{demand['ori']}_{demand['des']}_{demand['day']}_{demand['time']}\"\n",
    "        source_nodes.append(source_node)\n",
    "        G.add_node(\n",
    "            source_node, \n",
    "            type='source',\n",
    "            origin=demand['ori'],\n",
    "            destination=demand['des'],\n",
    "            day=demand['day'],\n",
    "            time=demand['time'],\n",
    "            demand=demand['demand']\n",
    "        )\n",
    "    \n",
    "    # Step 3: Create sink vertices for each destination airport\n",
    "    sink_nodes = []\n",
    "    unique_destinations = demand_df['des'].unique()\n",
    "    for dest in unique_destinations:\n",
    "        sink_node = f\"SINK_{dest}\"\n",
    "        sink_nodes.append(sink_node)\n",
    "        G.add_node(sink_node, type='sink', airport=dest)\n",
    "    \n",
    "    # Step 4: Create arcs between flights (f1 to f2) if arr(f1) + 60min â‰¤ dep(f2) and des(f1) = ori(f2)\n",
    "    for i, flight1 in schedule_df.iterrows():\n",
    "        f1_node = f\"FLIGHT_{flight1['flight_number']}_{flight1['day']}_{flight1['dep_time']}\"\n",
    "        \n",
    "        for j, flight2 in schedule_df.iterrows():\n",
    "            if i != j:  # Don't connect a flight to itself\n",
    "                # Check if des(f1) == ori(f2)\n",
    "                if flight1['des'] == flight2['ori']:\n",
    "                    # Calculate time difference, allowing connections across days\n",
    "                    time_diff = time_diff_minutes(\n",
    "                        flight1['day'], flight1['arr_time'],\n",
    "                        flight2['day'], flight2['dep_time']\n",
    "                    )\n",
    "                    \n",
    "                    # Minimum connection time: 60 minutes\n",
    "                    # Maximum connection time: connection_window_hours\n",
    "                    if 60 <= time_diff <= max_connection_minutes:\n",
    "                        f2_node = f\"FLIGHT_{flight2['flight_number']}_{flight2['day']}_{flight2['dep_time']}\"\n",
    "                        G.add_edge(\n",
    "                            f1_node, f2_node,\n",
    "                            type='connection',\n",
    "                            wait_time=time_diff\n",
    "                        )\n",
    "    \n",
    "    # Step 5: Connect sources to flights\n",
    "    for _, demand in demand_df.iterrows():\n",
    "        source_node = f\"SOURCE_{demand['ori']}_{demand['des']}_{demand['day']}_{demand['time']}\"\n",
    "        \n",
    "        for _, flight in schedule_df.iterrows():\n",
    "            # Check if flight departs from the demand origin\n",
    "            if flight['ori'] == demand['ori']:\n",
    "                # Check if flight departure time is after demand time\n",
    "                time_diff = time_diff_minutes(\n",
    "                    demand['day'], demand['time'],\n",
    "                    flight['day'], flight['dep_time']\n",
    "                )\n",
    "                \n",
    "                # Flight must depart after demand time, but within connection window\n",
    "                if 0 <= time_diff <= max_connection_minutes:\n",
    "                    flight_node = f\"FLIGHT_{flight['flight_number']}_{flight['day']}_{flight['dep_time']}\"\n",
    "                    G.add_edge(\n",
    "                        source_node, flight_node,\n",
    "                        type='source_to_flight',\n",
    "                        wait_time=time_diff\n",
    "                    )\n",
    "    \n",
    "    # Step 6: Connect flights to sinks\n",
    "    for _, flight in schedule_df.iterrows():\n",
    "        flight_node = f\"FLIGHT_{flight['flight_number']}_{flight['day']}_{flight['dep_time']}\"\n",
    "        sink_node = f\"SINK_{flight['des']}\"\n",
    "        \n",
    "        G.add_edge(\n",
    "            flight_node, sink_node,\n",
    "            type='flight_to_sink',\n",
    "            arrival_time=flight['arr_time'],\n",
    "            arrival_day=flight['day']\n",
    "        )\n",
    "    \n",
    "    return G\n",
    "\n",
    "def analyze_graph(G):\n",
    "    \"\"\"Analyze the graph structure and print useful statistics\"\"\"\n",
    "    print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Count nodes by type\n",
    "    node_types = {}\n",
    "    for node, data in G.nodes(data=True):\n",
    "        node_type = data.get('type', 'unknown')\n",
    "        node_types[node_type] = node_types.get(node_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nNode counts by type:\")\n",
    "    for node_type, count in node_types.items():\n",
    "        print(f\"  {node_type}: {count}\")\n",
    "    \n",
    "    # Count edges by type\n",
    "    edge_types = {}\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        edge_type = data.get('type', 'unknown')\n",
    "        edge_types[edge_type] = edge_types.get(edge_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nEdge counts by type:\")\n",
    "    for edge_type, count in edge_types.items():\n",
    "        print(f\"  {edge_type}: {count}\")\n",
    "        \n",
    "    # Check for any sources that have no outgoing paths\n",
    "    isolated_sources = 0\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if data.get('type') == 'source' and G.out_degree(node) == 0:\n",
    "            isolated_sources += 1\n",
    "    \n",
    "    if isolated_sources > 0:\n",
    "        print(f\"\\nWARNING: {isolated_sources} source nodes have no outgoing paths\")\n",
    "    \n",
    "    # Check for connectivity between sources and sinks\n",
    "    sources = [n for n, d in G.nodes(data=True) if d.get('type') == 'source']\n",
    "    sinks = [n for n, d in G.nodes(data=True) if d.get('type') == 'sink']\n",
    "    \n",
    "    # Sample a few paths to check connectivity\n",
    "    print(\"\\nChecking connectivity between sources and sinks...\")\n",
    "    sampled_sources = sources[:min(5, len(sources))]\n",
    "    sampled_sinks = sinks[:min(5, len(sinks))]\n",
    "    \n",
    "    paths_found = 0\n",
    "    paths_attempted = 0\n",
    "    \n",
    "    for source in sampled_sources:\n",
    "        source_data = G.nodes[source]\n",
    "        # Find sinks that match the demand destination\n",
    "        target_sinks = [sink for sink in sinks if G.nodes[sink]['airport'] == source_data['destination']]\n",
    "        \n",
    "        if target_sinks:\n",
    "            target_sink = target_sinks[0]\n",
    "            paths_attempted += 1\n",
    "            try:\n",
    "                path = nx.shortest_path(G, source, target_sink)\n",
    "                paths_found += 1\n",
    "                print(f\"  Path exists from {source} to {target_sink} with {len(path)-2} intermediate flights\")\n",
    "            except nx.NetworkXNoPath:\n",
    "                print(f\"  No path from {source} to {target_sink}\")\n",
    "    \n",
    "    if paths_attempted > 0:\n",
    "        print(f\"\\n{paths_found} out of {paths_attempted} sampled source-sink pairs have valid paths\")\n",
    "    \n",
    "    return node_types, edge_types\n",
    "\n",
    "def find_paths_for_demand(G, demand_row, max_paths=3):\n",
    "    \"\"\"Find multiple paths for a specific demand\"\"\"\n",
    "    source_node = f\"SOURCE_{demand_row['ori']}_{demand_row['des']}_{demand_row['day']}_{demand_row['time']}\"\n",
    "    sink_node = f\"SINK_{demand_row['des']}\"\n",
    "    \n",
    "    if source_node not in G or sink_node not in G:\n",
    "        print(f\"Source or sink node not found for demand {demand_row['key']}\")\n",
    "        return []\n",
    "    \n",
    "    paths = []\n",
    "    try:\n",
    "        # Try to find k simple paths\n",
    "        for i, path in enumerate(nx.shortest_simple_paths(G, source_node, sink_node)):\n",
    "            if i >= max_paths:\n",
    "                break\n",
    "            paths.append(path)\n",
    "            \n",
    "            # Print path details\n",
    "            print(f\"\\nPath {i+1} for demand {demand_row['key']} (demand: {demand_row['demand']} kg):\")\n",
    "            for j in range(len(path)):\n",
    "                node = path[j]\n",
    "                node_data = G.nodes[node]\n",
    "                \n",
    "                if node_data['type'] == 'source':\n",
    "                    print(f\"  Source: {node_data['origin']} â†’ {node_data['destination']} (Day {node_data['day']}, Time {node_data['time']})\")\n",
    "                elif node_data['type'] == 'flight':\n",
    "                    print(f\"  Flight: {node_data['flight_number']} from {node_data['origin']} â†’ {node_data['destination']} (Day {node_data['day']}, Dep {node_data['dep_time']}, Arr {node_data['arr_time']})\")\n",
    "                elif node_data['type'] == 'sink':\n",
    "                    print(f\"  Sink: {node_data['airport']}\")\n",
    "                \n",
    "                # If not the last node, print edge details\n",
    "                if j < len(path) - 1:\n",
    "                    edge_data = G.edges[path[j], path[j+1]]\n",
    "                    if edge_data['type'] == 'connection':\n",
    "                        print(f\"    â†’ Connection wait time: {edge_data['wait_time']} minutes\")\n",
    "                    elif edge_data['type'] == 'source_to_flight':\n",
    "                        print(f\"    â†’ Wait time before flight: {edge_data['wait_time']} minutes\")\n",
    "    \n",
    "    except nx.NetworkXNoPath:\n",
    "        print(f\"No path found for demand {demand_row['key']}\")\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def main():\n",
    "    # Read data\n",
    "    schedule_df = read_capacity()\n",
    "    demand_df = read_market()\n",
    "    \n",
    "    print(f\"Loaded {len(schedule_df)} flights and {len(demand_df)} demand entries\")\n",
    "    \n",
    "    # Build the time-expanded network with 48-hour connection window\n",
    "    G = build_time_expanded_network(schedule_df, demand_df, connection_window_hours=48)\n",
    "    \n",
    "    # Analyze the graph\n",
    "    node_types, edge_types = analyze_graph(G)\n",
    "    \n",
    "    # Sample a few demands and find paths for them\n",
    "    sample_demands = demand_df.sample(min(3, len(demand_df)))\n",
    "    for _, demand in sample_demands.iterrows():\n",
    "        paths = find_paths_for_demand(G, demand, max_paths=2)\n",
    "        print(f\"Found {len(paths)} paths for demand {demand['key']}\")\n",
    "    \n",
    "    # Optional: Save the graph for future use\n",
    "    # import pickle\n",
    "    # with open('flight_network.pickle', 'wb') as f:\n",
    "    #     pickle.dump(G, f)\n",
    "    \n",
    "    return G, schedule_df, demand_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    G, schedule_df, demand_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
